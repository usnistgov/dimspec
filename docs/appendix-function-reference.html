<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Function Reference | User Guide for the NIST Database Infrastructure for Mass Spectrometry (DIMSpec) Toolkit</title>
  <meta name="description" content="This is the User Guide distributed alongside the R Project containing the toolset supporting the “Database Infrastructure for Mass Spectrometry (DIMSpec)” project." />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Function Reference | User Guide for the NIST Database Infrastructure for Mass Spectrometry (DIMSpec) Toolkit" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/assets/fig00-02_dimspec_conceptual_graphic.png" />
  <meta property="og:description" content="This is the User Guide distributed alongside the R Project containing the toolset supporting the “Database Infrastructure for Mass Spectrometry (DIMSpec)” project." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Function Reference | User Guide for the NIST Database Infrastructure for Mass Spectrometry (DIMSpec) Toolkit" />
  
  <meta name="twitter:description" content="This is the User Guide distributed alongside the R Project containing the toolset supporting the “Database Infrastructure for Mass Spectrometry (DIMSpec)” project." />
  <meta name="twitter:image" content="/assets/fig00-02_dimspec_conceptual_graphic.png" />

<meta name="author" content="Jared M. Ragland and Benjamin J. Place" />


<meta name="date" content="2023-07-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="msmatch-home.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<!-- Insert NIST header and footer -->
  <link rel="stylesheet" href="https://pages.nist.gov/nist-header-footer/css/nist-combined.css" />
  <!-- The live updating version is preferrable, but it causes race conditions in the DOM with auto formatting based on whether or not the NIST header/footer can be loaded. That script has been recreated here with the proper modifications to override gitbook CSS with the NIST header styling; see below.
    <script src="https://pages.nist.gov/nist-header-footer/js/nist-header-footer.js" type="text/javascript" defer="defer"></script>
  -->
  <!-- Project already includes jQuery 3.6 as part of gitbook -->
  <!-- <script src="https://code.jquery.com/jquery-3.6.2.min.js" type="text/javascript" defer="defer"></script> -->
  <!-- Insert NIST leave notice -->
  <!-- Project already includes jQuery 3.6 as part of gitbook -->
  <!-- <script type="text/javascript" src="https://code.jquery.com/jquery-1.12.4.min.js"></script> -->
  <script type="text/javascript" src="https://pages.nist.gov/leaveNotice/js/jquery.leaveNotice-nist.min.js"></script>
  <link rel="stylesheet" type="text/css" href="https://pages.nist.gov/leaveNotice/css/jquery.leaveNotice.css" />
  <script type="text/javascript" defer="defer">
    $(document).ready(function(){
      var divider = $('<li class="divider"></li>');
      var online_user_guide_link = $('<li><a href="https://pages.nist.gov/dimspec/docs/index.html" target="_blank"><i class="fa fa-bookmark"></i><p style="display: inline; font-weight: bold;">&nbsp&nbspOnline Version</p></a>');
      var nist_pao_privacy_link = $('<li><a href="http://www.nist.gov/public_affairs/privacy.cfm#privpolicy" target="_blank"><i class="fa fa-info-circle"></i><p style="display: inline;">&nbsp&nbspSite Privacy</p></a>');
      var nist_disclaimers_link = $('<li><a href="https://www.nist.gov/disclaimer" target="_blank"><i class="fa fa-info-circle"></i><p style="display: inline;">&nbsp&nbspDisclaimers</p></a>');
      var nist_pfas_program = $('<li><a href="https://www.nist.gov/programs-projects/and-polyfluoroalkyl-substances-pfas/research/reference-data-and-tools" target="_blank"><i class="fa fa-info-circle"></i><p style="display: inline;">&nbsp&nbspNIST PFAS Program - Tools</p></a>');
      $("body").prepend('<div id="nistheadergoeshere"></div>');
      $(".summary").append(divider);
      $.ajax({
        url: "https://pages.nist.gov/nist-header-footer/boilerplate-header.html",
        cache: false,
        dataType: "html"
      })
      .done(function (data) {
        $('#nistheadergoeshere').append(data);
        // Mark external (non-nist.gov) A tags with class "external"
        // If the adress start with https and ends with nist.gov
        var re_nist = new RegExp('^https?:\/\/((^\/)*\.)*nist\\.gov(\/|$)'); 
        // Regex to find address that start with https 
        var re_absolute_address = new RegExp('^((https?:)?\/\/)');
        $("a").each(function(){
          var url=$(this).attr('href'); 
          if(re_nist.test(url) || !re_absolute_address.test(url)){
            $(this).addClass('local'); 
          }else{
            $(this).addClass('external');
          } 
        });
        // Add leaveNotice to external A elements 
        $('a.external').leaveNotice({
          siteName: 'the DIMSpec User Guide',
        });
        // Add proper markings for NIST footer placement at bottom of page
        $("html").addClass('nist-footer-bottom');
        $("body").attr('id', 'main');
        // Hide the NIST logo, which is displayed on local copies lacking the NIST header and footer.
        $("#nist-logo-link").hide();
        // Set the background of the gitbook header to match that of the NIST header.
        $(".book-header").addClass("nist-style-header");
        var more_styles = $("<style>.nist-style-header { background-color: " + $("#nist-header").css("background-color") + " !important; }</style>");
        $("html > head").append(more_styles);
        $(".summary").append(nist_pfas_program);
        $(".summary").append(nist_pao_privacy_link);
        $(".summary").append(nist_disclaimers_link);
      })
      .fail(function() {
        // The gitbook search tool does not work when launched locally as it is not using a web server.
        $(".js-toolbar-action[aria-label='Search']").remove();
        $(".summary").append(online_user_guide_link);
        $(".summary").append(nist_pfas_program);
        $(".summary").append(nist_disclaimers_link);
      });
      $("body").append('<div id="nistfootergoeshere"></div>');
      $.ajax({
        url: "https://pages.nist.gov/nist-header-footer/boilerplate-footer.html",
        cache: false,
        dataType: "html"
      })
      .done(function (data) {
        $('#nistfootergoeshere').append(data);
      });
    });
  </script>
<!-- Insert NIST GA, uncomment the next line to activate.  -->
<script async type="text/javascript" id="_fed_an_ua_tag" src="https://dap.digitalgov.gov/Universal-Federated-Analytics-Min.js?agency=NIST&subagency=github&pua=UA-66610693-1&yt=true&exts=ppsx,pps,f90,sch,rtf,wrl,txz,m1v,xlsm,msi,xsd,f,tif,eps,mpg,xml,pl,xlt,c"></script>
<!--
  Use this file to address any browser compatibility or accessibility adjustments neccessary.
  Opening locally (and likely hosted) throws several errors and warnings in DevTools
  Last assessed 2023-03-14 by jared.ragland@nist.gov using MS Edge DevTools: 65 warnings and 7 errors.
  The majority of these issues were not easily fixable and stemmed from either CORS issues or gitbook styling rules.
-->
<!-- Accessibility -->
<script type="text/javascript">
  $(document).ready(function() {
    // No lanugage attribute is set on the html element by default.
    $("html").attr("lang", "en");
    $("html").attr("xml:lang", "en");
    // Default icon role is "presentation" which is not recognized as a valid role.
    $("#preface > p > i").attr("role", "img");
    $("div.buttons > button").each(function(){
      $(this).attr("type", "button");
    });
  })
</script>
<!-- Compatibility
  Errors (15x) included unrecognized CSS, primarily inclusion of the deprecated "-ms-*" rules. These stem from gitbook-2.6.7/css/style.css and will not be overridden as they are largely inapplicable as they are inclusion of additional rules for other browser.
  Flagged gitbook style rules (5x) included: -ms-filter, -ms-text-size-adjust, -webkit-text-size-adjust, test-size-adjust, -webkit-overflow-scrolling, -webkit-tap-highlight-color, orphans, widows.
  Flagged font-awesome header issues (2x) included: 'content-type' should be 'font/woff' not 'application/font-woff'
-->
<!-- Security
  Errors (2x) from CORS, resulting when the local version tries to include the hosted NIST header footer files. Inserting locally would somewhat fix these but make things more static. In this case, given the size of the NIST footer, it was decided to let this fail behind the scenes and render from the locally cached version of the User Guide as the tool may be used off-network in support of analytical laboratory operations. These should not be an issue with the hosted version.
  Errors (32x) CORS-related cookie errors, see above.
-->
<!-- Other
  Flagged MathJax (imported by gitbook) style rules (2x) included: 'border-radius' and 'box-shadow' being listed before '-khtml-border-radius' and '-khtml-box-shadow'.
  Flagged gitbook style rules (2x) included: 'box-sizing' and 'text-size-adjust' being listed before '-webkit-box-sizing' and '-moz-text-size-adjust'
  Flagged javascript (1x) from gitbook included use of navigator.platform.
  Deprecated Feature "Expect-CT header" which wasn't found in a sources search but continues to show up in the Issues list.
-->


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="part" id="book-links">
  <a id="nist-logo-link" href="https://www.nist.gov">
    <img id="nist-logo-svg" src="assets/NIST-Logo-Brand-White.svg" target="_blank" title="NIST logo"></img>
  </a>
  <h3 id="gitbook-title">
    <a id="github-link" href="https://github.com/usnistgov/dimspec" target="_blank">
      A Database Infrastructure for Mass Spectrometry (DIMSpec)  
      <svg aria-hidden="true" role="img" viewBox="0 0 496 512" style="height:1em;width:0.97em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;">
        <path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path>
      </svg>
    </a>
  </h3>
</li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>DIMSpec User Guide</b></span></li>
<li class="chapter" data-level="" data-path="intro-start.html"><a href="intro-start.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="intro-start.html"><a href="intro-start.html#intro-contributors"><i class="fa fa-check"></i>Contributors</a></li>
<li class="chapter" data-level="" data-path="intro-start.html"><a href="intro-start.html#intro-contributing"><i class="fa fa-check"></i>Contributing</a></li>
<li class="chapter" data-level="" data-path="intro-start.html"><a href="intro-start.html#intro-about"><i class="fa fa-check"></i>About this Book</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="instructions.html"><a href="instructions.html"><i class="fa fa-check"></i>Instructions</a>
<ul>
<li class="chapter" data-level="" data-path="instructions.html"><a href="instructions.html#installation"><i class="fa fa-check"></i>Installation</a></li>
<li class="chapter" data-level="" data-path="instructions.html"><a href="instructions.html#project-directory"><i class="fa fa-check"></i>Project Directory</a></li>
<li class="chapter" data-level="" data-path="instructions.html"><a href="instructions.html#project-set-up"><i class="fa fa-check"></i>Project Set Up</a></li>
<li class="chapter" data-level="" data-path="instructions.html"><a href="instructions.html#using-dimspec"><i class="fa fa-check"></i>Using DIMSpec</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html"><i class="fa fa-check"></i>Technical Details</a>
<ul>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html#database-schema"><i class="fa fa-check"></i>Database Schema</a></li>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html#populating-data-at-build"><i class="fa fa-check"></i>Populating Data at Build</a></li>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html#compute-environments"><i class="fa fa-check"></i>Compute Environments</a></li>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html#shiny-applications"><i class="fa fa-check"></i>Shiny Applications</a></li>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html#logger"><i class="fa fa-check"></i>Logger</a></li>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html#plumber"><i class="fa fa-check"></i>Plumber</a></li>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html#python"><i class="fa fa-check"></i>Python</a></li>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html#importing-data-td"><i class="fa fa-check"></i>Importing Data</a></li>
<li class="chapter" data-level="" data-path="technical-details.html"><a href="technical-details.html#future-development"><i class="fa fa-check"></i>Future Development</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="conclusions.html"><a href="conclusions.html"><i class="fa fa-check"></i>Conclusions</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="part"><span><b>Shiny Web Applications</b></span></li>
<li class="chapter" data-level="" data-path="table-explorer-home.html"><a href="table-explorer-home.html"><i class="fa fa-check"></i>Table Explorer</a>
<ul>
<li class="chapter" data-level="" data-path="table-explorer-home.html"><a href="table-explorer-home.html#table-explorer-table-viewer"><i class="fa fa-check"></i>Table Viewer</a></li>
<li class="chapter" data-level="" data-path="table-explorer-home.html"><a href="table-explorer-home.html#table-explorer-erd"><i class="fa fa-check"></i>Entity Relationship Diagram</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="dimspec-qc-home.html"><a href="dimspec-qc-home.html"><i class="fa fa-check"></i>DIMSpec Quality Control (DIMSpec-QC)</a>
<ul>
<li class="chapter" data-level="" data-path="dimspec-qc-home.html"><a href="dimspec-qc-home.html#dimspec-qc-intro"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="dimspec-qc-home.html"><a href="dimspec-qc-home.html#dimspec-qc-instructions"><i class="fa fa-check"></i>Instructions</a></li>
<li class="chapter" data-level="" data-path="dimspec-qc-home.html"><a href="dimspec-qc-home.html#dimspec-qc-technical-details"><i class="fa fa-check"></i>Technical Details</a></li>
<li class="chapter" data-level="" data-path="dimspec-qc-home.html"><a href="dimspec-qc-home.html#dimspec-qc-conclusions"><i class="fa fa-check"></i>Conclusions</a></li>
<li class="chapter" data-level="" data-path="dimspec-qc-home.html"><a href="dimspec-qc-home.html#dimspec-qc-appendices"><i class="fa fa-check"></i>Appendices</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="msmatch-home.html"><a href="msmatch-home.html"><i class="fa fa-check"></i>Mass Spectral Match (MSMatch)</a>
<ul>
<li class="chapter" data-level="" data-path="msmatch-home.html"><a href="msmatch-home.html#msmatch-intro"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="msmatch-home.html"><a href="msmatch-home.html#msmatch-instructions"><i class="fa fa-check"></i>Instructions</a></li>
<li class="chapter" data-level="" data-path="msmatch-home.html"><a href="msmatch-home.html#msmatch-technical-details"><i class="fa fa-check"></i>Technical Details</a></li>
<li class="chapter" data-level="" data-path="msmatch-home.html"><a href="msmatch-home.html#msmatch-conclusions"><i class="fa fa-check"></i>Conclusions</a></li>
</ul></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li class="chapter" data-level="" data-path="appendix-function-reference.html"><a href="appendix-function-reference.html"><i class="fa fa-check"></i>Function Reference</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">User Guide for the NIST Database Infrastructure for Mass Spectrometry (DIMSpec) Toolkit</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="appendix-function-reference" class="section level1 unnumbered hasAnchor">
<h1>Function Reference<a href="appendix-function-reference.html#appendix-function-reference" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>This appendix contains links to all documented functions included as part of the DIMSpec toolkit. As is common in R packages, not all functions are documented, but most are. Functions referenced in the rest of this user guide are linked directly to their entry on this page. Click any function in this table of contents to open its documentation.</p>
<table width="100%" summary="Help Index for DIMSpec Project">
<tr>
<td>
<h2>
DIMSpec Help Index
</h2>
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<table id="function_list">
<tr>
<td>
<a id="fn_activate_py_env" class="fn_link" href="#fn_def_activate_py_env" target="_blank">activate_py_env</a>
</td>
<td>
Activate a python environment
</td>
</tr>
<tr>
<td>
<a id="fn_active_connection" class="fn_link" href="#fn_def_active_connection" target="_blank">active_connection</a>
</td>
<td>
Is a connection object still available?
</td>
</tr>
<tr>
<td>
<a id="fn_add_help" class="fn_link" href="#fn_def_add_help" target="_blank">add_help</a>
</td>
<td>
Attach a superscript icon with a bsTooltip to an HTML element
</td>
</tr>
<tr>
<td>
<a id="fn_add_normalization_value" class="fn_link" href="#fn_def_add_normalization_value" target="_blank">add_normalization_value</a>
</td>
<td>
Add value(s) to a normalization table
</td>
</tr>
<tr>
<td>
<a id="fn_add_or_get_id" class="fn_link" href="#fn_def_add_or_get_id" target="_blank">add_or_get_id</a>
</td>
<td>
Utility function to add a record
</td>
</tr>
<tr>
<td>
<a id="fn_add_rdkit_aliases" class="fn_link" href="#fn_def_add_rdkit_aliases" target="_blank">add_rdkit_aliases</a>
</td>
<td>
Add fragment or compound aliases generated by RDKit functions
</td>
</tr>
<tr>
<td>
<a id="fn_adduct_formula" class="fn_link" href="#fn_def_adduct_formula" target="_blank">adduct_formula</a>
</td>
<td>
Add Adduct to Formula
</td>
</tr>
<tr>
<td>
<a id="fn_api_endpoint" class="fn_link" href="#fn_def_api_endpoint" target="_blank">api_endpoint</a>
</td>
<td>
Build an API endpoint programmatically
</td>
</tr>
<tr>
<td>
<a id="fn_api_open_doc" class="fn_link" href="#fn_def_api_open_doc" target="_blank">api_open_doc</a>
</td>
<td>
Open Swagger API documentation
</td>
</tr>
<tr>
<td>
<a id="fn_api_reload" class="fn_link" href="#fn_def_api_reload" target="_blank">api_reload</a>
</td>
<td>
Reloads the plumber API
</td>
</tr>
<tr>
<td>
<a id="fn_api_start" class="fn_link" href="#fn_def_api_start" target="_blank">api_start</a>
</td>
<td>
Start the plumber API
</td>
</tr>
<tr>
<td>
<a id="fn_api_stop" class="fn_link" href="#fn_def_api_stop" target="_blank">api_stop</a>
</td>
<td>
Stop the plumber API
</td>
</tr>
<tr>
<td>
<a id="fn_append_icon_to" class="fn_link" href="#fn_def_append_icon_to" target="_blank">append_icon_to</a>
</td>
<td>
Create the JS to append an icon to an HTML element by its ID
</td>
</tr>
<tr>
<td>
<a id="fn_bootstrap_compare_ms" class="fn_link" href="#fn_def_bootstrap_compare_ms" target="_blank">bootstrap_compare_ms</a>
</td>
<td>
Calculate dot product match score using bootstrap data
</td>
</tr>
<tr>
<td>
<a id="fn_build_db" class="fn_link" href="#fn_def_build_db" target="_blank">build_db</a>
</td>
<td>
Build or rebuild the database from scratch
</td>
</tr>
<tr>
<td>
<a id="fn_build_db_action" class="fn_link" href="#fn_def_build_db_action" target="_blank">build_db_action</a>
</td>
<td>
Build an escaped SQL query
</td>
</tr>
<tr>
<td>
<a id="fn_build_triggers" class="fn_link" href="#fn_def_build_triggers" target="_blank">build_triggers</a>
</td>
<td>
Build pairs of INSERT/UPDATE triggers to resolve foreign key relationships
</td>
</tr>
<tr>
<td>
<a id="fn_build_views" class="fn_link" href="#fn_def_build_views" target="_blank">build_views</a>
</td>
<td>
Build SQL to create views on normalized tables in SQLite
</td>
</tr>
<tr>
<td>
<a id="fn_calculate.monoisotope" class="fn_link" href="#fn_def_calculate.monoisotope" target="_blank">calculate.monoisotope</a>
</td>
<td>
Calculate the monoisotopic mass of an elemental formula list
</td>
</tr>
<tr>
<td>
<a id="fn_check_for_value" class="fn_link" href="#fn_def_check_for_value" target="_blank">check_for_value</a>
</td>
<td>
Check for a value in a database table
</td>
</tr>
<tr>
<td>
<a id="fn_check_fragments" class="fn_link" href="#fn_def_check_fragments" target="_blank">check_fragments</a>
</td>
<td>
Determine number of matching fragments between unknown mass spectrum and specific peaks
</td>
</tr>
<tr>
<td>
<a id="fn_check_isotopedist" class="fn_link" href="#fn_def_check_isotopedist" target="_blank">check_isotopedist</a>
</td>
<td>
Compare Isotopic Pattern to simulated pattern
</td>
</tr>
<tr>
<td>
<a id="fn_check_mzML_convert" class="fn_link" href="#fn_def_check_mzML_convert" target="_blank">check_mzML_convert</a>
</td>
<td>
Check mzML file for specific MSConvert parameters
</td>
</tr>
<tr>
<td>
<a id="fn_clause_where" class="fn_link" href="#fn_def_clause_where" target="_blank">clause_where</a>
</td>
<td>
Build a WHERE clause for SQL statements
</td>
</tr>
<tr>
<td>
<a id="fn_close_up_shop" class="fn_link" href="#fn_def_close_up_shop" target="_blank">close_up_shop</a>
</td>
<td>
Conveniently close all database connections
</td>
</tr>
<tr>
<td>
<a id="fn_compare_ms" class="fn_link" href="#fn_def_compare_ms" target="_blank">compare_ms</a>
</td>
<td>
Calculate dot product match score
</td>
</tr>
<tr>
<td>
<a id="fn_complete_form_entry" class="fn_link" href="#fn_def_complete_form_entry" target="_blank">complete_form_entry</a>
</td>
<td>
Ensure complete form entry
</td>
</tr>
<tr>
<td>
<a id="fn_create_fallback_build" class="fn_link" href="#fn_def_create_fallback_build" target="_blank">create_fallback_build</a>
</td>
<td>
Create an SQL file for use without the SQLite CLI
</td>
</tr>
<tr>
<td>
<a id="fn_create_peak_list" class="fn_link" href="#fn_def_create_peak_list" target="_blank">create_peak_list</a>
</td>
<td>
Spectral Uncertainty Functions ———————————————————-
</td>
</tr>
<tr>
<td>
<a id="fn_create_peak_table_ms1" class="fn_link" href="#fn_def_create_peak_table_ms1" target="_blank">create_peak_table_ms1</a>
</td>
<td>
Create peak table for MS1 data
</td>
</tr>
<tr>
<td>
<a id="fn_create_peak_table_ms2" class="fn_link" href="#fn_def_create_peak_table_ms2" target="_blank">create_peak_table_ms2</a>
</td>
<td>
Create peak table for MS2 data
</td>
</tr>
<tr>
<td>
<a id="fn_create_py_env" class="fn_link" href="#fn_def_create_py_env" target="_blank">create_py_env</a>
</td>
<td>
Create a python environment for RDKit
</td>
</tr>
<tr>
<td>
<a id="fn_create_search_df" class="fn_link" href="#fn_def_create_search_df" target="_blank">create_search_df</a>
</td>
<td>
Create data.frame containing parameters for extraction and searching
</td>
</tr>
<tr>
<td>
<a id="fn_create_search_ms" class="fn_link" href="#fn_def_create_search_ms" target="_blank">create_search_ms</a>
</td>
<td>
Generate uncertainty mass spectrum for MS1 and MS2 data
</td>
</tr>
<tr>
<td>
<a id="fn_data_dictionary" class="fn_link" href="#fn_def_data_dictionary" target="_blank">data_dictionary</a>
</td>
<td>
Create a data dictionary
</td>
</tr>
<tr>
<td>
<a id="fn_dataframe_match" class="fn_link" href="#fn_def_dataframe_match" target="_blank">dataframe_match</a>
</td>
<td>
Match multiple values in a database table
</td>
</tr>
<tr>
<td>
<a id="fn_dotprod" class="fn_link" href="#fn_def_dotprod" target="_blank">dotprod</a>
</td>
<td>
Calculate dot product
</td>
</tr>
<tr>
<td>
<a id="fn_dt_color_by" class="fn_link" href="#fn_def_dt_color_by" target="_blank">dt_color_by</a>
</td>
<td>
Apply colors to DT objects by value in a column
</td>
</tr>
<tr>
<td>
<a id="fn_dt_formatted" class="fn_link" href="#fn_def_dt_formatted" target="_blank">dt_formatted</a>
</td>
<td>
Easily format multiple DT objects in a shiny project in the same manner
</td>
</tr>
<tr>
<td>
<a id="fn_er_map" class="fn_link" href="#fn_def_er_map" target="_blank">er_map</a>
</td>
<td>
Create a simple entity relationship map
</td>
</tr>
<tr>
<td>
<a id="fn_export_msp" class="fn_link" href="#fn_def_export_msp" target="_blank">export_msp</a>
</td>
<td>
Export to MSP
</td>
</tr>
<tr>
<td>
<a id="fn_extend_suspect_list" class="fn_link" href="#fn_def_extend_suspect_list" target="_blank">extend_suspect_list</a>
</td>
<td>
Extend the compounds and aliases tables
</td>
</tr>
<tr>
<td>
<a id="fn_extract.elements" class="fn_link" href="#fn_def_extract.elements" target="_blank">extract.elements</a>
</td>
<td>
Elemental Formula Functions
</td>
</tr>
<tr>
<td>
<a id="fn_flush_dir" class="fn_link" href="#fn_def_flush_dir" target="_blank">flush_dir</a>
</td>
<td>
Flush a directory with archive
</td>
</tr>
<tr>
<td>
<a id="fn_fn_guide" class="fn_link" href="#fn_def_fn_guide" target="_blank">fn_guide</a>
</td>
<td>
View an index of help documentation in your browser
</td>
</tr>
<tr>
<td>
<a id="fn_fn_help" class="fn_link" href="#fn_def_fn_help" target="_blank">fn_help</a>
</td>
<td>
Get function documentation for this project
</td>
</tr>
<tr>
<td>
<a id="fn_format_id" class="fn_link" href="#fn_def_format_id" target="_blank">format_id</a>
</td>
<td>
Format a file name as an HTML element ID
</td>
</tr>
<tr>
<td>
<a id="fn_format_list_of_names" class="fn_link" href="#fn_def_format_list_of_names" target="_blank">format_list_of_names</a>
</td>
<td>
Grammatically collapse a list of values
</td>
</tr>
<tr>
<td>
<a id="fn_formulalize" class="fn_link" href="#fn_def_formulalize" target="_blank">formulalize</a>
</td>
<td>
Generate standard chemical formula notation
</td>
</tr>
<tr>
<td>
<a id="fn_full_import" class="fn_link" href="#fn_def_full_import" target="_blank">full_import</a>
</td>
<td>
Import one or more files from the NIST Method Reporting Tool for NTA
</td>
</tr>
<tr>
<td>
<a id="fn_gather_qc" class="fn_link" href="#fn_def_gather_qc" target="_blank">gather_qc</a>
</td>
<td>
Quality Control Check of Import Data
</td>
</tr>
<tr>
<td>
<a id="fn_get_annotated_fragments" class="fn_link" href="#fn_def_get_annotated_fragments" target="_blank">get_annotated_fragments</a>
</td>
<td>
Get all annotated fragments have matching masses
</td>
</tr>
<tr>
<td>
<a id="fn_get_component" class="fn_link" href="#fn_def_get_component" target="_blank">get_component</a>
</td>
<td>
Resolve components from a list or named vector
</td>
</tr>
<tr>
<td>
<a id="fn_get_compound_fragments" class="fn_link" href="#fn_def_get_compound_fragments" target="_blank">get_compound_fragments</a>
</td>
<td>
Get all fragments associated with compounds
</td>
</tr>
<tr>
<td>
<a id="fn_get_compoundid" class="fn_link" href="#fn_def_get_compoundid" target="_blank">get_compoundid</a>
</td>
<td>
Get compound ID and name for specific peaks
</td>
</tr>
<tr>
<td>
<a id="fn_get_fkpk_relationships" class="fn_link" href="#fn_def_get_fkpk_relationships" target="_blank">get_fkpk_relationships</a>
</td>
<td>
Extract foreign key relationships from a schema
</td>
</tr>
<tr>
<td>
<a id="fn_get_massadj" class="fn_link" href="#fn_def_get_massadj" target="_blank">get_massadj</a>
</td>
<td>
Calculate the mass adjustment for a specific adduct
</td>
</tr>
<tr>
<td>
<a id="fn_get_msconvert_data" class="fn_link" href="#fn_def_get_msconvert_data" target="_blank">get_msconvert_data</a>
</td>
<td>
Extract msconvert metadata
</td>
</tr>
<tr>
<td>
<a id="fn_get_msdata" class="fn_link" href="#fn_def_get_msdata" target="_blank">get_msdata</a>
</td>
<td>
Get all mass spectral data within the database
</td>
</tr>
<tr>
<td>
<a id="fn_get_msdata_compound" class="fn_link" href="#fn_def_get_msdata_compound" target="_blank">get_msdata_compound</a>
</td>
<td>
Get all mass spectral data for a specific compound
</td>
</tr>
<tr>
<td>
<a id="fn_get_msdata_peakid" class="fn_link" href="#fn_def_get_msdata_peakid" target="_blank">get_msdata_peakid</a>
</td>
<td>
Get all mass spectral data for a specific peak id
</td>
</tr>
<tr>
<td>
<a id="fn_get_msdata_precursors" class="fn_link" href="#fn_def_get_msdata_precursors" target="_blank">get_msdata_precursors</a>
</td>
<td>
Get all mass spectral data with a specific precursor ion
</td>
</tr>
<tr>
<td>
<a id="fn_get_opt_params" class="fn_link" href="#fn_def_get_opt_params" target="_blank">get_opt_params</a>
</td>
<td>
Get optimized uncertainty mass spectra parameters for a peak
</td>
</tr>
<tr>
<td>
<a id="fn_get_peak_fragments" class="fn_link" href="#fn_def_get_peak_fragments" target="_blank">get_peak_fragments</a>
</td>
<td>
Get annotated fragments for a specific peak
</td>
</tr>
<tr>
<td>
<a id="fn_get_peak_precursor" class="fn_link" href="#fn_def_get_peak_precursor" target="_blank">get_peak_precursor</a>
</td>
<td>
Get precursor ion m/z for a specific peak
</td>
</tr>
<tr>
<td>
<a id="fn_get_sample_class" class="fn_link" href="#fn_def_get_sample_class" target="_blank">get_sample_class</a>
</td>
<td>
Get sample class information for specific peaks
</td>
</tr>
<tr>
<td>
<a id="fn_get_search_object" class="fn_link" href="#fn_def_get_search_object" target="_blank">get_search_object</a>
</td>
<td>
Generate msdata object from input peak data
</td>
</tr>
<tr>
<td>
<a id="fn_get_suspectlist" class="fn_link" href="#fn_def_get_suspectlist" target="_blank">get_suspectlist</a>
</td>
<td>
Get the current NIST PFAS suspect list.
</td>
</tr>
<tr>
<td>
<a id="fn_get_ums" class="fn_link" href="#fn_def_get_ums" target="_blank">get_ums</a>
</td>
<td>
Generate consensus mass spectrum
</td>
</tr>
<tr>
<td>
<a id="fn_get_uniques" class="fn_link" href="#fn_def_get_uniques" target="_blank">get_uniques</a>
</td>
<td>
Get unique components of a nested list
</td>
</tr>
<tr>
<td>
<a id="fn_getcharge" class="fn_link" href="#fn_def_getcharge" target="_blank">getcharge</a>
</td>
<td>
Get polarity of a ms scan within mzML object
</td>
</tr>
<tr>
<td>
<a id="fn_getmslevel" class="fn_link" href="#fn_def_getmslevel" target="_blank">getmslevel</a>
</td>
<td>
Get MS Level of a ms scan within mzML object
</td>
</tr>
<tr>
<td>
<a id="fn_getmzML" class="fn_link" href="#fn_def_getmzML" target="_blank">getmzML</a>
</td>
<td>
Brings raw data file into environment
</td>
</tr>
<tr>
<td>
<a id="fn_getprecursor" class="fn_link" href="#fn_def_getprecursor" target="_blank">getprecursor</a>
</td>
<td>
Get precursor ion of a ms scan within mzML object
</td>
</tr>
<tr>
<td>
<a id="fn_gettime" class="fn_link" href="#fn_def_gettime" target="_blank">gettime</a>
</td>
<td>
Get time of a ms scan within mzML object
</td>
</tr>
<tr>
<td>
<a id="fn_has_missing_elements" class="fn_link" href="#fn_def_has_missing_elements" target="_blank">has_missing_elements</a>
</td>
<td>
Simple check for if an object is empty
</td>
</tr>
<tr>
<td>
<a id="fn_is_elemental_match" class="fn_link" href="#fn_def_is_elemental_match" target="_blank">is_elemental_match</a>
</td>
<td>
Checks if two elemental formulas match
</td>
</tr>
<tr>
<td>
<a id="fn_is_elemental_subset" class="fn_link" href="#fn_def_is_elemental_subset" target="_blank">is_elemental_subset</a>
</td>
<td>
Check if elemental formula is a subset of another formula
</td>
</tr>
<tr>
<td>
<a id="fn_isotopic_distribution" class="fn_link" href="#fn_def_isotopic_distribution" target="_blank">isotopic_distribution</a>
</td>
<td>
Isotopic distribution functions
</td>
</tr>
<tr>
<td>
<a id="fn_lockmass_remove" class="fn_link" href="#fn_def_lockmass_remove" target="_blank">lockmass_remove</a>
</td>
<td>
Remove lockmass scan from mzml object
</td>
</tr>
<tr>
<td>
<a id="fn_log_as_dataframe" class="fn_link" href="#fn_def_log_as_dataframe" target="_blank">log_as_dataframe</a>
</td>
<td>
Pull a log file into an R object
</td>
</tr>
<tr>
<td>
<a id="fn_log_fn" class="fn_link" href="#fn_def_log_fn" target="_blank">log_fn</a>
</td>
<td>
Simple logging convenience
</td>
</tr>
<tr>
<td>
<a id="fn_log_it" class="fn_link" href="#fn_def_log_it" target="_blank">log_it</a>
</td>
<td>
Conveniently log a message to the console
</td>
</tr>
<tr>
<td>
<a id="fn_make_acronym" class="fn_link" href="#fn_def_make_acronym" target="_blank">make_acronym</a>
</td>
<td>
Simple acronym generator
</td>
</tr>
<tr>
<td>
<a id="fn_make_install_code" class="fn_link" href="#fn_def_make_install_code" target="_blank">make_install_code</a>
</td>
<td>
Convenience function to set a new installation code
</td>
</tr>
<tr>
<td>
<a id="fn_make_requirements" class="fn_link" href="#fn_def_make_requirements" target="_blank">make_requirements</a>
</td>
<td>
Make import requirements file
</td>
</tr>
<tr>
<td>
<a id="fn_manage_connection" class="fn_link" href="#fn_def_manage_connection" target="_blank">manage_connection</a>
</td>
<td>
Check for, and optionally remove, a database connection object
</td>
</tr>
<tr>
<td>
<a id="fn_map_import" class="fn_link" href="#fn_def_map_import" target="_blank">map_import</a>
</td>
<td>
Map an import file to the database schema
</td>
</tr>
<tr>
<td>
<a id="fn_mode_checks" class="fn_link" href="#fn_def_mode_checks" target="_blank">mode_checks</a>
</td>
<td>
Get list of available functions
</td>
</tr>
<tr>
<td>
<a id="fn_molecule_picture" class="fn_link" href="#fn_def_molecule_picture" target="_blank">molecule_picture</a>
</td>
<td>
Picture a molecule from structural notation
</td>
</tr>
<tr>
<td>
<a id="fn_monoisotope.list" class="fn_link" href="#fn_def_monoisotope.list" target="_blank">monoisotope.list</a>
</td>
<td>
Calculate the monoisotopic mass of a elemental formulas in
</td>
</tr>
<tr>
<td>
<a id="fn_ms_plot_peak" class="fn_link" href="#fn_def_ms_plot_peak" target="_blank">ms_plot_peak</a>
</td>
<td>
Plot a peak from database mass spectral data
</td>
</tr>
<tr>
<td>
<a id="fn_ms_plot_peak_overview" class="fn_link" href="#fn_def_ms_plot_peak_overview" target="_blank">ms_plot_peak_overview</a>
</td>
<td>
Create a patchwork plot of peak spectral properties
</td>
</tr>
<tr>
<td>
<a id="fn_ms_plot_spectra" class="fn_link" href="#fn_def_ms_plot_spectra" target="_blank">ms_plot_spectra</a>
</td>
<td>
Plot a fragment map from database mass spectral data
</td>
</tr>
<tr>
<td>
<a id="fn_ms_plot_spectral_intensity" class="fn_link" href="#fn_def_ms_plot_spectral_intensity" target="_blank">ms_plot_spectral_intensity</a>
</td>
<td>
Create a spectral intensity plot
</td>
</tr>
<tr>
<td>
<a id="fn_ms_plot_titles" class="fn_link" href="#fn_def_ms_plot_titles" target="_blank">ms_plot_titles</a>
</td>
<td>
Consistent for ms_plot_x functions
</td>
</tr>
<tr>
<td>
<a id="fn_ms_spectra_separated" class="fn_link" href="#fn_def_ms_spectra_separated" target="_blank">ms_spectra_separated</a>
</td>
<td>
Parse “Separated” MS Data
</td>
</tr>
<tr>
<td>
<a id="fn_ms_spectra_zipped" class="fn_link" href="#fn_def_ms_spectra_zipped" target="_blank">ms_spectra_zipped</a>
</td>
<td>
Parse “Zipped” MS Data
</td>
</tr>
<tr>
<td>
<a id="fn_mzMLconvert" class="fn_link" href="#fn_def_mzMLconvert" target="_blank">mzMLconvert</a>
</td>
<td>
Converts a raw file into an mzML
</td>
</tr>
<tr>
<td>
<a id="fn_mzMLtoR" class="fn_link" href="#fn_def_mzMLtoR" target="_blank">mzMLtoR</a>
</td>
<td>
Opens file of type mzML into R environment
</td>
</tr>
<tr>
<td>
<a id="fn_nist_shinyalert" class="fn_link" href="#fn_def_nist_shinyalert" target="_blank">nist_shinyalert</a>
</td>
<td>
Call [shinyalert::shinyalert] with specific styling
</td>
</tr>
<tr>
<td>
<a id="fn_obj_name_check" class="fn_link" href="#fn_def_obj_name_check" target="_blank">obj_name_check</a>
</td>
<td>
Sanity check for environment object names
</td>
</tr>
<tr>
<td>
<a id="fn_open_env" class="fn_link" href="#fn_def_open_env" target="_blank">open_env</a>
</td>
<td>
Convenience shortcut to open and edit session environment variables
</td>
</tr>
<tr>
<td>
<a id="fn_open_proj_file" class="fn_link" href="#fn_def_open_proj_file" target="_blank">open_proj_file</a>
</td>
<td>
Open and edit project files
</td>
</tr>
<tr>
<td>
<a id="fn_optimal_ums" class="fn_link" href="#fn_def_optimal_ums" target="_blank">optimal_ums</a>
</td>
<td>
Get the optimal uncertainty mass spectrum parameters for data
</td>
</tr>
<tr>
<td>
<a id="fn_overlap" class="fn_link" href="#fn_def_overlap" target="_blank">overlap</a>
</td>
<td>
Calculate overlap ranges
</td>
</tr>
<tr>
<td>
<a id="fn_pair_ums" class="fn_link" href="#fn_def_pair_ums" target="_blank">pair_ums</a>
</td>
<td>
Pairwise data.frame of two uncertainty mass spectra
</td>
</tr>
<tr>
<td>
<a id="fn_peak_gather_json" class="fn_link" href="#fn_def_peak_gather_json" target="_blank">peak_gather_json</a>
</td>
<td>
Extract peak data and metadata
</td>
</tr>
<tr>
<td>
<a id="fn_plot_compare_ms" class="fn_link" href="#fn_def_plot_compare_ms" target="_blank">plot_compare_ms</a>
</td>
<td>
Plot MS Comparison
</td>
</tr>
<tr>
<td>
<a id="fn_plot_ms" class="fn_link" href="#fn_def_plot_ms" target="_blank">plot_ms</a>
</td>
<td>
Generate consensus mass spectrum
</td>
</tr>
<tr>
<td>
<a id="fn_pool.sd" class="fn_link" href="#fn_def_pool.sd" target="_blank">pool.sd</a>
</td>
<td>
Pool standard deviations
</td>
</tr>
<tr>
<td>
<a id="fn_pool.ums" class="fn_link" href="#fn_def_pool.ums" target="_blank">pool.ums</a>
</td>
<td>
Pool uncertainty mass spectra
</td>
</tr>
<tr>
<td>
<a id="fn_pragma_table_def" class="fn_link" href="#fn_def_pragma_table_def" target="_blank">pragma_table_def</a>
</td>
<td>
Get table definition from SQLite
</td>
</tr>
<tr>
<td>
<a id="fn_pragma_table_info" class="fn_link" href="#fn_def_pragma_table_info" target="_blank">pragma_table_info</a>
</td>
<td>
Explore properties of an SQLite table
</td>
</tr>
<tr>
<td>
<a id="fn_py_modules_available" class="fn_link" href="#fn_def_py_modules_available" target="_blank">py_modules_available</a>
</td>
<td>
Are all conda modules available in the active environment
</td>
</tr>
<tr>
<td>
<a id="fn_rdkit_active" class="fn_link" href="#fn_def_rdkit_active" target="_blank">rdkit_active</a>
</td>
<td>
Sanity check on RDKit binding
</td>
</tr>
<tr>
<td>
<a id="fn_rdkit_mol_aliases" class="fn_link" href="#fn_def_rdkit_mol_aliases" target="_blank">rdkit_mol_aliases</a>
</td>
<td>
Create aliases for a molecule from RDKit
</td>
</tr>
<tr>
<td>
<a id="fn_read_log" class="fn_link" href="#fn_def_read_log" target="_blank">read_log</a>
</td>
<td>
Read a log from a log file
</td>
</tr>
<tr>
<td>
<a id="fn_rebuild_helps" class="fn_link" href="#fn_def_rebuild_helps" target="_blank">rebuild_helps</a>
</td>
<td>
Rebuild the help files as HTML with an index
</td>
</tr>
<tr>
<td>
<a id="fn_rectify_null_from_env" class="fn_link" href="#fn_def_rectify_null_from_env" target="_blank">rectify_null_from_env</a>
</td>
<td>
Rectify NULL values provided to functions
</td>
</tr>
<tr>
<td>
<a id="fn_ref_table_from_map" class="fn_link" href="#fn_def_ref_table_from_map" target="_blank">ref_table_from_map</a>
</td>
<td>
Get the name of a linked normalization table
</td>
</tr>
<tr>
<td>
<a id="fn_remove_db" class="fn_link" href="#fn_def_remove_db" target="_blank">remove_db</a>
</td>
<td>
Remove an existing database
</td>
</tr>
<tr>
<td>
<a id="fn_remove_icon_from" class="fn_link" href="#fn_def_remove_icon_from" target="_blank">remove_icon_from</a>
</td>
<td>
Remove the last icon attached to an HTML element
</td>
</tr>
<tr>
<td>
<a id="fn_remove_sample" class="fn_link" href="#fn_def_remove_sample" target="_blank">remove_sample</a>
</td>
<td>
Delete a sample
</td>
</tr>
<tr>
<td>
<a id="fn_repair_xl_casrn_forced_to_date" class="fn_link" href="#fn_def_repair_xl_casrn_forced_to_date" target="_blank">repair_xl_casrn_forced_to_date</a>
</td>
<td>
Repair CAS RNs forced to a date numeric by MSXL
</td>
</tr>
<tr>
<td>
<a id="fn_repl_nan" class="fn_link" href="#fn_def_repl_nan" target="_blank">repl_nan</a>
</td>
<td>
Replace NaN
</td>
</tr>
<tr>
<td>
<a id="fn_report_qc" class="fn_link" href="#fn_def_report_qc" target="_blank">report_qc</a>
</td>
<td>
Export QC result JSONfile into PDF
</td>
</tr>
<tr>
<td>
<a id="fn_reset_logger_settings" class="fn_link" href="#fn_def_reset_logger_settings" target="_blank">reset_logger_settings</a>
</td>
<td>
Update logger settings
</td>
</tr>
<tr>
<td>
<a id="fn_resolve_compound_aliases" class="fn_link" href="#fn_def_resolve_compound_aliases" target="_blank">resolve_compound_aliases</a>
</td>
<td>
Resolve compound aliases provided as part of the import routine
</td>
</tr>
<tr>
<td>
<a id="fn_resolve_compound_fragments" class="fn_link" href="#fn_def_resolve_compound_fragments" target="_blank">resolve_compound_fragments</a>
</td>
<td>
Link together peaks, fragments, and compounds
</td>
</tr>
<tr>
<td>
<a id="fn_resolve_compounds" class="fn_link" href="#fn_def_resolve_compounds" target="_blank">resolve_compounds</a>
</td>
<td>
Resolve the compounds node during bulk import
</td>
</tr>
<tr>
<td>
<a id="fn_resolve_description_NTAMRT" class="fn_link" href="#fn_def_resolve_description_NTAMRT" target="_blank">resolve_description_NTAMRT</a>
</td>
<td>
Resolve the method description tables during import
</td>
</tr>
<tr>
<td>
<a id="fn_resolve_fragments_NTAMRT" class="fn_link" href="#fn_def_resolve_fragments_NTAMRT" target="_blank">resolve_fragments_NTAMRT</a>
</td>
<td>
Resolve the fragments node during database import
</td>
</tr>
<tr>
<td>
<a id="fn_resolve_method" class="fn_link" href="#fn_def_resolve_method" target="_blank">resolve_method</a>
</td>
<td>
Add an ms_method record via import
</td>
</tr>
<tr>
<td>
<a id="fn_resolve_mobile_phase_NTAMRT" class="fn_link" href="#fn_def_resolve_mobile_phase_NTAMRT" target="_blank">resolve_mobile_phase_NTAMRT</a>
</td>
<td>
Resolve the mobile phase node
</td>
</tr>
<tr>
<td>
<a id="fn_resolve_ms_data" class="fn_link" href="#fn_def_resolve_ms_data" target="_blank">resolve_ms_data</a>
</td>
<td>
Resolve and store mass spectral data during import
</td>
</tr>
<tr>
<td>
<a id="fn_resolve_ms_spectra" class="fn_link" href="#fn_def_resolve_ms_spectra" target="_blank">resolve_ms_spectra</a>
</td>
<td>
Unpack mass spectral data in compressed format
</td>
</tr>
<tr>
<td>
<a id="fn_resolve_multiple_values" class="fn_link" href="#fn_def_resolve_multiple_values" target="_blank">resolve_multiple_values</a>
</td>
<td>
Utility function to resolve multiple choices interactively
</td>
</tr>
<tr>
<td>
<a id="fn_resolve_normalization_value" class="fn_link" href="#fn_def_resolve_normalization_value" target="_blank">resolve_normalization_value</a>
</td>
<td>
Resolve a normalization value against the database
</td>
</tr>
<tr>
<td>
<a id="fn_resolve_peak_ums_params" class="fn_link" href="#fn_def_resolve_peak_ums_params" target="_blank">resolve_peak_ums_params</a>
</td>
<td>
Resolve and import optimal uncertain mass spectrum parameters
</td>
</tr>
<tr>
<td>
<a id="fn_resolve_peaks" class="fn_link" href="#fn_def_resolve_peaks" target="_blank">resolve_peaks</a>
</td>
<td>
Resolve the peaks node during import
</td>
</tr>
<tr>
<td>
<a id="fn_resolve_qc_data_NTAMRT" class="fn_link" href="#fn_def_resolve_qc_data_NTAMRT" target="_blank">resolve_qc_data_NTAMRT</a>
</td>
<td>
Resolve and import quality control data for import
</td>
</tr>
<tr>
<td>
<a id="fn_resolve_qc_methods_NTAMRT" class="fn_link" href="#fn_def_resolve_qc_methods_NTAMRT" target="_blank">resolve_qc_methods_NTAMRT</a>
</td>
<td>
Resolve and import quality control method information
</td>
</tr>
<tr>
<td>
<a id="fn_resolve_sample" class="fn_link" href="#fn_def_resolve_sample" target="_blank">resolve_sample</a>
</td>
<td>
Add a sample via import
</td>
</tr>
<tr>
<td>
<a id="fn_resolve_sample_aliases" class="fn_link" href="#fn_def_resolve_sample_aliases" target="_blank">resolve_sample_aliases</a>
</td>
<td>
Resolve and import sample aliases
</td>
</tr>
<tr>
<td>
<a id="fn_resolve_software_settings_NTAMRT" class="fn_link" href="#fn_def_resolve_software_settings_NTAMRT" target="_blank">resolve_software_settings_NTAMRT</a>
</td>
<td>
Import software settings
</td>
</tr>
<tr>
<td>
<a id="fn_resolve_table_name" class="fn_link" href="#fn_def_resolve_table_name" target="_blank">resolve_table_name</a>
</td>
<td>
Check presence of a database table
</td>
</tr>
<tr>
<td>
<a id="fn_save_data_dictionary" class="fn_link" href="#fn_def_save_data_dictionary" target="_blank">save_data_dictionary</a>
</td>
<td>
Save the current data dictionary to disk
</td>
</tr>
<tr>
<td>
<a id="fn_search_all" class="fn_link" href="#fn_def_search_all" target="_blank">search_all</a>
</td>
<td>
Search all mass spectra within database against unknown mass spectrum
</td>
</tr>
<tr>
<td>
<a id="fn_search_precursor" class="fn_link" href="#fn_def_search_precursor" target="_blank">search_precursor</a>
</td>
<td>
Search the database for all compounds with matching precursor ion m/z values
</td>
</tr>
<tr>
<td>
<a id="fn_setup_rdkit" class="fn_link" href="#fn_def_setup_rdkit" target="_blank">setup_rdkit</a>
</td>
<td>
Conveniently set up an RDKit python environment for use with R
</td>
</tr>
<tr>
<td>
<a id="fn_sigtest" class="fn_link" href="#fn_def_sigtest" target="_blank">sigtest</a>
</td>
<td>
Significance testing function
</td>
</tr>
<tr>
<td>
<a id="fn_smilestoformula" class="fn_link" href="#fn_def_smilestoformula" target="_blank">smilestoformula</a>
</td>
<td>
Convert SMILES string to Formula and other information
</td>
</tr>
<tr>
<td>
<a id="fn_sql_to_msp" class="fn_link" href="#fn_def_sql_to_msp" target="_blank">sql_to_msp</a>
</td>
<td>
Export SQL Database to a MSP NIST MS Format
</td>
</tr>
<tr>
<td>
<a id="fn_sqlite_auto_trigger" class="fn_link" href="#fn_def_sqlite_auto_trigger" target="_blank">sqlite_auto_trigger</a>
</td>
<td>
Create a basic SQL trigger for handling foreign key relationships
</td>
</tr>
<tr>
<td>
<a id="fn_sqlite_auto_view" class="fn_link" href="#fn_def_sqlite_auto_view" target="_blank">sqlite_auto_view</a>
</td>
<td>
Create a basic SQL view of a normalized table
</td>
</tr>
<tr>
<td>
<a id="fn_sqlite_parse_build" class="fn_link" href="#fn_def_sqlite_parse_build" target="_blank">sqlite_parse_build</a>
</td>
<td>
Parse SQL build statements
</td>
</tr>
<tr>
<td>
<a id="fn_sqlite_parse_import" class="fn_link" href="#fn_def_sqlite_parse_import" target="_blank">sqlite_parse_import</a>
</td>
<td>
Parse SQL import statements
</td>
</tr>
<tr>
<td>
<a id="fn_start_api" class="fn_link" href="#fn_def_start_api" target="_blank">start_api</a>
</td>
<td>
Start the plumber interface from a clean environment
</td>
</tr>
<tr>
<td>
<a id="fn_start_app" class="fn_link" href="#fn_def_start_app" target="_blank">start_app</a>
</td>
<td>
WIP Launch a shiny application
</td>
</tr>
<tr>
<td>
<a id="fn_start_rdkit" class="fn_link" href="#fn_def_start_rdkit" target="_blank">start_rdkit</a>
</td>
<td>
Start the RDKit integration
</td>
</tr>
<tr>
<td>
<a id="fn_summarize_check_fragments" class="fn_link" href="#fn_def_summarize_check_fragments" target="_blank">summarize_check_fragments</a>
</td>
<td>
Summarize results of check_fragments function
</td>
</tr>
<tr>
<td>
<a id="fn_support_info" class="fn_link" href="#fn_def_support_info" target="_blank">support_info</a>
</td>
<td>
R session information for support needs
</td>
</tr>
<tr>
<td>
<a id="fn_suspectlist_at_NIST" class="fn_link" href="#fn_def_suspectlist_at_NIST" target="_blank">suspectlist_at_NIST</a>
</td>
<td>
Open the NIST PDR entry for the current NIST PFAS suspect list
</td>
</tr>
<tr>
<td>
<a id="fn_table_msdata" class="fn_link" href="#fn_def_table_msdata" target="_blank">table_msdata</a>
</td>
<td>
Tabulate MS Data
</td>
</tr>
<tr>
<td>
<a id="fn_tack_on" class="fn_link" href="#fn_def_tack_on" target="_blank">tack_on</a>
</td>
<td>
Append additional named elements to a list
</td>
</tr>
<tr>
<td>
<a id="fn_tidy_comments" class="fn_link" href="#fn_def_tidy_comments" target="_blank">tidy_comments</a>
</td>
<td>
Tidy up table and field comments
</td>
</tr>
<tr>
<td>
<a id="fn_tidy_ms_spectra" class="fn_link" href="#fn_def_tidy_ms_spectra" target="_blank">tidy_ms_spectra</a>
</td>
<td>
Tidy Spectra
</td>
</tr>
<tr>
<td>
<a id="fn_tidy_spectra" class="fn_link" href="#fn_def_tidy_spectra" target="_blank">tidy_spectra</a>
</td>
<td>
Decompress Spectra
</td>
</tr>
<tr>
<td>
<a id="fn_unzip" class="fn_link" href="#fn_def_unzip" target="_blank">unzip</a>
</td>
<td>
Unzip binary data into vector
</td>
</tr>
<tr>
<td>
<a id="fn_update_all" class="fn_link" href="#fn_def_update_all" target="_blank">update_all</a>
</td>
<td>
Convenience function to rebuild all database related files
</td>
</tr>
<tr>
<td>
<a id="fn_update_data_sources" class="fn_link" href="#fn_def_update_data_sources" target="_blank">update_data_sources</a>
</td>
<td>
Dump current database contents
</td>
</tr>
<tr>
<td>
<a id="fn_update_env_from_file" class="fn_link" href="#fn_def_update_env_from_file" target="_blank">update_env_from_file</a>
</td>
<td>
Update a conda environment from a requirements file
</td>
</tr>
<tr>
<td>
<a id="fn_update_logger_settings" class="fn_link" href="#fn_def_update_logger_settings" target="_blank">update_logger_settings</a>
</td>
<td>
Update logger settings
</td>
</tr>
<tr>
<td>
<a id="fn_user_guide" class="fn_link" href="#fn_def_user_guide" target="_blank">user_guide</a>
</td>
<td>
Launch the User Guide for DIMSpec
</td>
</tr>
<tr>
<td>
<a id="fn_valid_file_format" class="fn_link" href="#fn_def_valid_file_format" target="_blank">valid_file_format</a>
</td>
<td>
Ensure files uploaded to a shiny app are of the required file type
</td>
</tr>
<tr>
<td>
<a id="fn_validate_casrns" class="fn_link" href="#fn_def_validate_casrns" target="_blank">validate_casrns</a>
</td>
<td>
Validate a CAS RN
</td>
</tr>
<tr>
<td>
<a id="fn_validate_column_names" class="fn_link" href="#fn_def_validate_column_names" target="_blank">validate_column_names</a>
</td>
<td>
Ensure database column presence
</td>
</tr>
<tr>
<td>
<a id="fn_validate_tables" class="fn_link" href="#fn_def_validate_tables" target="_blank">validate_tables</a>
</td>
<td>
Ensure database table presence
</td>
</tr>
<tr>
<td>
<a id="fn_verify_args" class="fn_link" href="#fn_def_verify_args" target="_blank">verify_args</a>
</td>
<td>
Verify arguments for a function
</td>
</tr>
<tr>
<td>
<a id="fn_verify_import_columns" class="fn_link" href="#fn_def_verify_import_columns" target="_blank">verify_import_columns</a>
</td>
<td>
Verify column names for import
</td>
</tr>
<tr>
<td>
<a id="fn_verify_import_requirements" class="fn_link" href="#fn_def_verify_import_requirements" target="_blank">verify_import_requirements</a>
</td>
<td>
Verify an import file’s properties
</td>
</tr>
<tr>
<td>
<a id="fn_with_help" class="fn_link" href="#fn_def_with_help" target="_blank">with_help</a>
</td>
<td>
Convenience application of codeadd_help using pipes directly in codeUI.R
</td>
</tr>
</table>
<hr/>
<table id="fn_def_activate_py_env" width="100%" summary="page for activate_py_env">
<tr>
<td>
activate_py_env
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Activate a python environment
</h2>
<h3>
Description
</h3>
<p>
Programmatically setting up python bindings is a bit more convoluted than in
a standard script. Given the name of a Python environment, it either (1)
checks the provided ‘env_name’ against currently installed environments and
binds the current session to it if found OR (2) installs a new environment
with [<a href="appendix-function-reference.html#fn_def_create_py_env">create_py_env</a>] and activates it by calling itself.
</p>
<h3>
Usage
</h3>
<pre>
activate_py_env(
  env_name = NULL,
  required_libraries = NULL,
  required_modules = NULL,
  log_ns = NULL,
  conda_path = NULL
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>env_name</code>
</td>
<td>
<p>
CHR scalar of a python environment name to bind. The default,
NULL, will look for an environment variable named ‘PYENV_NAME’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>required_libraries</code>
</td>
<td>
<p>
CHR vector of python libraries to include in the
environment, if building a new environment. Ignored if ‘env_name’ is an
existing environment. The default, NULL, will look for an environment
variable named ‘PYENV_LIBRARIES’.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>required_modules</code>
</td>
<td>
<p>
CHR vector of modules to be checked for availability
once the environment is activated. The default, NULL, will look for an
environment variable named ‘PYENV_MODULES’.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use, if any.
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
It is recommended that project variables in ‘../config/env_py.R’ and
‘../config/env_glob.txt’ be used to control most of the behavior of this
function. This works with both virtual and conda environments, though
creation of new environments is done in conda.
</p>
<h3>
Value
</h3>
<p>
LGL scalar of whether or not activate was successful
</p>
<h3>
Note
</h3>
<p>
Where parameters are NULL, [<a href="appendix-function-reference.html#fn_def_rectify_null_from_env">rectify_null_from_env</a>] will be used to get
a value associated with it if they exist.
</p>
<hr/>
<table id="fn_def_active_connection" width="100%" summary="page for active_connection">
<tr>
<td>
active_connection
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Is a connection object still available?
</h2>
<h3>
Description
</h3>
<p>
This is a thin wrapper for [DBI::dbIsValid] with some error logging.
</p>
<h3>
Usage
</h3>
<pre>
active_connection(db_conn = con)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default “con”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LGL scalar indicating whether the database is available
</p>
<hr/>
<table id="fn_def_add_help" width="100%" summary="page for add_help">
<tr>
<td>
add_help
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Attach a superscript icon with a bsTooltip to an HTML element
</h2>
<h3>
Description
</h3>
<p>
Attach a superscript icon with a bsTooltip to an HTML element
</p>
<h3>
Usage
</h3>
<pre>
add_help(
  id,
  tooltip,
  icon_name = "question",
  size = "xs",
  icon_class = "info-tooltip primary",
  ...
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>id</code>
</td>
<td>
<p>
CHR scalar of the HTML ID to which to append the icon
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>tooltip</code>
</td>
<td>
<p>
CHR scalar of the tooltip text
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>icon_name</code>
</td>
<td>
<p>
CHR scalar of the icon name, which must be understandable by
the ‘shiny::icon’ function; e.g. a font-awesome icon name (default:
“question”).
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>size</code>
</td>
<td>
<p>
CHR scalar of the general icon size as understandable by the
font-awesome library (default: “xs”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>icon_class</code>
</td>
<td>
<p>
CHR vector of classes to apply to the ‘&lt;sup&gt;’ container,
as defined in the current CSS (default: “info-tooltip primary”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>…</code>
</td>
<td>
<p>
Other named arguments to be passed to ‘shinyBS:bsTooltip’
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LIST of HTML tags for the desired help icon and its tooltip
</p>
<h3>
Note
</h3>
<p>
<p>The following CSS is typically defined to go with this.
.info-tooltip
opacity: 30
transition: opacity .25s;</p>
<p>.info-tooltip:hover
opacity: 100</p>
<p>.primary
color: #3c8dbc;</p>
</p>
<h3>
Examples
</h3>
<pre>
add_help("example", "a tooltip")

</pre>
<hr/>
<table id="fn_def_add_normalization_value" width="100%" summary="page for add_normalization_value">
<tr>
<td>
add_normalization_value
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Add value(s) to a normalization table
</h2>
<h3>
Description
</h3>
<p>
One of the most common database operations is to look up or add a value in a
normalization table. This utility function adds a single value and returns
its associated id by using [<a href="appendix-function-reference.html#fn_def_build_db_action">build_db_action</a>]. This is only suitable for a
single value. If you need to bulk add multiple new values, use this with
something like [lapply].
</p>
<h3>
Usage
</h3>
<pre>
add_normalization_value("norm_table", name = "new value", acronym = "NV")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>db_table</code>
</td>
<td>
<p>
CHR scalar of the normalization table’s name
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default “con”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use during execution
(default: “db”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>id_column</code>
</td>
<td>
<p>
CHR scalar of the column to use as the primary key
identifier for ‘db_table’ (default: “id”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>database_map</code>
</td>
<td>
<p>
LIST of the database entity relationship map, typically
from calling [<a href="appendix-function-reference.html#fn_def_er_map">er_map</a>]. If NULL (default) the object “db_map” will be
searched for and used by default, otherwise it will be created with
[<a href="appendix-function-reference.html#fn_def_er_map">er_map</a>]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>…</code>
</td>
<td>
<p>
CHR vector of additional named arguments to be added; names not
appearing in the referenced table will be ignored
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
NULL if unable to add the values, INT scalar of the new ID otherwise
</p>
<hr/>
<table id="fn_def_add_or_get_id" width="100%" summary="page for add_or_get_id">
<tr>
<td>
add_or_get_id
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Utility function to add a record
</h2>
<h3>
Description
</h3>
<p>
Checks a table in the attached SQL connection for a primary key ID matching
the provided ‘values’ and returns the ID. If none exists, adds a record and
returns the resulting ID if successful. Values should be provided as a named
vector of the values to add. No data coercion is performed, relying almost
entirely on the database schema or preprocessing to ensure data integrity.
</p>
<h3>
Usage
</h3>
<pre>
add_or_get_id(
  db_table,
  values,
  db_conn = con,
  ensure_unique = TRUE,
  require_all = TRUE,
  ignore = FALSE,
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>db_table</code>
</td>
<td>
<p>
CHR scalar name of the database table being modified
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>values</code>
</td>
<td>
<p>
named vector of the values being added, passed to
[<a href="appendix-function-reference.html#fn_def_build_db_action">build_db_action</a>]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ensure_unique</code>
</td>
<td>
<p>
LGL scalar of whether or not to first check that the
values provided form a new unique record (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>require_all</code>
</td>
<td>
<p>
LGL scalar of whether to require all columns (except the
assumed primary key column of “id”) or only those defined as “NOT NULL”
(default: TRUE requires the presence of all columns in the table)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ignore</code>
</td>
<td>
<p>
LGL scalar on whether to treat the insert try as an “INSERT OR
IGNORE” SQL statement (default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use (default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
Provided values are checked agaisnt required columns in the table using
[<a href="appendix-function-reference.html#fn_def_verify_import_columns">verify_import_columns</a>].
</p>
<p>
Operations to add the record and get the resulting ID are both performed with
[<a href="appendix-function-reference.html#fn_def_build_db_action">build_db_action</a>] and are performed virtually back to back with the
latest-added ID being given preference in cases where added values may match
multiple extant records.
</p>
<h3>
Value
</h3>
<p>
INT scalar of the record identifier
</p>
<h3>
Note
</h3>
<p>
If this is used in high volume/traffic applications, ID conflicts may
occur if the timing is such that another record containing identical values
is added before the call getting the ID completes.
</p>
<hr/>
<table id="fn_def_add_rdkit_aliases" width="100%" summary="page for add_rdkit_aliases">
<tr>
<td>
add_rdkit_aliases
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Add fragment or compound aliases generated by RDKit functions
</h2>
<h3>
Description
</h3>
<p>
Aliases are stored for both compounds and fragments within the database to
facilitate search and unambiguous identification. Given one molecular
structure notation (SMILES is preferred), other machine-readable expressions
can be generated quickly. Requested aliases as provided to ‘rdkit_aliases’
will be prefixed by ‘mol_to_prefix’ and checked against the namespace of
available functions in RDKit and the correct functions automatically
assigned.
</p>
<h3>
Usage
</h3>
<pre>
add_rdkit_aliases(
  identifiers,
  alias_category = c("compounds", "fragments"),
  compound_aliases_table = "compound_aliases",
  fragment_aliases_table = "fragment_aliases",
  inchi_prefix = "InChI=1S/",
  rdkit_name = ifelse(exists("PYENV_NAME"), PYENV_NAME, "rdkit"),
  rdkit_ref = ifelse(exists("PYENV_REF"), PYENV_REF, "rdk"),
  rdkit_ns = "rdk",
  rdkit_make_if_not = TRUE,
  rdkit_aliases = c("inchi", "inchikey"),
  mol_to_prefix = "MolTo",
  mol_from_prefix = "MolFrom",
  type = "smiles",
  as_object = TRUE,
  db_conn = con,
  log_ns = "rdk"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>identifiers</code>
</td>
<td>
<p>
CHR vector of machine readable notations in ‘type’ format
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>alias_category</code>
</td>
<td>
<p>
CHR scalar, one of “compounds” or “fragments” to
determine where in the database to store the resulting aliases (default:
“compounds”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>compound_aliases_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding
compound aliases (default: “compound_aliases”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fragment_aliases_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding
fragment aliases (default: “fragment_aliases”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>inchi_prefix</code>
</td>
<td>
<p>
CHR scalar prefix for the InChI code to use, if InChI is
requested as part of ‘rdkit_aliases’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>rdkit_name</code>
</td>
<td>
<p>
CHR scalar name of the python environment at which RDKit is
installed (default: is the session variable PYENV_NAME or “rdkit”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>rdkit_ref</code>
</td>
<td>
<p>
CHR scalar name of the R pointer object to RDKit (default:
is the session variable PYENV_REF or “rdk”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>rdkit_ns</code>
</td>
<td>
<p>
CHR scalar name of the logging namespace to use (default:
“rdk”); will be ignored if logging is off
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>rdkit_make_if_not</code>
</td>
<td>
<p>
LGL scalar of whether to create an RDKit environment
if it does not exist (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>rdkit_aliases</code>
</td>
<td>
<p>
CHR vector of machine-readable aliases to generate,
which must be recognizeable as names in the RDKit namespace when prefixed
by ‘mol_to_prefix’ (default: c(“inchi”, “inchikey”)); these are not case
sensitive
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>mol_to_prefix</code>
</td>
<td>
<p>
CHR scalar of the prefix identifying alias creation
functions, which must be recognizeable as names in the RDKit namespace when
suffixed by ‘rdkit_aliases’ (default: “MolTo”); this is not case sensitive
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>mol_from_prefix</code>
</td>
<td>
<p>
CHR scalar of the prefix identifying molecule
expression creation functions, which must be recognizeable as names in the
RDKit namespace when suffixed by ‘type’ (default: “MolFrom”); this is not
case sensitive
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>type</code>
</td>
<td>
<p>
CHR scalar indicating the type of ‘identifiers’ to be converted
to molecule notation (default: “smiles”); this is not case sensitive
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>as_object</code>
</td>
<td>
<p>
LGL scalar indicating whether to return the alias list to
the session as an object (default: TRUE) or write aliases to the database
(FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use (default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
If ‘as_object’ == TRUE, a data.frame of unpacked spectra, otherwise
no return and a database insertion will be performed
</p>
<h3>
Note
</h3>
<p>
It is not recommended to change the defaults here unless you are
familiar with the naming conventions of RDKit.
</p>
<p>
Requires both INFORMATICS and USE_RDKIT set to TRUE in the session and
a valid installation of the RDKIT python environment to function.
</p>
<p>
See the <a href="https://rdkit.org/docs/index.html">RDKit Documentation</a> for
more details.
</p>
<hr/>
<table id="fn_def_adduct_formula" width="100%" summary="page for adduct_formula">
<tr>
<td>
adduct_formula
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Add Adduct to Formula
</h2>
<h3>
Description
</h3>
<p>
Add Adduct to Formula
</p>
<h3>
Usage
</h3>
<pre>
adduct_formula(elementalformula, adduct = "+H")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>elementalformula</code>
</td>
<td>
<p>
character string elemental formula
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>adduct</code>
</td>
<td>
<p>
character string adduct state to add to the elemental formula, must contain an element, options are ‘+H’, ‘-H’, ‘+Na’, ‘+K’
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
character string containing elemental formula with adduct
</p>
<h3>
Examples
</h3>
<pre>
adduct_formula("C2H5O", adduct = "+H")
</pre>
<hr/>
<table id="fn_def_api_endpoint" width="100%" summary="page for api_endpoint">
<tr>
<td>
api_endpoint
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Build an API endpoint programmatically
</h2>
<h3>
Description
</h3>
<p>
This is a convenience function intended to support plumber endpoints. It only
assists in the construction (and execution if ‘execute’ == TRUE) of
endpoints. Endpoints must still be understood. Validity checking, execution,
and opening in a web browser are supported. Invalid endpoints will not be
executed or opened for viewing.
</p>
<h3>
Usage
</h3>
<pre>
api_endpoint(
  path,
  ...,
  server_addr = PLUMBER_URL,
  check_valid = TRUE,
  execute = TRUE,
  open_in_browser = FALSE,
  raw_result = FALSE,
  max_pings = 20L,
  return_type = c("text", "raw", "parsed"),
  return_format = c("vector", "data.frame", "list")
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>path</code>
</td>
<td>
<p>
CHR scalar of the endpoint path.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>…</code>
</td>
<td>
<p>
Additional named parameters added to the endpoint, most typically
the query portion. If only one is provided, it can remain unnamed and a
query is assumed. If more than one is provided, all must be named. Named
elements must be components of the return from [httr::parse_url] (see
<a href="https://tools.ietf.org/html/rfc3986" class="uri">https://tools.ietf.org/html/rfc3986</a>) for details of the parsing algorithm;
unrecognized elements will be ignored.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>server_addr</code>
</td>
<td>
<p>
CHR scalar uniform resource locator (URL) address of an
API server (e.g. “<a href="https://myapi.com:8080" class="uri">https://myapi.com:8080</a>”) (defaults to the current
environment variable “PLUMBER_URL”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>check_valid</code>
</td>
<td>
<p>
LGL scalar on whether or not to first check that an
endpoint returns a valid status code (200-299) (default: TRUE).
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>execute</code>
</td>
<td>
<p>
LGL scalar of whether or not to execute the constructed
endpoint and return the result; will be defaulted to FALSE if ‘check_valid’
== TRUE and the endpoint returns anything other than a valid status code.
(default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>open_in_browser</code>
</td>
<td>
<p>
LGL scalar of whether or not to open the resulting
endpoint in the system’s default browser; will be defaulted to FALSE if
‘check_valid’ == TRUE and the endpoint returns anything other than a valid
status code. (default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>max_pings</code>
</td>
<td>
<p>
INT scalar maximum number of pings to try before timeout if
using endpoint “_ping”; this is only used for endpoint “_ping” (default:
20)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>return_type</code>
</td>
<td>
<p>
CHR scalar on which return type to use, which must be one
of “text”, “raw”, or “parsed” which will be used to read the content of the
response item (default: “text”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>return_format</code>
</td>
<td>
<p>
CHR scalar on which form to return data, which must be
one of “vector”, “data.frame”, or “list” (default: “vector” to support
primarily single value responses)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
CHR scalar of the constructed endpoint, with messages regarding
status checks, return from the endpoint (typically JSON) if valid and
‘execute’ == TRUE, or NONE if ‘open_in_browser’ == TRUE
</p>
<h3>
Note
</h3>
<p>
Special support is provided for the way in which the NIST Public Data
Repository treats URL fragments
</p>
<p>
This only support [httr::GET] requests.
</p>
<h3>
Examples
</h3>
<pre>
api_endpoint("https://www.google.com/search", list(q = "something"), open_in_browser = TRUE)
api_endpoint("https://www.google.com/search", query = list(q = "NIST Public Data Repository"), open_in_browser = TRUE)
</pre>
<hr/>
<table id="fn_def_api_open_doc" width="100%" summary="page for api_open_doc">
<tr>
<td>
api_open_doc
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Open Swagger API documentation
</h2>
<h3>
Description
</h3>
<p>
This will launch the Swagger UI in a browser tab. The URL suffix “<strong>docs</strong>”
will be automatically added if not part of the host URL accepted as ‘url’.
</p>
<h3>
Usage
</h3>
<pre>
api_open_doc(url = PLUMBER_URL)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>url</code>
</td>
<td>
<p>
CHR URL/URI of the plumber documentation host (default:
environment variable “PLUMBER_URL”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, opens a browser to the requested URL
</p>
<hr/>
<table id="fn_def_api_reload" width="100%" summary="page for api_reload">
<tr>
<td>
api_reload
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Reloads the plumber API
</h2>
<h3>
Description
</h3>
<p>
Depending on system architecture, the plumber service may take some time to
spin up and spin down. If ‘background’ is TRUE, this may mean the calling R
thread runs ahead of the background process resulting in unexpected behavior
(e.g. newly defined endpoints not being available), effectively binding it to
the prior iteration. If the API does not appear to be reloading properly, it
may be necessary to manually kill the process controlling it through your OS
and to call this function again.
</p>
<h3>
Usage
</h3>
<pre>
api_reload(
  pr = NULL,
  background = TRUE,
  plumber_file = NULL,
  on_host = NULL,
  on_port = NULL,
  log_ns = "api"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>pr</code>
</td>
<td>
<p>
CHR scalar name of the plumber service object, typically only
created as a background observer from [callr::r_bg] as a result of calling
[api_reload] (default: NULL gets the environment setting for
PLUMBER_OBJ_NAME)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>background</code>
</td>
<td>
<p>
LGL scalar of whether to load the plumber server as a
background service (default: TRUE); set to FALSE for testing
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>plumber_file</code>
</td>
<td>
<p>
CHR scalar of the path to a plumber API to launch
(default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>on_host</code>
</td>
<td>
<p>
CHR scalar of the host IP address (default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>on_port</code>
</td>
<td>
<p>
CHR or INT scalar of the host port to use (default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar namespace to use for logging (default: “api”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
Launches the plumber API service on your local machine and returns
the URL on which it can be accessed as a CHR scalar
</p>
<hr/>
<table id="fn_def_api_start" width="100%" summary="page for api_start">
<tr>
<td>
api_start
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Start the plumber API
</h2>
<h3>
Description
</h3>
<p>
This is a wrapper to [plumber::pr_run] pointing to a project’s opinionated
plumber settings with some error trapping. The host, port, and plumber file
are set in the “config/env_R.R” location as PLUMBER_HOST, PLUMBER_PORT, and
PLUMBER_FILE respectively.
</p>
<h3>
Usage
</h3>
<pre>
api_start(plumber_file = NULL, on_host = NULL, on_port = NULL)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>plumber_file</code>
</td>
<td>
<p>
CHR scalar of the path to a plumber API to launch
(default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>on_host</code>
</td>
<td>
<p>
CHR scalar of the host IP address (default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>on_port</code>
</td>
<td>
<p>
CHR or INT scalar of the host port to use (default: NULL)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LGL scalar with success status
</p>
<h3>
Note
</h3>
<p>
If either of ‘on_host’ or ‘on_port’ are NULL they will default first to
any existing environment values of PLUMBER_HOST and PLUMBER_PORT, then to
getOption(“plumber.host”, “127.0.0.1”) and getOption(“plumber.port”, 8080)
</p>
<p>
This will fail if the requested port is in use.
</p>
<hr/>
<table id="fn_def_api_stop" width="100%" summary="page for api_stop">
<tr>
<td>
api_stop
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Stop the plumber API
</h2>
<h3>
Description
</h3>
<p>
Stop the plumber API
</p>
<h3>
Usage
</h3>
<pre>
api_stop(pr = NULL, flush = TRUE, db_conn = "con", remove_service_obj = TRUE)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>pr</code>
</td>
<td>
<p>
CHR scalar name of the plumber service object, typically only
created as a background observer from [callr::r_bg] as a result of calling
[<a href="appendix-function-reference.html#fn_def_api_reload">api_reload</a>] (default: NULL gets the environment setting for
PLUMBER_OBJ_NAME)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>flush</code>
</td>
<td>
<p>
LGL scalar of whether to disconnect and reconnect to a database
connection named as ‘db_conn’ (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
CHR scalar of the connection object name (default: “con”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>remove_service_obj</code>
</td>
<td>
<p>
LGL scalar of whether to remove the reference to
‘pr’ from the current global environment (default: TRUE)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, stops the plumber server
</p>
<h3>
Note
</h3>
<p>
This will also kill and restart the connection object if ‘flush’ is
TRUE to release connections with certain configurations such as SQLite in
write ahead log mode.
</p>
<p>
This function assumes the object referenced by name ‘pr’ exists in the
global environment, and ‘remove_service_object’ will only remove it from
.GlobalEnv.
</p>
<hr/>
<table id="fn_def_append_icon_to" width="100%" summary="page for append_icon_to">
<tr>
<td>
append_icon_to
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Create the JS to append an icon to an HTML element by its ID
</h2>
<h3>
Description
</h3>
<p>
Create the JS to append an icon to an HTML element by its ID
</p>
<h3>
Usage
</h3>
<pre>
append_icon_to(id, icon_name, icon_class = NULL)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>id</code>
</td>
<td>
<p>
CHR scalar of the HTML ID to which to append an icon
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>icon_name</code>
</td>
<td>
<p>
CHR scalar of the icon name, which must be understandable by
the ‘shiny::icon’ function; e.g. a font-awesome icon name.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>icon_class</code>
</td>
<td>
<p>
CHR vector of classes to apply
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
CHR scalar suitable to execute with ‘shinyjs::runJS’
</p>
<h3>
Examples
</h3>
<pre>
append_icon_to("example", "r-project", "fa-3x")

</pre>
<hr/>
<table id="fn_def_bootstrap_compare_ms" width="100%" summary="page for bootstrap_compare_ms">
<tr>
<td>
bootstrap_compare_ms
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Calculate dot product match score using bootstrap data
</h2>
<h3>
Description
</h3>
<p>
Calculates a the match score (based on dot product) of the two uncertainty mass spectra.
To generate a distribution of match scores using the uncertainty of the two mass spectra,
bootstrapped data (using ‘rnorm’ for now)
</p>
<h3>
Usage
</h3>
<pre>
bootstrap_compare_ms(
  ms1,
  ms2,
  error = c(5, 5),
  minerror = c(0.002, 0.002),
  m = 1,
  n = 0.5,
  runs = 10000
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>ms1, ms2</code>
</td>
<td>
<p>
the uncertainty mass spectra from function ‘get_ums’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>error</code>
</td>
<td>
<p>
a vector of the respective mass error (in ppm) for each mass spectrum or a single vector representing the mass error for all m/z values
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>minerror</code>
</td>
<td>
<p>
a two component vector of the respective minimum mass error (in Da) for each mass spectrum or a single value representing the minimum mass error of all m/z values
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>m, n</code>
</td>
<td>
<p>
weighting values for mass (m) and intensity (n)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>runs</code>
</td>
<td>
</td>
</tr>
</table>
<hr/>
<table id="fn_def_build_db" width="100%" summary="page for build_db">
<tr>
<td>
build_db
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Build or rebuild the database from scratch
</h2>
<h3>
Description
</h3>
<p>
This function will build or rebuild the NIST HRAMS database structure from
scratch, removing the existing instance. By default, most parameters are set
in the environment (at “./config/env_glob.txt”) but any values can be passed
directly. This can be used to quickly spin up multiple copies with a clean
slate using different build files, data files, or return to the last stable
release.
</p>
<h3>
Usage
</h3>
<pre>
build_db(db = "test_db.sqlite", db_conn_name = "test_conn")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>db</code>
</td>
<td>
<p>
CHR scalar of the database name (default: session value DB_NAME)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>build_from</code>
</td>
<td>
<p>
CHR scalar of a SQL build script to use (default:
environment value DB_BUILD_FILE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>populate</code>
</td>
<td>
<p>
LGL scalar of whether to populate with data from the file in
‘populate_with’ (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>populate_with</code>
</td>
<td>
<p>
CHR scalar for the populate script (e.g.
“populate_demo.sql”) to during after the build is complete; (default:
session value DB_DATA); ignored if ‘populate = FALSE’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>archive</code>
</td>
<td>
<p>
LGL scalar of whether to create an archive of the current
database (if it exists) matching the name supplied in argument ‘db’
(default: FALSE), passed to [‘remove_db()’]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>sqlite_cli</code>
</td>
<td>
<p>
CHR scalar to use to look for installed sqlite3 CLI tools
in the current system environment (default: session value SQLITE_CLI)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>connect</code>
</td>
<td>
<p>
LGL scalar of whether or not to connect to the rebuilt
database in the global environment as object ’con“ (default: FALSE)
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
If sqlite3 and its command line interface are available on your platform,
that will be used (preferred method) but, if not, this function will read in
all the necessary files to directly create it using shell commands. The shell
method may not be universally applicable to certain compute environments or
may require elevated permissions.
</p>
<h3>
Value
</h3>
<p>
None, check console for details
</p>
<hr/>
<table id="fn_def_build_db_action" width="100%" summary="page for build_db_action">
<tr>
<td>
build_db_action
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Build an escaped SQL query
</h2>
<h3>
Description
</h3>
<p>
In most cases, issuing basic SQL queries is made easy by tidyverse compliant
functions such as [dplyr::tbl]. Full interaction with an SQLite database is a
bit more complicated and typically requires [DBI::dbExecute] and writing SQL
directly; several helpers exist for that (e.g. [glue::glue_sql]) but aren’t
as friendly or straight forward when writing more complicated actions, and
still require directly writing SQL equivalents, routing through
[DBI::dbQuoteIdentifier] and [DBI::dbQuoteLiteral] to prevent SQL injection
attacks.
</p>
<h3>
Usage
</h3>
<pre>
build_db_action("insert", "table", values = list(col1 = "a", col2 = 2,
  col3 = "describe"), execute = FALSE) build_db_action("insert", "table",
  values = list(col1 = "a", col2 = 2, col3 = "describe"))
  
  build_db_action("get_id", "table", match_criteria = list(id = 2))
  
  build_db_action("delete", "table", match_criteria = list(id = 2))
  
  build_db_action("select", "table", columns = c("col1", "col2", "col3"),
  match_criteria = list(id = 2)) build_db_action("select", "table",
  match_criteria = list(sample_name = "sample 123"))
  
  build_db_action("select", "table", match_criteria = list(sample_name =
  list(value = "sample 123", exclude = TRUE)) build_db_action("select",
  "table", match_criteria = list(sample_name = "sample 123",
  sample_contributor = "Smith"), and_or = "AND", limit = 5)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>action</code>
</td>
<td>
<p>
CHR scalar, of one “INSERT”, “UPDATE”, “SELECT”, “GET_ID”, or
“DELETE”
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>table_name</code>
</td>
<td>
<p>
CHR scalar of the table name to which this query applies
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>column_names</code>
</td>
<td>
<p>
CHR vector of column names to include (default NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>values</code>
</td>
<td>
<p>
LIST of CHR vectors with values to INSERT or UPDATE (default
NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>match_criteria</code>
</td>
<td>
<p>
LIST of matching criteria with names matching columns
against which to apply. In the simplest case, a direct value is given to
the name (e.g. ‘list(last_name = “Smith”)’) for single matches. All match
criteria must be their own list item. Values can also be provided as a
nested list for more complicated WHERE clauses with names ‘values’,
‘exclude’, and ‘like’ that will be recognized. ‘values’ should be the
actual search criteria, and if a vector of length greater than one is
specified, the WHERE clause becomes an IN clause. ‘exclude’ (LGL scalar)
determines whether to apply the NOT operator. ‘like’ (LGL scalar)
determines whether this is an equality, list, or similarity. To reverse the
example above by issuing a NOT statement, use ‘list(last_name = list(values
= “Smith”, exclude = TRUE))’, or to look for all records LIKE (or NOT LIKE)
“Smith”, set this as ‘list(last_name = list(values = “Smith”, exclude =
FALSE, like = TRUE))’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>case_sensitive</code>
</td>
<td>
<p>
LGL scalar of whether to match on a case sensitive
basis (the default TRUE searches for values as-provided) or whether to
coerce value matches by upper, lower, sentence, and title case matches
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>and_or</code>
</td>
<td>
<p>
LGL scalar of whether to use “AND” or “OR” for multiple
criteria, which will be used to combine them all. More complicated WHERE
clauses (including a mixture of AND and OR usage) should be built directly.
(default: “OR”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>limit</code>
</td>
<td>
<p>
INT scalar of the maximum number of rows to return (default
NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>group_by</code>
</td>
<td>
<p>
CHR vector of columns by which to group (default NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>order_by</code>
</td>
<td>
<p>
named CHR vector of columns by which to order, with names
matching columns and values indicating whether to sort ascending (default
NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>distinct</code>
</td>
<td>
<p>
LGL scalar of whether or not to apply the DISTINCT clause to
all match criteria (default FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>get_all_columns</code>
</td>
<td>
<p>
LGL scalar of whether to return all columns; will be
set to TRUE automatically if no column names are provided (default FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>execute</code>
</td>
<td>
<p>
LGL scalar of whether or not to immediately execute the build
query statement (default TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>single_column_as_vector</code>
</td>
<td>
<p>
LGL scalar of whether to return results as a
vector if they consist of only a single column (default TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use during execution
(default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
This function is intended to ease that by taking care of most of the
associated logic and enabling routing through other functions, or picking up
arguments from within other function calls.
</p>
<h3>
Value
</h3>
<p>
CHR scalar of the constructed query
</p>
<hr/>
<table id="fn_def_build_triggers" width="100%" summary="page for build_triggers">
<tr>
<td>
build_triggers
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Build pairs of INSERT/UPDATE triggers to resolve foreign key relationships
</h2>
<h3>
Description
</h3>
<p>
When building schema by script, it is often handy to enforce certain
behaviors on database transactions involving foreign keys, especially in
SQLite. Given a properly structured list object describing the mappings
between tables in a schema (e.g. one deriving from [<a href="appendix-function-reference.html#fn_def_er_map">er_map</a>]), this function
will parse those for foreign key relationships.
</p>
<h3>
Usage
</h3>
<pre>
build_triggers(er_map(db_conn = con))
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>db_map</code>
</td>
<td>
<p>
LIST object containing descriptions of table mapping in an
opinionated manner, generally generated by [<a href="appendix-function-reference.html#fn_def_er_map">er_map</a>]. The expectation is a
list of tables, with references in SQL form enumerated in a child element
with a name matching ‘references_in’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>references_in</code>
</td>
<td>
<p>
CHR scalar naming the child element containing SQL
references statements of the form “fk_column REFERENCES table(pk_column)”
(default: “references” is provided by [<a href="appendix-function-reference.html#fn_def_er_map">er_map</a>])
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>create_insert_trigger</code>
</td>
<td>
<p>
LGL scalar indicating whether to build an insert
trigger for each table (default: TRUE).
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>create_update_trigger</code>
</td>
<td>
<p>
LGL scalar indicating whether to build an update
trigger for each table (default: FALSE).
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>save_to_file</code>
</td>
<td>
<p>
CHR scalar of a file in which to write the output, if any
(default: NULL will return the resulting object to the R session)
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
Primarily, this requires a list object referring to tables that contains in
each element a child element with the name provided in ‘references_in’. The
pre-pass parsing function [<a href="appendix-function-reference.html#fn_def_get_fkpk_relationships">get_fkpk_relationships</a>] is used to pull references
from
the full map is used.
</p>
<h3>
Value
</h3>
<p>
LIST object containing one element for each table in ‘db_map’
containing foreign key references, with one child
</p>
<h3>
Note
</h3>
<p>
Tables in ‘db_map’ that do not contain foreign key relationships will
be dropped from the output list.
</p>
<p>
This is largely a convenience function to programmatically apply
[make_sql_triggers] to an entire schema. To skip tables with defined
foreign key relationships for which triggers are undesirable, remove those
tables from ‘db_map’ prior to calling this function.
</p>
<hr/>
<table id="fn_def_build_views" width="100%" summary="page for build_views">
<tr>
<td>
build_views
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Build SQL to create views on normalized tables in SQLite
</h2>
<h3>
Description
</h3>
<p>
Build SQL to create views on normalized tables in SQLite
</p>
<h3>
Usage
</h3>
<pre>
build_views(db_map = er_map(con), dictionary = data_dictionary(con))
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>db_map</code>
</td>
<td>
<p>
LIST object containing descriptions of table mapping in an
opinionated manner, generally generated by [<a href="appendix-function-reference.html#fn_def_er_map">er_map</a>]. The expectation is a
list of tables, with references in SQL form enumerated in a child element
with a name matching ‘references_in’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>references_in</code>
</td>
<td>
<p>
CHR scalar naming the child element containing SQL
references statements of the form “fk_column REFERENCES table(pk_column)”
(default: “references” is provided by [<a href="appendix-function-reference.html#fn_def_er_map">er_map</a>])
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>dictionary</code>
</td>
<td>
<p>
LIST object containing the schema dictionary produced by
[<a href="appendix-function-reference.html#fn_def_data_dictionary">data_dictionary</a>] fully describing table entities
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>drop_if_exists</code>
</td>
<td>
<p>
LGL scalar indicating whether to include a “DROP VIEW”
prefix for the generated view statement; as this has an impact on schema,
no default is set
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>save_to_file</code>
</td>
<td>
<p>
CHR scalar name of a file path to save generated SQL
(default: NULL will return a list object to the R session)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>append</code>
</td>
<td>
<p>
LGL scalar on whether to appead to ‘save_to_file’ (default:
FALSE)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LIST if ‘save_to_file = FALSE’ or none
</p>
<hr/>
<table id="fn_def_calculate.monoisotope" width="100%" summary="page for calculate.monoisotope">
<tr>
<td>
calculate.monoisotope
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Calculate the monoisotopic mass of an elemental formula list
</h2>
<h3>
Description
</h3>
<p>
Calculate the monoisotopic mass of an elemental formula list
</p>
<h3>
Usage
</h3>
<pre>
calculate.monoisotope(
  elementlist,
  exactmasses = NULL,
  adduct = "neutral",
  db_conn = "con"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>elementlist</code>
</td>
<td>
<p>
list of elemental formula from ‘extract.elements’ function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>exactmasses</code>
</td>
<td>
<p>
list of exact masses of elements
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>adduct</code>
</td>
<td>
<p>
character string adduct/charge state to add to the elemental formula, options are ‘neutral’, ‘+H’, ‘-H’, ‘+Na’, ‘+K’, ‘+’, ‘-’, ‘-radical’, ‘+radical’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
database connection object, either a CHR scalar name (default: “con”) or the connection object itself (preferred)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
numeric monoisotopic exact mass
</p>
<h3>
Examples
</h3>
<pre>
elementlist &lt;- extract.elements("C2H5O")
calculate.monoisotope(elementalist, adduct = "neutral")

</pre>
<hr/>
<table id="fn_def_check_for_value" width="100%" summary="page for check_for_value">
<tr>
<td>
check_for_value
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Check for a value in a database table
</h2>
<h3>
Description
</h3>
<p>
This convenience function simply checks whether a value exists in the
distinct values of a given column. Only one column may be searched at a time;
serialize it in other code to check multiple columns. It leverages the
flexibility of [<a href="appendix-function-reference.html#fn_def_build_db_action">build_db_action</a>] to do the searching. The ‘values’ parameter
will be fed directly and can accept the nested list structure defined in
[<a href="appendix-function-reference.html#fn_def_clause_where">clause_where</a>] for exclusions and like clauses.
</p>
<h3>
Usage
</h3>
<pre>
con2 &lt;- DBI::dbConnect(RSQLite::SQLite(), ":memory:")
alphabet &lt;- dplyr::tibble(lower = letters, upper = LETTERS)
dplyr::copy_to(con2, alphabet)
check_for_value("A", "alphabet", "upper", db_conn = con2)
check_for_value("A", "alphabet", "lower", db_conn = con2)
check_for_value(letters[1:10], "alphabet", "lower", db_conn = con2)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>values</code>
</td>
<td>
<p>
CHR vector of the values to search
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_table</code>
</td>
<td>
<p>
CHR scalar of the database table to search
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_column</code>
</td>
<td>
<p>
CHR scalar of the column to search
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>case_sensitive</code>
</td>
<td>
<p>
LGL scalar of whether to match on a case sensitive
basis (the default TRUE searches for values as-provided) or whether to
coerce value matches by upper, lower, sentence, and title case matches
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fuzzy</code>
</td>
<td>
<p>
LGL scalar of whether to do a “fuzzy” match in the sense that
values provided are wrapped in an SQL “LIKE ’
the ‘case_sensitive’ setting if TRUE (default: FALSE).
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LIST of length 1-2 containing “exists” as a LGL scalar for whether
the values were found, and “values” containing the result of the database
call, a data.frame object containing matching rows or NULL if exists ==
FALSE.
</p>
<hr/>
<table id="fn_def_check_fragments" width="100%" summary="page for check_fragments">
<tr>
<td>
check_fragments
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Determine number of matching fragments between unknown mass spectrum and specific peaks
</h2>
<h3>
Description
</h3>
<p>
Determine number of matching fragments between unknown mass spectrum and specific peaks
</p>
<h3>
Usage
</h3>
<pre>
check_fragments(con, ums, peakid, masserror = 5, minerror = 0.001)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>con</code>
</td>
<td>
<p>
SQLite database connection
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ums</code>
</td>
<td>
<p>
uncertainty mass spectrum of unknown compound
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peakid</code>
</td>
<td>
<p>
integer vector of primary keys for peaks table
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>masserror</code>
</td>
<td>
<p>
numeric relative mass error (ppm)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>minerror</code>
</td>
<td>
<p>
numeric minimum mass error (Da)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
table of fragments and TRUE/FALSE for if the fragment is within the unknown mass spectrum
</p>
<hr/>
<table id="fn_def_check_isotopedist" width="100%" summary="page for check_isotopedist">
<tr>
<td>
check_isotopedist
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Compare Isotopic Pattern to simulated pattern
</h2>
<h3>
Description
</h3>
<p>
calculates the isotopic distribution of the stated elemental formula and compares against the empirical ms
</p>
<h3>
Usage
</h3>
<pre>
check_isotopedist(
  ms,
  elementalformula,
  exactmasschart,
  error,
  minerror = 0.002,
  remove.elements = c(),
  max.dist = 3,
  min.int = 0.001,
  charge = "neutral",
  m = 1,
  n = 0.5
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>ms</code>
</td>
<td>
<p>
data.frame mass spectrum containing pair-wise m/z and intensity values of empirical isotopic pattern
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>elementalformula</code>
</td>
<td>
<p>
character string of elemental formula to simulate isotopic pattern
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>exactmasschart</code>
</td>
<td>
<p>
exact mass chart
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>error</code>
</td>
<td>
<p>
numeric relative mass error (in ppm) of mass spectrometer
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>minerror</code>
</td>
<td>
<p>
numeric minimum mass error (in Da) of mass spectrometer
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>remove.elements</code>
</td>
<td>
<p>
character vector of elements to remove from elemental formula
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>max.dist</code>
</td>
<td>
<p>
numeric maximum mass distance (in Da) from exact mass to include in simulated isotopic pattern
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>min.int</code>
</td>
<td>
<p>
numeric minimum relative intensity (maximum = 1, minimum = 0) to include in simulated isotopic pattern
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>charge</code>
</td>
<td>
<p>
character string for the charge state of the simulated isotopic pattern, options are ‘neutral’, ‘positive’, and ‘negative’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>m</code>
</td>
<td>
<p>
numeric dot product mass weighting
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>n</code>
</td>
<td>
<p>
numeric dot product intensity weighting
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
numeric vector of match scores between the empirical and calculated isotopic distribution.
</p>
<hr/>
<table id="fn_def_check_mzML_convert" width="100%" summary="page for check_mzML_convert">
<tr>
<td>
check_mzML_convert
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Check mzML file for specific MSConvert parameters
</h2>
<h3>
Description
</h3>
<p>
Check mzML file for specific MSConvert parameters
</p>
<h3>
Usage
</h3>
<pre>
check_mzML_convert(mzml)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>mzml</code>
</td>
<td>
<p>
list of msdata from ‘mzMLtoR’ function
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data.frame object of conversion veracity checks
</p>
<hr/>
<table id="fn_def_clause_where" width="100%" summary="page for clause_where">
<tr>
<td>
clause_where
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Build a WHERE clause for SQL statements
</h2>
<h3>
Description
</h3>
<p>
Properly escaping SQL to prevent injection attacks can be difficult with more
complicated queries. This clause constructor is intended to be specific to
the WHERE clause of SELECT to UPDATE statements. The majority of construction
is achieved with the ‘match_criteria’ parameter, which should always be a
list with names for the columns to appear in the WHERE clause. A variety of
convenience is built in, from simple comparisons to more complicated ones
including negation and similarity (see the description for argument
‘match_criteria’).
</p>
<h3>
Usage
</h3>
<pre>
clause_where(ANSI(), "example", list(foo = "bar", cat = "dog"))
clause_where(ANSI(), "example", list(foo = list(values = "bar", like = TRUE)))
clause_where(ANSI(), "example", list(foo = list(values = "bar", exclude = TRUE)))
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>table_names</code>
</td>
<td>
<p>
CHR vector of tables to search
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>match_criteria</code>
</td>
<td>
<p>
LIST of matching criteria with names matching columns
against which to apply. In the simplest case, a direct value is given to
the name (e.g. ‘list(last_name = “Smith”)’) for single matches. All match
criteria must be their own list item. Values can also be provided as a
nested list for more complicated WHERE clauses with names ‘values’,
‘exclude’, and ‘like’ that will be recognized. ‘values’ should be the
actual search criteria, and if a vector of length greater than one is
specified, the WHERE clause becomes an IN clause. ‘exclude’ (LGL scalar)
determines whether to apply the NOT operator. ‘like’ (LGL scalar)
determines whether this is an equality, list, or similarity. To reverse the
example above by issuing a NOT statement, use ‘list(last_name = list(values
= “Smith”, exclude = TRUE))’, or to look for all records LIKE (or NOT LIKE)
“Smith”, set this as ‘list(last_name = list(values = “Smith”, exclude =
FALSE, like = TRUE))’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>case_sensitive</code>
</td>
<td>
<p>
LGL scalar of whether to match on a case sensitive
basis (the default TRUE searches for values as-provided) or whether to
coerce value matches by upper, lower, sentence, and title case matches
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>and_or</code>
</td>
<td>
<p>
LGL scalar of whether to use “AND” or “OR” for multiple
criteria, which will be used to combine them all. More complicated WHERE
clauses (including a mixture of AND and OR usage) should be built directly.
(default: “OR”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
CHR scalar of the constructed where clause for an SQL statement
</p>
<hr/>
<table id="fn_def_close_up_shop" width="100%" summary="page for close_up_shop">
<tr>
<td>
close_up_shop
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Conveniently close all database connections
</h2>
<h3>
Description
</h3>
<p>
This closes both the plumber service and all database connections from the
current running environment. If outstanding promises exist to database tables
or views were created as class ‘tbl_’ (e.g. with ‘tbl(con, “table”)’), set
‘back_up_connected_tbls’ to TRUE to collect data from those and preserve
in-place in the current global environment.
</p>
<h3>
Usage
</h3>
<pre>
manage_connection()
close_up_shop(TRUE)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>back_up_connected_tbls</code>
</td>
<td>
<p>
LGL scalar of whether to clone currently
promised tibble connections to database objects as data frames (default:
FALSE).
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, modifies the current global environment in place
</p>
<hr/>
<table id="fn_def_compare_ms" width="100%" summary="page for compare_ms">
<tr>
<td>
compare_ms
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Calculate dot product match score
</h2>
<h3>
Description
</h3>
<p>
Calculates a the match score (based on dot product) of the two uncertainty mass spectra.
Note: this is a static match score and does not include associated uncertainties.
</p>
<h3>
Usage
</h3>
<pre>
compare_ms(
  ms1,
  ms2,
  error = c(5, 5),
  minerror = c(0.002, 0.002),
  m = 1,
  n = 0.5
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>ms1, ms2</code>
</td>
<td>
<p>
the uncertainty mass spectra from function ‘get_ums’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>error</code>
</td>
<td>
<p>
a vector of the respective mass error (in ppm) for each mass spectrum or a single vector representing the mass error for all m/z values
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>minerror</code>
</td>
<td>
<p>
a two component vector of the respective minimum mass error (in Da) for each mass spectrum or a single value representing the minimum mass error of all m/z values
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>m, n</code>
</td>
<td>
<p>
weighting values for mass (m) and intensity (n)
</p>
</td>
</tr>
</table>
<hr/>
<table id="fn_def_complete_form_entry" width="100%" summary="page for complete_form_entry">
<tr>
<td>
complete_form_entry
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Ensure complete form entry
</h2>
<h3>
Description
</h3>
<p>
This input validation check ensures the current session’s input object
includes non-NA, non-NULL, and non-blank values similarly to [shiny::req] and
[shiny::validate] but can be called with a predefined list of input names to
check. Typically this is used for validate form entry completion. Call this
function prior to reading form entries to ensure that all values requested by
name in in ‘values’ are present. If they are not, a [<a href="appendix-function-reference.html#fn_def_nist_shinyalert">nist_shinyalert</a>] modal
is displayed prompting the user to complete the form.
</p>
<h3>
Usage
</h3>
<pre>
req(complete_form_entry(input, c("need1", "need2")))
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>input</code>
</td>
<td>
<p>
The session input object
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>values</code>
</td>
<td>
<p>
CHR vector of input object names to require
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>show_alert</code>
</td>
<td>
<p>
LGL scalar indicating whether or not to show an alert, set
FALSE to return the status of the check
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
Whether or not all required values are present.
</p>
<hr/>
<table id="fn_def_create_fallback_build" width="100%" summary="page for create_fallback_build">
<tr>
<td>
create_fallback_build
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Create an SQL file for use without the SQLite CLI
</h2>
<h3>
Description
</h3>
<p>
For cases where the SQLite Command Line Interface is not available, dot
commands used to simplify the database build pipeline are not usable. Call
this function to create a self-contained SQL build file that can be used in
[<a href="appendix-function-reference.html#fn_def_build_db">build_db</a>] to build the database. The self-contained file will include all
“CREATE” and “INSERT” statements necessary by parsing lines including “.read”
and “.import” commands and directly reading referenced files.
</p>
<h3>
Usage
</h3>
<pre>
create_fallback_build(build_file = file.path("config", "build.sql"))
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>build_file</code>
</td>
<td>
<p>
CHR scalar name SQL build file to use. The default, NULL,
will use the environment variable “DB_BUILD_FILE” if it is available.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>populate</code>
</td>
<td>
<p>
LGL scalar of whether to populate data (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>populate_with</code>
</td>
<td>
<p>
CHR scalar name SQL population file to use. The default,
NULL, will use the environment variable “DB_DATA” if it is available.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>driver</code>
</td>
<td>
<p>
CHR scalar of the database driver class to use to correctly
interpolate SQL commands (default: “SQLite”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>comments</code>
</td>
<td>
<p>
CHR scalar regex identifying SQLite comments
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>out_file</code>
</td>
<td>
<p>
CHR scalar of the output file name and destination. The
default, NULL, will write to a file named similarly to ‘build_file’
suffixed with “_full”.
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None: a file will be written at ‘out_file’ with the output.
</p>
<hr/>
<table id="fn_def_create_peak_list" width="100%" summary="page for create_peak_list">
<tr>
<td>
create_peak_list
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Spectral Uncertainty Functions ———————————————————-
Create peak list from SQL ms_data table
</h2>
<h3>
Description
</h3>
<p>
The function extracts the relevant information and sorts it into nested lists for
use in the uncertainty functions
</p>
<h3>
Usage
</h3>
<pre>
create_peak_list(ms_data)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>ms_data</code>
</td>
<td>
<p>
extraction of the ms_data from the SQL table for a specified peak
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
nested list of all data
</p>
<hr/>
<table id="fn_def_create_peak_table_ms1" width="100%" summary="page for create_peak_table_ms1">
<tr>
<td>
create_peak_table_ms1
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Create peak table for MS1 data
</h2>
<h3>
Description
</h3>
<p>
Takes a nested peak list and creates a peak table for easier determination of
uncertainty of the measurement for MS1 data.
</p>
<h3>
Usage
</h3>
<pre>
create_peak_table_ms1(peak, mass, masserror = 5, minerror = 0.002, int0 = NA)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>mass</code>
</td>
<td>
<p>
the exact mass of the compound of interest
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>masserror</code>
</td>
<td>
<p>
the mass accuracy (in ppm) of the instrument data
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>minerror</code>
</td>
<td>
<p>
the minimum mass error (in Da) of the instrument data
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>int0</code>
</td>
<td>
<p>
the default setting for intensity values for missing m/z values
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peaklist</code>
</td>
<td>
<p>
result of the ‘create_peak_list’ function
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
nested list of dataframes containing all MS2 data for the peak
</p>
<hr/>
<table id="fn_def_create_peak_table_ms2" width="100%" summary="page for create_peak_table_ms2">
<tr>
<td>
create_peak_table_ms2
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Create peak table for MS2 data
</h2>
<h3>
Description
</h3>
<p>
Takes a nested peak list and creates a peak table for easier determination of
uncertainty of the measurement for MS2 data.
</p>
<h3>
Usage
</h3>
<pre>
create_peak_table_ms2(peak, mass, masserror = 5, minerror = 0.002, int0 = NA)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>mass</code>
</td>
<td>
<p>
the exact mass of the compound of interest
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>masserror</code>
</td>
<td>
<p>
the mass accuracy (in ppm) of the instrument data
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>minerror</code>
</td>
<td>
<p>
the minimum mass error (in Da) of the instrument data
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>int0</code>
</td>
<td>
<p>
the default setting for intensity values for missing m/z values
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peaklist</code>
</td>
<td>
<p>
result of the ‘create_peak_list’ function
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
nested list of dataframes containing all MS2 data for the peak
</p>
<hr/>
<table id="fn_def_create_py_env" width="100%" summary="page for create_py_env">
<tr>
<td>
create_py_env
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Create a python environment for RDKit
</h2>
<h3>
Description
</h3>
<p>
This project offers a full integration of RDKit via [<a href="https://CRAN.R-project.org/package=reticulate">reticulate</a>]. This
function does the heavy lifting for setting up that environment, either from
an environment specifications file or from the conda forge channel.
</p>
<h3>
Usage
</h3>
<pre>
create_py_env("nist_hrms_db", c("reticulate", "rdkit"))
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>env_name</code>
</td>
<td>
<p>
CHR scalar of a python environment
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
Preferred set up is to set variables in the ‘env_py.R’ file, which will be
used over the internal defaults chosen here. The exception is if
‘INSTALL_FROM == “local”’ and no value is provided for ‘INSTALL_FROM_FILE’
which has no internal default.
</p>
<p>
Germane variables are ‘PYENV_NAME’ (default “reticulated_rdkit”),
‘CONDA_PATH’ (default “auto”), ‘CONDA_MODULES’ (default “rdkit”,
“r-reticulate” will be added), ‘INSTALL_FROM’ (default “conda”),
‘INSTALL_FROM_FILE’ (default “rdkit/environment.yml”), ‘MIN_PY_VER’ (default
3.9).
</p>
<h3>
Value
</h3>
<p>
None
</p>
<hr/>
<table id="fn_def_create_search_df" width="100%" summary="page for create_search_df">
<tr>
<td>
create_search_df
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Create data.frame containing parameters for extraction and searching
</h2>
<h3>
Description
</h3>
<p>
Use this to create an intermediate data frame object used as part of the search routine.
</p>
<h3>
Usage
</h3>
<pre>
create_search_df(
  filename,
  precursormz,
  rt,
  rt_start,
  rt_end,
  masserror,
  minerror,
  ms2exp,
  isowidth
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>filename</code>
</td>
<td>
<p>
CHR scalar path to the mzml file
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>precursormz</code>
</td>
<td>
<p>
NUM scalar for the mass-to-charge ratio to examine
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>rt</code>
</td>
<td>
<p>
NUM scalar for the retention time centroid to examine
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>rt_start</code>
</td>
<td>
<p>
NUM scalar for the retention time start point of the feature
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>rt_end</code>
</td>
<td>
<p>
NUM scalar for the retention time end point of the feature
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>masserror</code>
</td>
<td>
<p>
NUM scalar of the instrument mass error value in parts per million
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>minerror</code>
</td>
<td>
<p>
NUM scalar of the minimum mass error value to use in absolute terms
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms2exp</code>
</td>
<td>
<p>
NUM scalar type of the fragmentation experiment (e.g. MS1 or MS2)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>isowidth</code>
</td>
<td>
<p>
NUM scalar mass isolation width to use
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data.frame object collating provided values
</p>
<hr/>
<table id="fn_def_create_search_ms" width="100%" summary="page for create_search_ms">
<tr>
<td>
create_search_ms
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Generate uncertainty mass spectrum for MS1 and MS2 data
</h2>
<h3>
Description
</h3>
<p>
Generate uncertainty mass spectrum for MS1 and MS2 data
</p>
<h3>
Usage
</h3>
<pre>
create_search_ms(
  searchobj,
  correl = NULL,
  ph = NULL,
  freq = NULL,
  normfn = "sum",
  cormethod = "pearson"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>searchobj</code>
</td>
<td>
<p>
list object generated from ‘get_search-object’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>correl</code>
</td>
<td>
<p>
correlation limit for ions to MS1
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ph</code>
</td>
<td>
<p>
peak height to select scans for generating mass spectrum
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>freq</code>
</td>
<td>
<p>
observational frequency minimum for ions to use for generating mass spectrum
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>normfn</code>
</td>
<td>
<p>
normalization function, options are “sum” or “mean”
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>cormethod</code>
</td>
<td>
<p>
correlation function, default is “pearson”
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
list object containing the ms1 uncertainty mass spectrum ‘ums1’, ms2 uncertainty mass spectrum ‘ums2’ and respective uncertainty mass spectrum parameters ‘ms1params’ and ‘ms2params’
</p>
<hr/>
<table id="fn_def_data_dictionary" width="100%" summary="page for data_dictionary">
<tr>
<td>
data_dictionary
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Create a data dictionary
</h2>
<h3>
Description
</h3>
<p>
Get a list of tables and their defined columns with properties, including
comments, suitable as a data dictionary from a connection object amenable to
[odbc::dbListTables]. This function relies on [<a href="appendix-function-reference.html#fn_def_pragma_table_info">pragma_table_info</a>].
</p>
<h3>
Usage
</h3>
<pre>
data_dictionary(db_conn = con)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default:con)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LIST of length equal to the number of tables in ‘con’ with attributes
identifying which tables, if any, failed to render into the dictionary.
</p>
<hr/>
<table id="fn_def_dataframe_match" width="100%" summary="page for dataframe_match">
<tr>
<td>
dataframe_match
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Match multiple values in a database table
</h2>
<h3>
Description
</h3>
<p>
Complex queries are sometimes necessary to match against multiple varied
conditions across multiple items in a list or data frame. Call this function
to apply vectorization to all items in ‘match_criteria’ and create a fully
qualified SQL expression using [<a href="appendix-function-reference.html#fn_def_clause_where">clause_where</a>] and execute that query against
the database connection in ‘db_conn’. Speed is not optimized during the call
to clause where as each clause is built independently and joined together
with “OR” statements.
</p>
<h3>
Usage
</h3>
<pre>
dataframe_match(
  match_criteria,
  table_names,
  and_or = "AND",
  db_conn = con,
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>match_criteria</code>
</td>
<td>
<p>
LIST of matching criteria with names matching columns
against which to apply. In the simplest case, a direct value is given to
the name (e.g. ‘list(last_name = “Smith”)’) for single matches. All match
criteria must be their own list item. Values can also be provided as a
nested list for more complicated WHERE clauses with names ‘values’,
‘exclude’, and ‘like’ that will be recognized. ‘values’ should be the
actual search criteria, and if a vector of length greater than one is
specified, the WHERE clause becomes an IN clause. ‘exclude’ (LGL scalar)
determines whether to apply the NOT operator. ‘like’ (LGL scalar)
determines whether this is an equality, list, or similarity. To reverse the
example above by issuing a NOT statement, use ‘list(last_name = list(values
= “Smith”, exclude = TRUE))’, or to look for all records LIKE (or NOT LIKE)
“Smith”, set this as ‘list(last_name = list(values = “Smith”, exclude =
FALSE, like = TRUE))’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>table_names</code>
</td>
<td>
<p>
CHR vector of tables to search
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>and_or</code>
</td>
<td>
<p>
LGL scalar of whether to use “AND” or “OR” for multiple
criteria, which will be used to combine them all. More complicated WHERE
clauses (including a mixture of AND and OR usage) should be built directly.
(default: “OR”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use during execution
(default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
This is intended for use with a data frame object
</p>
<h3>
Value
</h3>
<p>
data.frame of the matching database rows
</p>
<hr/>
<table id="fn_def_dotprod" width="100%" summary="page for dotprod">
<tr>
<td>
dotprod
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Calculate dot product
</h2>
<h3>
Description
</h3>
<p>
Internal function: calculates the dot product between paired m/z and intensity values
</p>
<h3>
Usage
</h3>
<pre>
dotprod(m1, i1, m2, i2, m = 1, n = 0.5)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>m1, m2</code>
</td>
<td>
<p>
paired vectors containing measured m/z values
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>i1, i2</code>
</td>
<td>
<p>
paired vectors containing measured intensity values
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>m, n</code>
</td>
<td>
<p>
weighting values for mass (m) and intensity (n)
</p>
</td>
</tr>
</table>
<hr/>
<table id="fn_def_dt_color_by" width="100%" summary="page for dt_color_by">
<tr>
<td>
dt_color_by
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Apply colors to DT objects by value in a column
</h2>
<h3>
Description
</h3>
<p>
Adds a class to each node meeting the criteria defined elsewhere as project
object ‘table_bg_classes’ as a list of colors with names matches values.
</p>
<h3>
Usage
</h3>
<pre>
dt_color_by(names(DT_table_data), "color_by")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>table_names</code>
</td>
<td>
<p>
CHR vector of the names going into a table
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>look_for</code>
</td>
<td>
<p>
CHR vector of the column name to color by
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
JS function to apply to a DT object by row
</p>
<hr/>
<table id="fn_def_dt_formatted" width="100%" summary="page for dt_formatted">
<tr>
<td>
dt_formatted
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Easily format multiple DT objects in a shiny project in the same manner
</h2>
<h3>
Description
</h3>
<p>
This serves solely to reduce the amount of options fed into ‘DT::datatable’
by providing common defaults and transparent options. Parameters largely do
exactly what they say and will create a list ‘column_defs’ suitable for use
as ‘datatable(… options = list(columnDefs = column_defs)’. Leave NULL to
ignore any aspect.
</p>
<h3>
Usage
</h3>
<pre>
dt_formatted(
  dataframe,
  show_rownames = FALSE,
  hide_cols = NULL,
  center_cols = NULL,
  narrow_cols = NULL,
  narrow_col_width = "5%",
  medium_cols = NULL,
  medium_col_width = "10%",
  large_cols = NULL,
  large_col_width = "15%",
  truncate_cols = NULL,
  truncate_width = 20,
  date_cols = NULL,
  date_col_width = "10%",
  selection_mode = "single",
  callback = NULL,
  color_by_column = NULL,
  names_to = "title",
  filter_at = "top",
  chr_to_factor = TRUE,
  page_length = 10,
  page_length_menu = c(10, 25, 50),
  ...
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>dataframe</code>
</td>
<td>
<p>
data.frame to be converted to a DT::datatable object
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>hide_cols</code>
</td>
<td>
<p>
CHR vector of column names to hide
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>center_cols</code>
</td>
<td>
<p>
CHR vector of column names to center
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>narrow_cols</code>
</td>
<td>
<p>
CHR vector of column names to make ‘narrow_col_width’ wide
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>narrow_col_width</code>
</td>
<td>
<p>
CHR scalar defining column width (default: “5%”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>medium_cols</code>
</td>
<td>
<p>
CHR vector of column names to make ‘medium_col_width’ wide
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>medium_col_width</code>
</td>
<td>
<p>
CHR scalar defining column width (default: “10%”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>large_cols</code>
</td>
<td>
<p>
CHR vector of column names to make ‘large_col_width’ wide
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>large_col_width</code>
</td>
<td>
<p>
CHR scalar defining column width (default: “15%”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>truncate_cols</code>
</td>
<td>
<p>
CHR vector of column names to truncate
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>truncate_width</code>
</td>
<td>
<p>
INT scalar of the position at which to truncate
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>date_cols</code>
</td>
<td>
<p>
CHR vector of column names identifying dates
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>date_col_width</code>
</td>
<td>
<p>
CHR scalar defining column width (default: “10%”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>selection_mode</code>
</td>
<td>
<p>
CHR scalar of the DT selection mode (default: “single”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>callback</code>
</td>
<td>
<p>
JS custom callback to apply to the datatable widget
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>color_by_column</code>
</td>
<td>
<p>
CHR scalar of the column name by which to color rows
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>names_to</code>
</td>
<td>
<p>
CHR scalar of the name formatting modification to apply, as
one of the options available in the ‘stringr’ package (default: “title” to
apply ‘stringr::str_to_title’)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>filter_at</code>
</td>
<td>
<p>
CHR scalar of the position for the column filter as
understood by ‘DT::datatable(…, filter = filter_at)’. (default: “top”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>chr_to_factor</code>
</td>
<td>
<p>
BOOL scalar for whether or not to automatically convert
character columns to factor columns (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>…</code>
</td>
<td>
<p>
other named arguments to be passed to ‘DT::datatable’
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
DT::datatable object formatted as requested
</p>
<h3>
Note
</h3>
<p>
Truncation applies a JS function to retain the underlying information
as a hover tooltip and truncates using ellipses.
</p>
<p>
Column name formatting relies on being able to parse ‘names_to’ as a
valid function of the form ’sprintf(“str_to_
recognized options include”lower”, “upper”, “title”, and “sentence”.
</p>
<p>
To apply a custom format, define these parameters as a list (e.g.
“dt_format_options”) and pass it, along with your dataframe, as
do.call(“dt_formatted”, c(dataframe = df, dt_format_options))
</p>
<hr/>
<table id="fn_def_er_map" width="100%" summary="page for er_map">
<tr>
<td>
er_map
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Create a simple entity relationship map
</h2>
<h3>
Description
</h3>
<p>
This will poll the database connection and create an entity relationship map
as a list directly from defined SQL statements used to build the table or
view. For each table object it returns a list of length three containing the
entity names that the table (1) ‘references’ (i.e. has a foreign key to), (2)
is ‘referenced_by’ (i.e. is a foreign key for), and (3) views where it is
‘used_in_view’. These are names. This is intended for use as a mapping
shortcut when ER Diagrams are unavailable, or for quick reference within a
project, similarly to a dictionary relationship reference.
</p>
<h3>
Usage
</h3>
<pre>
er_map(db_conn = con)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object, specifically of class “SQLiteConnection” but
not strictly enforced
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
SQL is generated from [pragma_table_def()] with argument ‘get_sql’ = TRUE and
ignores entities whose names start with “sqlite”.
</p>
<h3>
Value
</h3>
<p>
nested LIST object describing the database entity connections
</p>
<hr/>
<table id="fn_def_export_msp" width="100%" summary="page for export_msp">
<tr>
<td>
export_msp
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Export to MSP
</h2>
<h3>
Description
</h3>
<p>
The function exports an uncertainty mass spectrum into a NIST MS Search .msp file
</p>
<h3>
Usage
</h3>
<pre>
export_msp(
  ms,
  file,
  precursor = "",
  name = "Exported Mass Spectrum",
  headerdata = c(),
  append = FALSE
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>ms</code>
</td>
<td>
<p>
uncertainty mass spectrum from ‘get_ums’ function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>file</code>
</td>
<td>
<p>
export .msp file to save the msp files
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>precursor</code>
</td>
<td>
<p>
If available, the numeric precursor m/z for the designated mass spectrum
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>name</code>
</td>
<td>
<p>
Text name to assign to the mass spectrum (not used in spectral searching)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>headerdata</code>
</td>
<td>
<p>
character string containing named values for additional data to put in the header
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>append</code>
</td>
<td>
<p>
boolean (TRUE/FALSE) to append to .msp file (TRUE) or overwrite (FALSE)
</p>
</td>
</tr>
</table>
<hr/>
<table id="fn_def_extend_suspect_list" width="100%" summary="page for extend_suspect_list">
<tr>
<td>
extend_suspect_list
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Extend the compounds and aliases tables
</h2>
<h3>
Description
</h3>
<p>
Suspect lists are occasionally updated. To keep the current database up to
date, run this function by pointing it to the updated or current suspect
list. That suspect list should be one of (1) a file in either
comma-separated-value (CSV) or a Microsoft Excel format (XLS or XLSX), (2) a
data frame containing the new compounds in the standard format of the suspect
list, or (3) a URL pointing to the suspect list.
</p>
<h3>
Usage
</h3>
<pre>
extend_suspect_list(suspect_list, db_conn = con, retain_current = TRUE)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>suspect_list</code>
</td>
<td>
<p>
CHR scalar pointing either to a file (CSV, XLS, or XLSX)
or URL pointing to an XLSX file.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>retain_current</code>
</td>
<td>
<p>
LGL scalar of whether to retain the current list by
attempting to match new entries to older ones, or to append all entries
(default: TRUE)
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
If ‘suspect_list’ does not contain one of the expected file extensions, it
will be assumed to be a URL pointing to a Microsoft Excel file with the
suspect list in the first spreadsheet. The file for that URL will be
downloaded temporarily, read in as a data frame, and then removed.
</p>
<p>
Required columns for the compounds table are first pulled and all other
columns are treated as aliases. If ‘retain_current’ is TRUE, entries in the
“name” column will be matched against current aliases and the compound id
will be persisted for that compound.
</p>
<h3>
Value
</h3>
<p>
None
</p>
<hr/>
<table id="fn_def_extract.elements" width="100%" summary="page for extract.elements">
<tr>
<td>
extract.elements
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Elemental Formula Functions
Extract elements from formula
</h2>
<h3>
Description
</h3>
<p>
Converts elemental formula into list of ‘elements’ and ‘counts’ corresponding to the composition
</p>
<h3>
Usage
</h3>
<pre>
extract.elements(composition.str, remove.elements = c())
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>composition.str</code>
</td>
<td>
<p>
character string elemental formula
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>remove.elements</code>
</td>
<td>
<p>
character vector containing elements to remove from
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
list with ‘elements’ and ‘counts’
</p>
<h3>
Examples
</h3>
<pre>
extract.elements("C2H5O")

extract.elements("C2H5ONa", remove.elements = c("Na", "Cl"))
</pre>
<hr/>
<table id="fn_def_flush_dir" width="100%" summary="page for flush_dir">
<tr>
<td>
flush_dir
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Flush a directory with archive
</h2>
<h3>
Description
</h3>
<p>
Clear a directory and archive those files if desired in any directory
matching any pattern.
</p>
<p>
Clear a directory and archive those files if desired in any directory
matching any pattern.
</p>
<h3>
Usage
</h3>
<pre>
flush_dir("logs", ".txt")

flush_dir(directory = "logs")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>archive</code>
</td>
<td>
<p>
LGL scalar on whether to archive current logs
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>directory</code>
</td>
<td>
<p>
CHR scalar path to the directory to flush
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, executes directory actions
</p>
<p>
None, removes files from a directory
</p>
<hr/>
<table id="fn_def_fn_guide" width="100%" summary="page for fn_guide">
<tr>
<td>
fn_guide
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
View an index of help documentation in your browser
</h2>
<h3>
Description
</h3>
<p>
View an index of help documentation in your browser
</p>
<h3>
Usage
</h3>
<pre>
fn_guide()
</pre>
<h3>
Value
</h3>
<p>
None
</p>
<hr/>
<table id="fn_def_fn_help" width="100%" summary="page for fn_help">
<tr>
<td>
fn_help
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get function documentation for this project
</h2>
<h3>
Description
</h3>
<p>
This function is analogous to “?”, “??”, and “help”. For now, this effort is
distributed as a project instead of a package. This imposes certain
limitations, particularly regarding function documentation. Use this function
to see the documentation for functions in this project just as you would any
installed package. The other limitation is that these help files will not
populate directly as a pop up when using RStudio tab completion.
</p>
<h3>
Usage
</h3>
<pre>
fn_help(fn_name)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>fn_name</code>
</td>
<td>
<p>
Object or CHR string name of a function in this project.
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, opens help file.
</p>
<h3>
Note
</h3>
<p>
This function will be deprecated if the project is moved to a package.
</p>
<h3>
Examples
</h3>
<pre>
fn_help(fn_help)
</pre>
<hr/>
<table id="fn_def_format_html_id" width="100%" summary="page for format_html_id">
<tr>
<td>
format_html_id
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Format a file name as an HTML element ID
</h2>
<h3>
Description
</h3>
<p>
This is often useful to provide feedback to the user about the files they’ve
provided to a shiny application in a more informative manner, as IDs produced
here are suitable to build dynamic UI around. This can serve as the base ID
for tooltips, additional information, icons, etc. and produce everything
necessary in one place for any number of files.
</p>
<h3>
Usage
</h3>
<pre>
format_html_id(filename)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>filename</code>
</td>
<td>
<p>
CHR vector of file names
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
CHR vector of the same size as filename
</p>
<h3>
Examples
</h3>
<pre>
format_html_id(list.files())

</pre>
<hr/>
<table id="fn_def_format_list_of_names" width="100%" summary="page for format_list_of_names">
<tr>
<td>
format_list_of_names
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Grammatically collapse a list of values
</h2>
<h3>
Description
</h3>
<p>
Given a vector of arbitrary length that coerces properly to a human-readable
character string, return it formatted as one of: “one”, “one and two”, or
“one, two, …, and three” using <code>glue::glue</code>. This is functionally the same
as a static version of [glue::glue_collapse] with parameters sep = “,”,
width = Inf, and last = “, and”.
</p>
<h3>
Usage
</h3>
<pre>
format_list_of_names(namelist, add_quotes = FALSE)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>namelist</code>
</td>
<td>
<p>
vector of values to format
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>add_quotes</code>
</td>
<td>
<p>
LGL scalar of whether to enclose individual values in
quotation marks
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
CHR vector of length one
</p>
<h3>
Examples
</h3>
<pre>
format_list_of_names("test")
format_list_of_names(c("apples", "bananas"))
format_list_of_names(c(1:3))
format_list_of_names(seq.Date(Sys.Date(), Sys.Date() + 3, by = 1))
</pre>
<hr/>
<table id="fn_def_formulalize" width="100%" summary="page for formulalize">
<tr>
<td>
formulalize
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Generate standard chemical formula notation
</h2>
<h3>
Description
</h3>
<p>
Generate standard chemical formula notation
</p>
<h3>
Usage
</h3>
<pre>
formulalize(formula)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>formula</code>
</td>
<td>
<p>
CHR string of an elemental formula
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
string with a standard ordered formula
</p>
<h3>
Examples
</h3>
<pre>

formula &lt;- "C10H15S1O3"
formulalize(formula)
</pre>
<hr/>
<table id="fn_def_full_import" width="100%" summary="page for full_import">
<tr>
<td>
full_import
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Import one or more files from the NIST Method Reporting Tool for NTA
</h2>
<h3>
Description
</h3>
<p>
This function serves as a single entry point for data imports. It is
predicated upon the NIST import routine defined here and relies on several
assumptions. It is intended ONLY as an interactive manner of importing n data
files from the NIST Method Reporting Tool for NTA (MRT NTA).
</p>
<h3>
Usage
</h3>
<pre>
full_import(
  import_object = NULL,
  file_name = NULL,
  db_conn = con,
  exclude_missing_required = FALSE,
  stop_if_missing_required = TRUE,
  include_if_missing_recommended = FALSE,
  stop_if_missing_recommended = TRUE,
  ignore_extra = TRUE,
  ignore_insert_conflicts = TRUE,
  requirements_obj = "import_requirements",
  method_in = "massspectrometry",
  ms_methods_table = "ms_methods",
  instrument_properties_table = "instrument_properties",
  sample_info_in = "sample",
  sample_table = "samples",
  contributor_in = "data_generator",
  contributors_table = "contributors",
  sample_aliases = NULL,
  generation_type = NULL,
  generation_type_norm_table = ref_table_from_map(sample_table, "generation_type"),
  mass_spec_in = "massspectrometry",
  chrom_spec_in = "chromatography",
  mobile_phases_in = "chromatography",
  qc_method_in = "qcmethod",
  qc_method_table = "qc_methods",
  qc_method_norm_table = ref_table_from_map(qc_method_table, "name"),
  qc_references_in = "source",
  qc_data_in = "qc",
  qc_data_table = "qc_data",
  carrier_mix_names = NULL,
  id_mix_by = "^mp*[0-9]+",
  mix_collection_table = "carrier_mix_collections",
  mobile_phase_props = list(in_item = "chromatography", db_table = "mobile_phases", props
    = c(flow = "flow", flow_units = "flowunits", duration = "duration", duration_units =
    "durationunits")),
  carrier_props = list(db_table = "carrier_mixes", norm_by =
    ref_table_from_map("carrier_mixes", "component"), alias_in = "carrier_aliases", props
    = c(id_by = "solvent", fraction_by = "fraction")),
  additive_props = list(db_table = "carrier_additives", norm_by =
    ref_table_from_map("carrier_additives", "component"), alias_in = "additive_aliases",
    props = c(id_by = "add$", amount_by = "_amount", units_by = "_units")),
  exclude_values = c("none", "", NA),
  peaks_in = "peak",
  peaks_table = "peaks",
  software_timestamp = NULL,
  software_settings_in = "msconvertsettings",
  ms_data_in = "msdata",
  ms_data_table = "ms_data",
  unpack_spectra = FALSE,
  unpack_format = c("separated", "zipped"),
  ms_spectra_table = "ms_spectra",
  linkage_table = "conversion_software_peaks_linkage",
  settings_table = "conversion_software_settings",
  as_date_format = "%Y-%m-%d %H:%M:%S",
  format_checks = c("ymd_HMS", "ydm_HMS", "mdy_HMS", "dmy_HMS"),
  min_datetime = "2000-01-01 00:00:00",
  fragments_in = "annotation",
  fragments_table = "annotated_fragments",
  fragments_sources_table = "fragment_sources",
  fragments_norm_table = "norm_fragments",
  citation_info_in = "fragment_citation",
  inspection_info_in = "fragment_inspections",
  inspection_table = "fragment_inspections",
  generate_missing_aliases = TRUE,
  fragment_aliases_in = "fragment_aliases",
  fragment_aliases_table = "fragment_aliases",
  fragment_alias_type_norm_table = ref_table_from_map(fragment_aliases_table,
    "alias_type"),
  inchi_prefix = "InChI=1S/",
  rdkit_ref = ifelse(exists("PYENV_REF"), PYENV_REF, "rdk"),
  rdkit_ns = "rdk",
  rdkit_make_if_not = TRUE,
  rdkit_aliases = c("inchi", "inchikey"),
  mol_to_prefix = "MolTo",
  mol_from_prefix = "MolFrom",
  type = "smiles",
  compounds_in = "compounddata",
  compounds_table = "compounds",
  compound_category = NULL,
  compound_category_table = "compound_categories",
  compound_aliases_in = "compound_aliases",
  compound_aliases_table = "compound_aliases",
  compound_alias_type_norm_table = ref_table_from_map(compound_aliases_table,
    "alias_type"),
  fuzzy = FALSE,
  case_sensitive = TRUE,
  ensure_unique = TRUE,
  require_all = FALSE,
  import_map = IMPORT_MAP,
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>import_object</code>
</td>
<td>
<p>
nested LIST object of JSON data to import; this import
routine was built around output from the NTA MRT (default: NULL) - note you
may supply either import object or file_name
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>file_name</code>
</td>
<td>
<p>
external file in JSON format of data to import; this import
routine was built around output from the NTA MRT (default: NULL) - note you
may supply either import object or file_name
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>exclude_missing_required</code>
</td>
<td>
<p>
LGL scalar of whether or not to skip imports
missing required information (default: FALSE); if set to TRUE, this will
override the setting for ‘stop_if_missing_required’ and the import will
continue with logging messages for which files were incomplete
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>stop_if_missing_required</code>
</td>
<td>
<p>
LGL scalar of whether or not to to stop the
import routine if a file is missing required information (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>include_if_missing_recommended</code>
</td>
<td>
<p>
LGL scalar of whether or not to include
imports missing recommended information (default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>stop_if_missing_recommended</code>
</td>
<td>
<p>
LGL scalar of whether or not to to stop
the import routine if a file is missing recommended information (default:
TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ignore_extra</code>
</td>
<td>
<p>
LGL scalar of whether to ignore extraneous import
elements or stop the import process (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ignore_insert_conflicts</code>
</td>
<td>
<p>
LGL scalar of whether to ignore insert
conflicts during the qc methods and qc data import steps (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>requirements_obj</code>
</td>
<td>
<p>
CHR scalar of the name of an R object holding import
requirements; this is a convenience shorthand to prevent multiple imports
from parameter ‘file_name’ (default: “import_requirements”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>method_in</code>
</td>
<td>
<p>
CHR scalar name of the ‘obj’ list containing method
information
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms_methods_table</code>
</td>
<td>
<p>
CHR scalar name of the database table containing
method information
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>instrument_properties_table</code>
</td>
<td>
<p>
CHR scalar name of the database table
holding instrument property information for a given method (default:
“instrument_properties”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>sample_info_in</code>
</td>
<td>
<p>
CHR scalar name of the element within ‘import_object’
containing samples information
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>sample_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding sample
information (default: “samples”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>contributor_in</code>
</td>
<td>
<p>
CHR scalar name of the element within
‘import_object[[sample_info_in]]’ containing contributor information
(default: “data_generator”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>contributors_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding
contributor information (default: “contributors”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>sample_aliases</code>
</td>
<td>
<p>
named CHR vector of aliases with names matching the
alias, and values of the alias reference e.g. c(“ACU1234” = “NIST
Biorepository GUAID”) which can be virutally any reference text; it is
recommended that the reference be to a resolver service if connecting with
external data sources (default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>generation_type</code>
</td>
<td>
<p>
CHR scalar of the type of data generated for this
sample (e.g. “empirical” or “in silico”). The default (NULL) will assign
based on ‘generation_type_default’; any other value will override the
default value and be checked against values in ‘geneation_type_norm_table’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>generation_type_norm_table</code>
</td>
<td>
<p>
CHR scalar name of the database table
normalizing sample generation type (default: “empirical”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>mass_spec_in</code>
</td>
<td>
<p>
CHR scalar name of the element in ‘obj’ holding mass
spectrometry information (default: “massspectrometry”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>chrom_spec_in</code>
</td>
<td>
<p>
CHR scalar name of the element in ‘obj’ holding
chromatographic information (default: “chromatography”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>mobile_phases_in</code>
</td>
<td>
<p>
CHR scalar name of the database table holding mobile
phase and chromatographic information (default: “chromatography”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>qc_method_in</code>
</td>
<td>
<p>
CHR scalar name of the import object element containing
QC method information (default: “qcmethod”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>qc_method_table</code>
</td>
<td>
<p>
CHR scalar of the database table name holding QC
method check information (default: “qc_methods”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>qc_method_norm_table</code>
</td>
<td>
<p>
CHR scalar name of the database table normalizing
QC methods type (default: “norm_qc_methods_name”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>qc_references_in</code>
</td>
<td>
<p>
CHR scalar of the name in ‘obj[[qc_method_in]]’ that
contains the reference or citation for the QC protocol (default: “source”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>carrier_mix_names</code>
</td>
<td>
<p>
CHR vector (optional) of carrier mix collection
names to assign, the length of which should equal 1 or the length of
discrete carrier mixtures; the default, NULL, will automatically assign
names as a function of the method and sample id.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>id_mix_by</code>
</td>
<td>
<p>
regex CHR to identify mobile phase mixtures (default:
“^mp*[0-9]+” matches the generated mixture names)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>mix_collection_table</code>
</td>
<td>
<p>
CHR scalar name of the mix collections table
(default: “carrier_mix_collections”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>mobile_phase_props</code>
</td>
<td>
<p>
LIST object describing how to import the mobile
phase table containing: in_item: CHR scalar name of the ‘obj’ name
containing chromatographic information (default: “chromatography”);
db_table: CHR scalar name of the mobile phases table (default:
“mobile_phases”); props: named CHR vector of name mappings with names equal
to database columns in ‘mobile_phase_props<span class="math inline">\(db_table&#39; and values matching regex to match names in &#39;obj[[mobile_phase_props\)</span>in_item]]’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>carrier_props</code>
</td>
<td>
<p>
LIST object describing how to import the mobile phase
table containing: db_table: CHR scalar name of the mobile phases table
(default: “mobile_phases”); norm_table: CHR scalar name of the table used
to normalize carriers (default: “norm_carriers”); alias_table: CHR scalar
name of the table containing carrier aliases to search (default:
“carrier_aliases”); props: named CHR vector of name mappings with names
equal to database columns in ‘carrier_props<span class="math inline">\(db_table&#39; and values matching regex to match names in &#39;obj[[mobile_phase_props\)</span>in_item]]’, and an extra
element named ‘id_by’ containing regex used to match names in the import
object indicate a carrier (e.g. “solvent”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>additive_props</code>
</td>
<td>
<p>
LIST object describing how to import the mobile phase
table containing: db_table: CHR scalar name of the mobile phases table
(default: “mobile_phases”); norm_table: CHR scalar name of the table used
to normalize carriers (default: “norm_additives”); alias_table: CHR scalar
name of the table containing carrier aliases to search (default:
“additive_aliases”); props: named CHR vector of name mappings with names
equal to database columns in ‘additive_props<span class="math inline">\(db_table&#39; and values matching regex to match names in &#39;obj[[mobile_phase_props\)</span>in_item]]’
‘obj[[mobile_phase_props<span class="math inline">\(in_item]][[mobile_phase_props\)</span>db_table]]’, and an
extra element named ‘id_by’ containing regex used to match names in the
import object indicate an additive (e.g. “add$”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>exclude_values</code>
</td>
<td>
<p>
CHR vector indicating which values to ignore in ‘obj’
(default: c(“none”, ““, NA))
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peaks_in</code>
</td>
<td>
<p>
CHR scalar name of the element within ‘import_object’
containing peak information
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peaks_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding sample
information (default: “samples”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms_data_in</code>
</td>
<td>
<p>
CHR scalar of the named component of ‘obj’ holding mass
spectral data (default: “msdata”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms_data_table</code>
</td>
<td>
<p>
CHR scalar name of the table holding packed spectra in
the database (default: “ms_data”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>unpack_spectra</code>
</td>
<td>
<p>
LGL scalar indicating whether or not to unpack spectral
data to a long format (i.e. all masses and intensities will become a single
record) in the table defined by ‘ms_spectra_table’ (default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>unpack_format</code>
</td>
<td>
<p>
CHR scalar of the type of data packing for the spectra,
one of “separated” (default) or “zipped”
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms_spectra_table</code>
</td>
<td>
<p>
CHR scalar name of the table holding long form
spectra in the database (default: “ms_spectra”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fragments_in</code>
</td>
<td>
<p>
CHR scalar name of the ‘obj’ component holding annotated
fragment information (default: “annotation”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fragments_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding
annotated fragment information (default: “annotated_fragments”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fragments_sources_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding
fragment source (e.g. generation) information (default: “fragment_sources”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fragments_norm_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding
normalized fragment identities (default: obtains this from the result of a
call to [<a href="appendix-function-reference.html#fn_def_er_map">er_map</a>] with the table name from ‘fragments_table’)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>citation_info_in</code>
</td>
<td>
<p>
CHR scalar name of the ‘obj’ component holding
fragment citation information (default: “fragment_citation”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>inspection_info_in</code>
</td>
<td>
<p>
CHR scalar name of the ‘obj’ component holding
fragment inspection information (default: “fragment_inspections”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>inspection_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding
fragment inspection information (default: “fragment_inspections”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>generate_missing_aliases</code>
</td>
<td>
<p>
LGL scalar determining whether or not to
generate machine readable expressions (e.g. InChI) for fragment aliases
from RDKit (requires RDKit activation; default: FALSE); see formals list
for [<a href="appendix-function-reference.html#fn_def_add_rdkit_aliases">add_rdkit_aliases</a>]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fragment_aliases_in</code>
</td>
<td>
<p>
CHR scalar name of the ‘obj’ component holding
fragment aliases (default: “fragment_aliases”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fragment_aliases_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding
fragment aliases (default: “fragment_aliases”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fragment_alias_type_norm_table</code>
</td>
<td>
<p>
CHR scalar name of the alias reference
normalization table, by default the return of
<code>ref_table_from_map(fragment_aliases_table, “alias_type”)</code>
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>rdkit_ref</code>
</td>
<td>
<p>
CHR scalar OR R object of an RDKit binding (default NULL
goes to “rdk” for convenience with other pipelines in this project)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>mol_to_prefix</code>
</td>
<td>
<p>
CHR scalar of the prefix to identify an RDKit function
to create an alias from a mol object (default: “MolTo”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>mol_from_prefix</code>
</td>
<td>
<p>
CHR scalar of the prefix to identify an RDKit function
to create a mol object from’identifiers’ (default: “MolFrom”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>type</code>
</td>
<td>
<p>
The type of chemical structure notation (default: SMILES)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>compounds_in</code>
</td>
<td>
<p>
CHR scalar name in ‘obj’ holding compound data (default:
“compounddata”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>compounds_table</code>
</td>
<td>
<p>
CHR scalar name the database table holding compound
data (default: “compounds”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>compound_category</code>
</td>
<td>
<p>
CHR or INT scalar of the compound category (either a
direct ID or a matching category label in ‘compound_category_table’)
(default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>compound_category_table</code>
</td>
<td>
<p>
CHR scalar name the database table holding
normalized compound categories (default: “compound_categories”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>compound_aliases_in</code>
</td>
<td>
<p>
CHR scalar name of where compound aliases are
located within the import (default: “compound_aliases”), passed to
[<a href="appendix-function-reference.html#fn_def_resolve_compounds">resolve_compounds</a>] as “norm_alias_table”
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>compound_aliases_table</code>
</td>
<td>
<p>
CHR scalar name of the alias reference table to
use when assigning compound aliases (default: “compound_aliases”) passed to
[<a href="appendix-function-reference.html#fn_def_resolve_compounds">resolve_compounds</a>] as “compounds_table”
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>compound_alias_type_norm_table</code>
</td>
<td>
<p>
CHR scalar name of the alias reference
normalization table, by default the return of
<code>ref_table_from_map(compound_aliases_table, “alias_type”)</code>
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fuzzy</code>
</td>
<td>
<p>
LGL scalar of whether to do a “fuzzy” match in the sense that
values provided are wrapped in an SQL “LIKE ’
the ‘case_sensitive’ setting if TRUE (default: FALSE).
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>case_sensitive</code>
</td>
<td>
<p>
LGL scalar of whether to match on a case sensitive
basis (the default TRUE searches for values as-provided) or whether to
coerce value matches by upper, lower, sentence, and title case matches
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ensure_unique</code>
</td>
<td>
<p>
LGL scalar of whether or not to first check that the
values provided form a new unique record (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>require_all</code>
</td>
<td>
<p>
LGL scalar of whether to require all columns (except the
assumed primary key column of “id”) or only those defined as “NOT NULL”
(default: TRUE requires the presence of all columns in the table)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>import_map</code>
</td>
<td>
<p>
data.frame object of the import map (e.g. from a CSV)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use (default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
Import files should be in JSON format as created by the MRT NTA. Examples are
provided in the “example” directory of the project.
</p>
<p>
Defaults for this release are set throughout as of the latest database
schema, but left here as arguments in case those should change, or slight
changes are made to column and table names.
</p>
<h3>
Value
</h3>
<p>
Console logging if enabled and interactive prompts when user
intervention is required. There is no formal return as it executes database
actions.
</p>
<h3>
Note
</h3>
<p>
Many calls within this function are executed as do.call with a filtered
argument list based on the names of formals for the called function.
Several arguments to those functions are also left as the defaults set
there; names must match exactly to be passed in this manner. See the list
of inherited parameters.
</p>
<hr/>
<table id="fn_def_gather_qc" width="100%" summary="page for gather_qc">
<tr>
<td>
gather_qc
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Quality Control Check of Import Data
</h2>
<h3>
Description
</h3>
<p>
Performs the quality control check on the imported data from the peak gather function.
</p>
<h3>
Usage
</h3>
<pre>
gather_qc(
  gather_peak,
  exactmasses,
  exactmasschart,
  ms1range = c(0.5, 3),
  ms1isomatchlimit = 0.5,
  minerror = 0.002,
  max_correl = 0.8,
  correl_bin = 0.1,
  max_ph = 10,
  ph_bin = 1,
  max_freq = 10,
  freq_bin = 1,
  min_n_peaks = 3,
  cormethod = "pearson"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>gather_peak</code>
</td>
<td>
<p>
peak object generated from ‘peak_gather_json’ function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>exactmasses</code>
</td>
<td>
<p>
exactmasses list
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms1range</code>
</td>
<td>
<p>
2-component vector containing stating the range to evaluate the isotopic pattern of the precursor ion, from mass - ms1range[1] to mass + ms1range[2]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms1isomatchlimit</code>
</td>
<td>
<p>
the reverse dot product minimum score for the isotopic pattern match
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>minerror</code>
</td>
<td>
<p>
the minimum mass error (in Da) allowable for the instrument
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>max_correl</code>
</td>
<td>
<p>
[TODO PLACEHOLDER]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>correl_bin</code>
</td>
<td>
<p>
[TODO PLACEHOLDER]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>max_ph</code>
</td>
<td>
<p>
[TODO PLACEHOLDER]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ph_bin</code>
</td>
<td>
<p>
[TODO PLACEHOLDER]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>max_freq</code>
</td>
<td>
<p>
[TODO PLACEHOLDER]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>freq_bin</code>
</td>
<td>
<p>
[TODO PLACEHOLDER]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>min_n_peaks</code>
</td>
<td>
<p>
[TODO PLACEHOLDER]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>cormethod</code>
</td>
<td>
<p>
[TODO PLACEHOLDER]
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
nested list of quality control check results
</p>
<hr/>
<table id="fn_def_get_annotated_fragments" width="100%" summary="page for get_annotated_fragments">
<tr>
<td>
get_annotated_fragments
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get all annotated fragments have matching masses
</h2>
<h3>
Description
</h3>
<p>
Get all annotated fragments have matching masses
</p>
<h3>
Usage
</h3>
<pre>
get_annotated_fragments(con, fragmentions, masserror, minerror)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>con</code>
</td>
<td>
<p>
SQLite database connection
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fragmentions</code>
</td>
<td>
<p>
numeric vector containing m/z values for fragments to search
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>masserror</code>
</td>
<td>
<p>
numeric relative mass error (ppm)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>minerror</code>
</td>
<td>
<p>
numeric minimum mass error (Da)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data.frame of mass spectral data
</p>
<hr/>
<table id="fn_def_get_component" width="100%" summary="page for get_component">
<tr>
<td>
get_component
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Resolve components from a list or named vector
</h2>
<h3>
Description
</h3>
<p>
Call this to pull a component named <code>obj_component</code> from a list or named
vector provided as <code>obj</code> and optionally use [<a href="appendix-function-reference.html#fn_def_tack_on">tack_on</a>] to append to it. This
is intended to ease the process of pulling specific components from a list
for further treatment in the import process by isolating that component.
</p>
<h3>
Usage
</h3>
<pre>
get_component(obj, obj_component, silence = TRUE, log_ns = "global", ...)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>obj</code>
</td>
<td>
<p>
LIST or NAMED vector in which to find <code>obj_component</code>
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>obj_component</code>
</td>
<td>
<p>
CHR vector of named elements to find in <code>obj</code>
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>silence</code>
</td>
<td>
<p>
LGL scalar indicating whether to silence recursive messages,
which may be the same for each element of <code>obj</code> (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use (default: “db”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>…</code>
</td>
<td>
<p>
Additional arguments passed to/from the ellipsis parameter of
calling functions. If named, names are preserved.
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
This is similar in scope to [purrr::pluck] in many regards, but always
returns items with names, and will search an entire list structure, including
data frames, to return all values associated with that name in individual
elements.
</p>
<h3>
Value
</h3>
<p>
LIST object containing the elements of <code>obj</code>
</p>
<h3>
Note
</h3>
<p>
This is a recursive function.
</p>
<p>
If ellipsis arguments are provided, they will be appended to each
identified component via [<a href="appendix-function-reference.html#fn_def_tack_on">tack_on</a>]. Use with caution, but this can be
useful for appending common data to an entire list (e.g. a datetime stamp
for logging processing time or a processor name, human or software).
</p>
<h3>
Examples
</h3>
<pre>
get_component(list(a = letters, b = 1:10), "a")
get_component(list(ex = list(a = letters, b = 1:10), ex2 = list(c = 1:5, a = LETTERS)), "a")
get_component(list(a = letters, b = 1:10), "a", c = 1:5)

</pre>
<hr/>
<table id="fn_def_get_compound_fragments" width="100%" summary="page for get_compound_fragments">
<tr>
<td>
get_compound_fragments
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get all fragments associated with compounds
</h2>
<h3>
Description
</h3>
<p>
Get all fragments associated with compounds
</p>
<h3>
Usage
</h3>
<pre>
get_compound_fragments(con, fragmentions, masserror, minerror)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>con</code>
</td>
<td>
<p>
SQLite database connection
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fragmentions</code>
</td>
<td>
<p>
numeric vector containing m/z values for fragments to search
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>masserror</code>
</td>
<td>
<p>
numeric relative mass error (ppm)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>minerror</code>
</td>
<td>
<p>
numeric minimum mass error (Da)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data.frame object describing known fragments in the database with known compound and peak references attached
</p>
<hr/>
<table id="fn_def_get_compoundid" width="100%" summary="page for get_compoundid">
<tr>
<td>
get_compoundid
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get compound ID and name for specific peaks
</h2>
<h3>
Description
</h3>
<p>
Get compound ID and name for specific peaks
</p>
<h3>
Usage
</h3>
<pre>
get_compoundid(con, peakid)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>con</code>
</td>
<td>
<p>
SQLite database connection
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peakid</code>
</td>
<td>
<p>
integer vector of primary keys for peaks table
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
table of compound IDs and names
</p>
<hr/>
<table id="fn_def_get_fkpk_relationships" width="100%" summary="page for get_fkpk_relationships">
<tr>
<td>
get_fkpk_relationships
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Extract foreign key relationships from a schema
</h2>
<h3>
Description
</h3>
<p>
This convenience function is part of the automatic generation of SQL commands
building views and triggers from a defined schema. Its sole purpose is as a
pre-pass extraction of foreign key relationships between tables from an
object created by [db_map], which in turn relies on specific formatting in
the schema SQL definitions.
</p>
<h3>
Usage
</h3>
<pre>
get_fkpk_relationships(er_map(db_conn = con))
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>db_map</code>
</td>
<td>
<p>
LIST object containing descriptions of table mapping in an
opinionated manner, generally generated by [<a href="appendix-function-reference.html#fn_def_er_map">er_map</a>]. The expectation is a
list of tables, with references in SQL form enumerated in a child element
with a name matching ‘references_in’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>references_in</code>
</td>
<td>
<p>
CHR scalar naming the child element containing SQL
references statements of the form “fk_column REFERENCES table(pk_column)”
(default: “references” is provided by [<a href="appendix-function-reference.html#fn_def_er_map">er_map</a>])
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>dictionary</code>
</td>
<td>
<p>
LIST object containing the schema dictionary produced by
[<a href="appendix-function-reference.html#fn_def_data_dictionary">data_dictionary</a>] fully describing table entities
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LIST of data frames with one element for each table with a foreign
key defined
</p>
<h3>
Note
</h3>
<p>
This only functions for list objects formatted correctly. That is, each
entry in [db_map] must contain an element with a name matching that
provided to ‘references_in’ which contains a character vector formatted as
“table1 REFERENCES table2(pk_column)”.
</p>
<hr/>
<table id="fn_def_get_massadj" width="100%" summary="page for get_massadj">
<tr>
<td>
get_massadj
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Calculate the mass adjustment for a specific adduct
</h2>
<h3>
Description
</h3>
<p>
Calculate the mass adjustment for a specific adduct
</p>
<h3>
Usage
</h3>
<pre>
get_massadj(adduct = "+H", exactmasses = NULL, db_conn = "con")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>adduct</code>
</td>
<td>
<p>
character string containing the + or - and the elemental formula of the adduct, note “2H” should be represented as “H2”
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>exactmasses</code>
</td>
<td>
<p>
list of exact masses of elements, NULL pulls from the database
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
database connection object, either a CHR scalar name (default: “con”) or the connection object itself (preferred)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
NUM scalar of the mass adjustment value
</p>
<hr/>
<table id="fn_def_get_msconvert_data" width="100%" summary="page for get_msconvert_data">
<tr>
<td>
get_msconvert_data
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Extract msconvert metadata
</h2>
<h3>
Description
</h3>
<p>
Extracts relevant Proteowizard MSConvert metadata from mzml file.
Used for ‘peak_gather_json’ function
</p>
<h3>
Usage
</h3>
<pre>
get_msconvert_data(mzml)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>mzml</code>
</td>
<td>
<p>
list of msdata from ‘mzMLtoR’ function
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
list of msconvert parameters
</p>
<hr/>
<table id="fn_def_get_msdata" width="100%" summary="page for get_msdata">
<tr>
<td>
get_msdata
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get all mass spectral data within the database
</h2>
<h3>
Description
</h3>
<p>
Get all mass spectral data within the database
</p>
<h3>
Usage
</h3>
<pre>
get_msdata(con)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>con</code>
</td>
<td>
<p>
SQLite database connection
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data.frame of mass spectral data
</p>
<hr/>
<table id="fn_def_get_msdata_compound" width="100%" summary="page for get_msdata_compound">
<tr>
<td>
get_msdata_compound
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get all mass spectral data for a specific compound
</h2>
<h3>
Description
</h3>
<p>
Get all mass spectral data for a specific compound
</p>
<h3>
Usage
</h3>
<pre>
get_msdata_compound(con, 15)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>con</code>
</td>
<td>
<p>
SQLite database connection
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>compoundid</code>
</td>
<td>
<p>
integer compound ID value
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data.frame of mass spectral data
</p>
<hr/>
<table id="fn_def_get_msdata_peakid" width="100%" summary="page for get_msdata_peakid">
<tr>
<td>
get_msdata_peakid
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get all mass spectral data for a specific peak id
</h2>
<h3>
Description
</h3>
<p>
Get all mass spectral data for a specific peak id
</p>
<h3>
Usage
</h3>
<pre>
get_msdata_peakid(con, 15)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>con</code>
</td>
<td>
<p>
SQLite database connection
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peakid</code>
</td>
<td>
<p>
integer vector of peak ids
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data.frame of mass spectral data
</p>
<hr/>
<table id="fn_def_get_msdata_precursors" width="100%" summary="page for get_msdata_precursors">
<tr>
<td>
get_msdata_precursors
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get all mass spectral data with a specific precursor ion
</h2>
<h3>
Description
</h3>
<p>
Get all mass spectral data with a specific precursor ion
</p>
<h3>
Usage
</h3>
<pre>
get_msdata_precursors(con, precursorion, masserror, minerror)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>con</code>
</td>
<td>
<p>
SQLite database connection
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>precursorion</code>
</td>
<td>
<p>
numeric precursor ion m/z value
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>masserror</code>
</td>
<td>
<p>
numeric relative mass error (ppm)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>minerror</code>
</td>
<td>
<p>
numeric minimum mass error (Da)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data.frame of mass spectral data
</p>
<hr/>
<table id="fn_def_get_opt_params" width="100%" summary="page for get_opt_params">
<tr>
<td>
get_opt_params
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get optimized uncertainty mass spectra parameters for a peak
</h2>
<h3>
Description
</h3>
<p>
Get optimized uncertainty mass spectra parameters for a peak
</p>
<h3>
Usage
</h3>
<pre>
get_opt_params(con, peak_ids)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>con</code>
</td>
<td>
<p>
SQLite database connection
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_ids</code>
</td>
<td>
<p>
integer vector of primary keys for peaks table
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data.frame object of available optimized search parameters
</p>
<hr/>
<table id="fn_def_get_peak_fragments" width="100%" summary="page for get_peak_fragments">
<tr>
<td>
get_peak_fragments
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get annotated fragments for a specific peak
</h2>
<h3>
Description
</h3>
<p>
Get annotated fragments for a specific peak
</p>
<h3>
Usage
</h3>
<pre>
get_peak_fragments(con, peakid)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>con</code>
</td>
<td>
<p>
SQLite database connection
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peakid</code>
</td>
<td>
<p>
integer vector of primary keys for peaks table
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data.frame of annotated fragments
</p>
<hr/>
<table id="fn_def_get_peak_precursor" width="100%" summary="page for get_peak_precursor">
<tr>
<td>
get_peak_precursor
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get precursor ion m/z for a specific peak
</h2>
<h3>
Description
</h3>
<p>
Get precursor ion m/z for a specific peak
</p>
<h3>
Usage
</h3>
<pre>
get_peak_precursor(con, peakid)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>con</code>
</td>
<td>
<p>
SQLite database connection
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peakid</code>
</td>
<td>
<p>
integer primary key for peaks table
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
numeric value of precursor ion m/z value
</p>
<hr/>
<table id="fn_def_get_sample_class" width="100%" summary="page for get_sample_class">
<tr>
<td>
get_sample_class
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get sample class information for specific peaks
</h2>
<h3>
Description
</h3>
<p>
Get sample class information for specific peaks
</p>
<h3>
Usage
</h3>
<pre>
get_sample_class(con, peakid)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>con</code>
</td>
<td>
<p>
SQLite database connection
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peakid</code>
</td>
<td>
<p>
integer vector of primary keys for peaks table
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data.frame object of sample classes associated with a given peak
</p>
<hr/>
<table id="fn_def_get_search_object" width="100%" summary="page for get_search_object">
<tr>
<td>
get_search_object
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Generate msdata object from input peak data
</h2>
<h3>
Description
</h3>
<p>
Generate msdata object from input peak data
</p>
<h3>
Usage
</h3>
<pre>
get_search_object(searchmzml, zoom = c(1, 4))
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>searchmzml</code>
</td>
<td>
<p>
mzml with searching dataframe from ‘getmzML’ function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>zoom</code>
</td>
<td>
<p>
vector length of 2 containing +/- the area around the MS1 precursor ion to collect data.
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LIST object of data.frames include MS1 and MS2 analytical data, and the search parameters used to generate them
</p>
<hr/>
<table id="fn_def_get_suspectlist" width="100%" summary="page for get_suspectlist">
<tr>
<td>
get_suspectlist
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get the current NIST PFAS suspect list.
</h2>
<h3>
Description
</h3>
<p>
Downloads the current NIST suspect list of PFAS from the NIST Public Data
Repository to the current project directory.
</p>
<h3>
Usage
</h3>
<pre>
get_suspectlist(
  destfile = file.path("R", "compoundlist", "suspectlist.xlsx"),
  url_file = file.path("config", "suspectlist_url.txt"),
  default_url = SUS_LIST_URL,
  save_local = FALSE
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>destfile</code>
</td>
<td>
<p>
CHR scalar file.path of location to save the downloaded file
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>url_file</code>
</td>
<td>
<p>
CHR scalar file.path of where the text file containing the
download URL for the NIST PFAS Suspect List
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>save_local</code>
</td>
<td>
<p>
LGL scalar of whether to retain an R expression in the
current environment after download
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
none
</p>
<h3>
Examples
</h3>
<pre>
get_suspectlist()
</pre>
<hr/>
<table id="fn_def_get_ums" width="100%" summary="page for get_ums">
<tr>
<td>
get_ums
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Generate consensus mass spectrum
</h2>
<h3>
Description
</h3>
<p>
The function calculates the uncertainty mass spectrum for a single peak table based
on specific settings described in <a href="https://doi.org/10.1021/jasms.0c00423" class="uri">https://doi.org/10.1021/jasms.0c00423</a>
</p>
<h3>
Usage
</h3>
<pre>
get_ums(
  peaktable,
  correl = NULL,
  ph = NULL,
  freq = NULL,
  normfn = "sum",
  cormethod = "pearson"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>peaktable</code>
</td>
<td>
<p>
result of the ‘create_peak_table_ms1’ or ‘create_peak_table_ms1’ function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>correl</code>
</td>
<td>
<p>
Minimum correlation coefficient between the target ions and the base ion intensity of the targeted m/z to be included in the mass spectrum
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ph</code>
</td>
<td>
<p>
Minimum chromatographic peak height from which to extract MS2 data for the mass spectrum
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>freq</code>
</td>
<td>
<p>
minimum observational frequency of the target ions to be included in the mass spectrum
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>normfn</code>
</td>
<td>
<p>
the normalization function typically “mean” or “sum” for normalizing the intensity values
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>cormethod</code>
</td>
<td>
<p>
the correlation method used for calculating the correlation, see ‘cor’ function for methods
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
nested list of dataframes containing all MS1 and MS2 data for the peak
</p>
<hr/>
<table id="fn_def_get_uniques" width="100%" summary="page for get_uniques">
<tr>
<td>
get_uniques
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get unique components of a nested list
</h2>
<h3>
Description
</h3>
<p>
There are times when the concept of “samples” and “grouped data” may become
intertwined and difficult to parse. The import process is one of those times
depending on how the import file is generated. This function takes a nested
list and compares a specific aspect of it, grouping the output based on that
aspect and returning its characteristics.
</p>
<h3>
Usage
</h3>
<pre>
get_uniques(objects, aspect)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>objects</code>
</td>
<td>
<p>
LIST object
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>aspect</code>
</td>
<td>
<p>
CHR scalar name of the aspect from which to generate unique
combinations
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
For example, the standard NIST import includes the “sample” aspect, which may
be identical for multiple data import files. This provides a unique listing
of those sample characteristics to reduce data manipulation and storage, and
minimize database “chatter” during read/write. It returns a set of unique
characteristics in a list, with appended characteristics “import_object” with
the index number and object name of entries matching those characteristics.
</p>
<p>
This is largely superceded by later developments to database operations that
first check for a table primary key id given a comprehensive list of column
values in those tables where only a single record should contain those values
(e.g. a complete unique case, enforced or unenforced).
</p>
<h3>
Value
</h3>
<p>
Unnamed LIST of length equaling the number of unique combinations
with their values and indices
</p>
<h3>
Examples
</h3>
<pre>
tmp &lt;- list(list(a = 1:10, b = 1:10), list(a = 1:5, b = 1:5), list(a = 1:10, b = 1:5))
get_uniques(tmp)
</pre>
<hr/>
<table id="fn_def_getcharge" width="100%" summary="page for getcharge">
<tr>
<td>
getcharge
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get polarity of a ms scan within mzML object
</h2>
<h3>
Description
</h3>
<p>
Get polarity of a ms scan within mzML object
</p>
<h3>
Usage
</h3>
<pre>
getcharge(mzml, i)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>mzml</code>
</td>
<td>
<p>
list mzML object generated from ‘mzMLtoR’ function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>i</code>
</td>
<td>
<p>
integer scan number
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
integer representing scan polarity (either 1 (positive) or -1 (negative))
</p>
<hr/>
<table id="fn_def_getmslevel" width="100%" summary="page for getmslevel">
<tr>
<td>
getmslevel
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get MS Level of a ms scan within mzML object
</h2>
<h3>
Description
</h3>
<p>
Get MS Level of a ms scan within mzML object
</p>
<h3>
Usage
</h3>
<pre>
getmslevel(mzml, i)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>mzml</code>
</td>
<td>
<p>
list mzML object generated from ‘mzMLtoR’ function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>i</code>
</td>
<td>
<p>
integer scan number
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
integer representing the MS Level (1, 2, … n)
</p>
<hr/>
<table id="fn_def_getmzML" width="100%" summary="page for getmzML">
<tr>
<td>
getmzML
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Brings raw data file into environment
</h2>
<h3>
Description
</h3>
<p>
If filename is not extension .mzML, then converts the raw file
</p>
<h3>
Usage
</h3>
<pre>
getmzML(
  search_df,
  CONVERT = FALSE,
  CHECKCONVERT = TRUE,
  is_waters = FALSE,
  lockmass = NULL,
  lockmasswidth = NULL,
  correct = FALSE
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>search_df</code>
</td>
<td>
<p>
data.frame output of [<a href="appendix-function-reference.html#fn_def_create_search_df">create_search_df</a>] or file name of a raw file to be converted
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>CONVERT</code>
</td>
<td>
<p>
LGL scalar of whether or not to convert the search_df filename (default FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>CHECKCONVERT</code>
</td>
<td>
<p>
LGL scalar of whether or not to verify the conversion format (default TRUE)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LIST value of the trimmed mzML file matching search criteria
</p>
<hr/>
<table id="fn_def_getprecursor" width="100%" summary="page for getprecursor">
<tr>
<td>
getprecursor
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get precursor ion of a ms scan within mzML object
</h2>
<h3>
Description
</h3>
<p>
Get precursor ion of a ms scan within mzML object
</p>
<h3>
Usage
</h3>
<pre>
getprecursor(mzml, i)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>mzml</code>
</td>
<td>
<p>
list mzML object generated from ‘mzMLtoR’ function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>i</code>
</td>
<td>
<p>
integer scan number
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
numeric designating the precursor ion (or middle of the scan range for SWATCH or DIA), returns NULL if no precursor was selected
</p>
<hr/>
<table id="fn_def_gettime" width="100%" summary="page for gettime">
<tr>
<td>
gettime
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get time of a ms scan within mzML object
</h2>
<h3>
Description
</h3>
<p>
Get time of a ms scan within mzML object
</p>
<h3>
Usage
</h3>
<pre>
gettime(mzml, i)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>mzml</code>
</td>
<td>
<p>
list mzML object generated from ‘mzMLtoR’ function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>i</code>
</td>
<td>
<p>
integer scan number
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
numeric of the scan time
</p>
<hr/>
<table id="fn_def_has_missing_elements" width="100%" summary="page for has_missing_elements">
<tr>
<td>
has_missing_elements
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Simple check for if an object is empty
</h2>
<h3>
Description
</h3>
<p>
Checks for empty vectors, a blank character string, NULL, and NA values. If
fed a list object, returns TRUE if any element is is the “empty” set. For
data.frames checks that nrow is not 0. [rlang:::is_empty] only checks for
length 0.
</p>
<h3>
Usage
</h3>
<pre>
has_missing_elements(x, logging = TRUE)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>x</code>
</td>
<td>
<p>
Object to be checked
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>logging</code>
</td>
<td>
<p>
LGL scalar of whether or not to make log messages (default: TRUE)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LGL scalar of whether <code>x</code> is empty
</p>
<h3>
Note
</h3>
<p>
Reminder that vectors created with NULL values will be automatically
reduced by R.
</p>
<h3>
Examples
</h3>
<pre>
has_missing_elements("a")
# FALSE
has_missing_elements(c(NULL, 1:5))
# FALSE
has_missing_elements(list(NULL, 1:5))
# TRUE
has_missing_elements(data.frame(a = character(0)))
# TRUE
</pre>
<hr/>
<table id="fn_def_is_elemental_match" width="100%" summary="page for is_elemental_match">
<tr>
<td>
is_elemental_match
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Checks if two elemental formulas match
</h2>
<h3>
Description
</h3>
<p>
Checks if two elemental formulas match
</p>
<h3>
Usage
</h3>
<pre>
is_elemental_match(testformula, trueformula)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>testformula</code>
</td>
<td>
<p>
character string of elemental formula to test
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>trueformula</code>
</td>
<td>
<p>
character string of elemental formula to check against (truth)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
logical
</p>
<hr/>
<table id="fn_def_is_elemental_subset" width="100%" summary="page for is_elemental_subset">
<tr>
<td>
is_elemental_subset
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Check if elemental formula is a subset of another formula
</h2>
<h3>
Description
</h3>
<p>
Check if elemental formula is a subset of another formula
</p>
<h3>
Usage
</h3>
<pre>
is_elemental_subset(fragmentformula, parentformula)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>fragmentformula</code>
</td>
<td>
<p>
character string of elemental formula subset to test
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>parentformula</code>
</td>
<td>
<p>
character string of elemental formula to check for subset
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
logical
</p>
<h3>
Examples
</h3>
<pre>
is_elemental_subset("C2H2", "C2H5O")

is_elemental_subset("C2H2", "C2H1O")
</pre>
<hr/>
<table id="fn_def_isotopic_distribution" width="100%" summary="page for isotopic_distribution">
<tr>
<td>
isotopic_distribution
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Isotopic distribution functions
Generate isotopic distribution mass spectrum of elemental formula
</h2>
<h3>
Description
</h3>
<p>
Isotopic distribution functions
Generate isotopic distribution mass spectrum of elemental formula
</p>
<h3>
Usage
</h3>
<pre>
isotopic_distribution(
  elementalformula,
  exactmasschart,
  remove.elements = c(),
  max.dist = 3,
  min.int = 0.001,
  charge = "neutral"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>elementalformula</code>
</td>
<td>
<p>
character string of elemental formula to simulate isotopic pattern
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>exactmasschart</code>
</td>
<td>
<p>
exact mass chart generated from function create_exactmasschart
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>remove.elements</code>
</td>
<td>
<p>
character vector of elements to remove from elemental formula
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>max.dist</code>
</td>
<td>
<p>
numeric maximum mass distance (in Da) from exact mass to include in simulated isotopic pattern
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>min.int</code>
</td>
<td>
<p>
numeric minimum relative intensity (maximum = 1, minimum = 0) to include in simulated isotopic pattern
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>charge</code>
</td>
<td>
<p>
character string for the charge state of the simulated isotopic pattern, options are ‘neutral’, ‘positive’, and ‘negative’
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data frame containing mz and int values of mass spectrum
</p>
<hr/>
<table id="fn_def_lockmass_remove" width="100%" summary="page for lockmass_remove">
<tr>
<td>
lockmass_remove
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Remove lockmass scan from mzml object
</h2>
<h3>
Description
</h3>
<p>
For Waters instruments only, identifies the scans that are due to a lock mass scan
and removes them for easier processing.
</p>
<h3>
Usage
</h3>
<pre>
lockmass_remove(
  mzml,
  lockmass = NULL,
  lockmasswidth = NULL,
  correct = FALSE,
  approach = "baseion"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>mzml</code>
</td>
<td>
<p>
mzML object generated from mzMLtoR() function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>lockmass</code>
</td>
<td>
<p>
m/z value of the lockmass to remove
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>lockmasswidth</code>
</td>
<td>
<p>
m/z value for the half-window of the lockmass scan
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>correct</code>
</td>
<td>
<p>
logical if the subsequent spectra should be corrected
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
A copy of the object provided to ‘mzml’ with the lock mass removed.
</p>
<hr/>
<table id="fn_def_log_as_dataframe" width="100%" summary="page for log_as_dataframe">
<tr>
<td>
log_as_dataframe
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Pull a log file into an R object
</h2>
<h3>
Description
</h3>
<p>
Log messages generated by logger with anything other than the standard
formatting options can have multiple formatting tags to display in the R
console. These “junk up” any resulting object. If you want to read it
directly in the console and preserve formatting, call [<a href="appendix-function-reference.html#fn_def_read_log">read_log</a>] with the
default ‘as_object’ argument (FALSE). For deeper inspection, a data frame
works well, provided the formatting matches up. In ‘env_logger.R’ there is an
option to set formatting layouts. In addition to setting formatting layouts,
generate regex strings matching the desired format - ‘log_remove_color’ will
remove the colors (the majority should be caught by the string provided as
the default in this package) and ‘log_split_column’ will split the lines in
your logging file into discrete categories named by ‘df_titles’.
</p>
<h3>
Usage
</h3>
<pre>
log_as_dataframe("log.txt")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>file</code>
</td>
<td>
<p>
CHR scalar file path to a log file (default NULL is translated as
“log.txt”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>last_n</code>
</td>
<td>
<p>
INT scalar of the last ‘n’ log entries to read.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>condense</code>
</td>
<td>
<p>
LGL scalar of whether to nest the resulting tibble by the
nearest second.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>regex_remove</code>
</td>
<td>
<p>
CHR scalar regular expression of characters to REMOVE
from log messages via [stringr::str_remove_all]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>regex_split</code>
</td>
<td>
<p>
CHR scalar regular expression of characters used to split
the log entry into columns from log messages via [tidyr::separate]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>df_titles</code>
</td>
<td>
<p>
CHR vector of headers for the resulting data frame, passed
as the “into” argument of [tidyr::separate]
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
This will attempt to fail gracefully.
</p>
<h3>
Value
</h3>
<p>
tibble with one row per log entry (or groups)
</p>
<h3>
Note
</h3>
<p>
If “time” is included and ‘condense’ == TRUE, the log messages in the
resulting tibble will nested to the nearest second.
</p>
<p>
If “status” is included it will be a factor with levels including the
valid statuses from logger (see [logger::log_levels]).
</p>
<p>
Use care to develop ‘regex_split’ in order to split the log entries
into the appropriate columns as defined by ‘df_titles’; extra
values will be merged into the messages column.
</p>
<hr/>
<table id="fn_def_log_fn" width="100%" summary="page for log_fn">
<tr>
<td>
log_fn
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Simple logging convenience
</h2>
<h3>
Description
</h3>
<p>
Conveniently add a log message at the trace level. Typically this would be
called twice bookending the body of a function along the lines of “Start
fn()” and “End fn()” when calling a function. This can help provided
traceability to deeply nested function calls within a log.
</p>
<h3>
Usage
</h3>
<pre>
fn &lt;- function() {log_fn("start"); 1+1; log_fn("end")}
fn()
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>status</code>
</td>
<td>
<p>
CHR scalar to prefix the log message; will be coerced to
sentence case. Typically “start” or “end” but anything is accepted (default
“start”).
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logger namespace to use (default NA_character_)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>level</code>
</td>
<td>
<p>
CHR scalar of the logging level to be passed to [<a href="appendix-function-reference.html#fn_def_log_it">log_it</a>]
(default “trace”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, hands logging messages to [<a href="appendix-function-reference.html#fn_def_log_it">log_it</a>]
</p>
<hr/>
<table id="fn_def_log_it" width="100%" summary="page for log_it">
<tr>
<td>
log_it
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Conveniently log a message to the console
</h2>
<h3>
Description
</h3>
<p>
Use this to log messages of arbitrary level and message. It works best with
[<a href="https://CRAN.R-project.org/package=logger">logger</a>] but will also print directly to the console to support setups where
package [<a href="https://CRAN.R-project.org/package=logger">logger</a>] may not be available or custom log levels are desired.
</p>
<h3>
Usage
</h3>
<pre>
log_it(
  log_level,
  msg = NULL,
  log_ns = NULL,
  reset_logger_settings = FALSE,
  reload_all = FALSE,
  logger_settings = file.path("config", "env_logger.R"),
  add_unknown_ns = FALSE,
  clone_settings_from = NULL
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>log_level</code>
</td>
<td>
<p>
CHR scalar of the level at which to log a given statement.
If using the [<a href="https://CRAN.R-project.org/package=logger">logger</a>] package, must match one of [logger:::log_levels]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>msg</code>
</td>
<td>
<p>
CHR scalar of the message to accompany the log.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use during execution
(default: NULL prints to the global logging namespace)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>reset_logger_settings</code>
</td>
<td>
<p>
LGL scalar indicating whether or not to refresh
the logger settings using the file identified in <code>logger_settings</code>
(default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>reload_all</code>
</td>
<td>
<p>
LGL scalar indicating whether to, during
<code>reset_logger_settings</code>, to reload the R environment configuration file
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>logger_settings</code>
</td>
<td>
<p>
CHR file path to the file containing logger settings
(default: file.path(“config”, “env_logger.R”))
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>add_unknown_ns</code>
</td>
<td>
<p>
LGL scalar indicating whether or not to add a new
namespace if <code>log_ns</code> is not defined in <code>logger_settings</code> (default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>clone_settings_from</code>
</td>
<td>
<p>
CHR scalar indicating
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
When using [<a href="https://CRAN.R-project.org/package=logger">logger</a>], create settings for each namespace in file
<code>config/env_logger.R</code> as a list (see examples there) and make sure it is
sourced. If using with [<a href="https://CRAN.R-project.org/package=logger">logger</a>] and “file” or “both” is selected for the
namespace <code>LOGGING[[log_ns]]<span class="math inline">\(to&lt;/code&gt; parameter in &lt;code&gt;env_logger.R&lt;/code&gt; logs will be written to disk at the file defined in &lt;code&gt;LOGGING[[log_ns]]\)</span>file</code> as well as
the console.
</p>
<h3>
Value
</h3>
<p>
Adds to the logger file (if enabled) and/or prints to the console if
enabled. See
</p>
<h3>
Examples
</h3>
<pre>
log_it("test", "a test message")
test_log &lt;- function() {
  log_it("success", "a success message")
  log_it("warn", "a warning message")
}
test_log()
# Try it with and without logger loaded.
</pre>
<hr/>
<table id="fn_def_make_acronym" width="100%" summary="page for make_acronym">
<tr>
<td>
make_acronym
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Simple acronym generator
</h2>
<h3>
Description
</h3>
<p>
At times it is useful for display purposes to generate acronyms for longer
bits of text. This naively generates those by extracting the first letter as
upper case from each word in <code>text</code> elements.
</p>
<h3>
Usage
</h3>
<pre>
make_acronym(text)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>text</code>
</td>
<td>
<p>
CHR vector of the text to acronym-ize
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
CHR vector of length equal to that of <code>text</code> with the acronym
</p>
<h3>
Examples
</h3>
<pre>
make_acronym("test me")
make_acronym(paste("department of ", c("commerce", "energy", "defense")))
</pre>
<hr/>
<table id="fn_def_make_install_code" width="100%" summary="page for make_install_code">
<tr>
<td>
make_install_code
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Convenience function to set a new installation code
</h2>
<h3>
Description
</h3>
<p>
Convenience function to set a new installation code
</p>
<h3>
Usage
</h3>
<pre>
make_install_code(db_conn = con, new_name = NULL, log_ns = "db")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default “con”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>new_name</code>
</td>
<td>
<p>
CHR scalar of the human readable name of the installation
(e.g. your project name) (default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use during execution
(default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None
</p>
<hr/>
<table id="fn_def_make_requirements" width="100%" summary="page for make_requirements">
<tr>
<td>
make_requirements
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Make import requirements file
</h2>
<h3>
Description
</h3>
<p>
Importing from the NIST contribution spreadsheet requires a certain format.
In order to proceed smoothly, that format must be verified for gross
integrity with regard to expectations about shape (i.e. class), names of
elements, and whether they are required for import. This function creates a
JSON expression of the expected import structure and saves it to the project
directory.
</p>
<h3>
Usage
</h3>
<pre>
make_requirements(
  example_import,
  file_name = "import_requirements.json",
  not_required = c("annotation", "chromatography", "opt_ums_params"),
  archive = TRUE,
  retain_in_R = TRUE,
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>example_import</code>
</td>
<td>
<p>
CHR or LIST object containing an example of the
expected import format; this should include only a SINGLE compound
contribution file
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>file_name</code>
</td>
<td>
<p>
CHR scalar indicating a file name to save the resulting name
or search on any existing file to archive if ‘archive’ = TRUE (default:
“import_requirements.json”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>not_required</code>
</td>
<td>
<p>
CHR vector matching element names of ‘example_import’
which are not required; all others will be assumed to be required
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>archive</code>
</td>
<td>
<p>
LGL indicating whether or not to archive an existing file
matching ‘file_name’ by suffixing the file name with current date. Only one
archive per date is supported; if a file already exists, it will be
deleted. (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>retain_in_R</code>
</td>
<td>
<p>
LGL indicating whether to retain a local copy of the
requirements file generated (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use (default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
Either an existing JSON expression or an R list object may be used for
‘example_import’. If it is a character scalar, it will be assumed to be a
file name, which will be loaded based on file extension. That file must be a
JSON parseable text file, though raw text is acceptable.
</p>
<p>
An example file is located in the project directory at
“example/PFAC30PAR_PFCA1_mzML_cmpd2627.JSON”
</p>
<p>
As with any file manipulation, use care with ‘file_name’.
</p>
<h3>
Value
</h3>
<p>
writes a file to the project directory (based on the found location
of ‘file_name’) with the JSON structure
</p>
<hr/>
<table id="fn_def_manage_connection" width="100%" summary="page for manage_connection">
<tr>
<td>
manage_connection
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Check for, and optionally remove, a database connection object
</h2>
<h3>
Description
</h3>
<p>
This function seeks to abstract connection management objects to a degree. It
seeks to streamline the process of connecting and disconnecting existing
connections as defined by function parameters. This release has not been
tested extensively with drivers other than SQLite.
</p>
<h3>
Usage
</h3>
<pre>
manage_connection("test.sqlite", conn_name = "test_con")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>db</code>
</td>
<td>
<p>
CHR scalar name of the database to check, defaults to the name
supplied in config/env.R (default: session variable DB_NAME)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>drv_pack</code>
</td>
<td>
<p>
CHR scalar of the package used to connect to this database
(default: session variable DB_DRIVER)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>conn_class</code>
</td>
<td>
<p>
CHR vector of connection object classes to check against.
Note this may depend heavily on connection packages and must be present in
the class names of the driver used. (default session variable DB_CLASS)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>conn_name</code>
</td>
<td>
<p>
CHR scalar of the R environment object name to use for this
connection (default: “con”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>is_local</code>
</td>
<td>
<p>
LGL scalar indicating whether or not the referenced database
is a local file, if not it will be treated as though it is either a DSN or
a database name on your host server, connecting as otherwise defined
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>rm_objects</code>
</td>
<td>
<p>
LGL scalar indicating whether or not to remove objects
identifiably connected to the database from the current environment. This
is particularly useful if there are outstanding connections that need to be
closed (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>reconnect</code>
</td>
<td>
<p>
LGL scalar indicating whether or not to connect if a
connection does not exist; if both this and ‘disconnect’ are true, it will
first be disconnected before reconnecting. (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>disconnect</code>
</td>
<td>
<p>
LGL scalar indicating whether or not to terminate and
remove the connection from the current global environment (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the namespace (if any) to use for logging
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>.environ</code>
</td>
<td>
<p>
environment within which to place this connection object
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>…</code>
</td>
<td>
<p>
named list of any other connection parameters required for your
database driver (e.g. postgres username/password)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None
</p>
<h3>
Note
</h3>
<p>
If you want to disconnect everything but retain tibble pointers to your
data source as tibbles in this session, use [<a href="appendix-function-reference.html#fn_def_close_up_shop">close_up_shop</a>] instead.
</p>
<p>
For more complicated setups, it may be easier to use this function by
storing parameters in a list and calling with [base::do.call()]
</p>
<hr/>
<table id="fn_def_map_import" width="100%" summary="page for map_import">
<tr>
<td>
map_import
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Map an import file to the database schema
</h2>
<h3>
Description
</h3>
<p>
This parses an import object and attempts to map it to database fields and
tables as defined by an import map stored in an object of class data.frame,
typically created during project compliance as “IMPORT_MAP”. This object is a
list of all columns and their tables in the import file matched with the
database table and column to which they should be imported.
</p>
<h3>
Usage
</h3>
<pre>
map_import(
  import_obj,
  aspect,
  import_map,
  case_sensitive = TRUE,
  fuzzy = FALSE,
  ignore = TRUE,
  id_column = "_*id$",
  alias_column = "^alias$",
  resolve_normalization = TRUE,
  strip_na = FALSE,
  db_conn = con,
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>import_obj</code>
</td>
<td>
<p>
LIST object of values to import
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>aspect</code>
</td>
<td>
<p>
CHR scalar of the import aspect (e.g. “sample”) to map
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>import_map</code>
</td>
<td>
<p>
data.frame object of the import map (e.g. from a CSV)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>case_sensitive</code>
</td>
<td>
<p>
LGL scalar of whether to match on a case sensitive
basis (the default TRUE searches for values as-provided) or whether to
coerce value matches by upper, lower, sentence, and title case matches
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fuzzy</code>
</td>
<td>
<p>
LGL scalar of whether to do a “fuzzy” match in the sense that
values provided are wrapped in an SQL “LIKE ’
the ‘case_sensitive’ setting if TRUE (default: FALSE).
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use (default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LIST of final mapped values
</p>
<h3>
Note
</h3>
<p>
The object used for ‘import_map’ must be of a data.frame object that at
minimum includes names columns that includes import_category,
import_parameter, alias_lookup, and sql_normalization
</p>
<hr/>
<table id="fn_def_mode_checks" width="100%" summary="page for mode_checks">
<tr>
<td>
mode_checks
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get list of available functions
</h2>
<h3>
Description
</h3>
<p>
Helper function for <code>verify_args()</code> that returns all the
currently available functions matching a given prefix. This searches the
entire library associated with the current R install.
</p>
<h3>
Usage
</h3>
<pre>
mode_checks(prefix = "is", use_deprecated = FALSE)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>prefix</code>
</td>
<td>
<p>
CHR scalar for the function prefix to search (default “is”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>use_deprecated</code>
</td>
<td>
<p>
BOOL scalar indicating whether or not to include
functions marked as deprecated (PLACEHOLDER default FALSE)
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
Note: argument <code>use_deprecated</code> is not currently used but serves as a
placeholder for future development to avoid or include deprecated functions
</p>
<h3>
Value
</h3>
<p>
CHR vector of functions matching <code>prefix</code>
</p>
<h3>
Examples
</h3>
<pre>
mode_checks()
</pre>
<hr/>
<table id="fn_def_molecule_picture" width="100%" summary="page for molecule_picture">
<tr>
<td>
molecule_picture
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Picture a molecule from structural notation
</h2>
<h3>
Description
</h3>
<p>
This is a thin wrapper to rdkit.Chem.MolFromX methods to generate molecular
models from common structure notation such as InChI or SMILES. All picture
files produced will be in portable network graphics (.png) format.
</p>
<h3>
Usage
</h3>
<pre>
caffeine &lt;- "C[<a href="#fn_def_n">n</a>]1cnc2N(C)C(=O)N(C)C(=O)c12"
molecule_picture(caffeine, show = TRUE)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>mol</code>
</td>
<td>
<p>
CHR scalar expression of molecular structure
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>mol_type</code>
</td>
<td>
<p>
CHR scalar indicating the expression type of ‘mol’ (default:
“smiles”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>file_name</code>
</td>
<td>
<p>
CHR scalar of an intended file destination (default: NULL
will produce a random 10 character file name). Note that any file
extensions provided here will be ignored.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>rdkit_name</code>
</td>
<td>
<p>
CHR scalar indication the name of the R object bound to
RDkit OR the name of the R object directly (i.e. without quotes)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>open_file</code>
</td>
<td>
<p>
LGL scalar of whether to open the file after creation
(default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>show</code>
</td>
<td>
<p>
LGL scalar of whether to return the image itself as an object
(default: FALSE)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, or displays the resulting picture if ‘show == TRUE’
</p>
<h3>
Note
</h3>
<p>
Supported ‘mol’ expressions include FASTA, HELM, Inchi, Mol2Block,
Mol2File, MolBlock, MolFile, PDBBlock, PDBFile, PNGFile, PNGString,
RDKitSVG, Sequence, Smarts, Smiles, TPLBlock, and TPLFile
</p>
<hr/>
<table id="fn_def_monoisotope.list" width="100%" summary="page for monoisotope.list">
<tr>
<td>
monoisotope.list
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Calculate the monoisotopic mass of a elemental formulas in
</h2>
<h3>
Description
</h3>
<p>
Calculate the monoisotopic mass of a elemental formulas in
</p>
<h3>
Usage
</h3>
<pre>
monoisotope.list(
  df,
  column,
  exactmasses,
  remove.elements = c(),
  adduct = "neutral"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>df</code>
</td>
<td>
<p>
data.frame with at least one column with elemental formulas
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>column</code>
</td>
<td>
<p>
integer or CHR scalar indicating the column containing the elemental formulas, if CHR then regex match is used
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>exactmasses</code>
</td>
<td>
<p>
list of exact masses
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>remove.elements</code>
</td>
<td>
<p>
elements to remove from the elemental formulas
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>adduct</code>
</td>
<td>
<p>
character string adduct/charge state to add to the elemental formula, options are ‘neutral’, ‘+H’, ‘-H’, ‘+Na’, ‘+K’, ‘+’, ‘-’, ‘-radical’, ‘+radical’
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data.frame with column of exact masses appended to it
</p>
<hr/>
<table id="fn_def_ms_plot_peak" width="100%" summary="page for ms_plot_peak">
<tr>
<td>
ms_plot_peak
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Plot a peak from database mass spectral data
</h2>
<h3>
Description
</h3>
<p>
Plots the intensity of ion traces over the scan period and annotates them
with the mass to charge value. Several flexible plotting aspects are provided
as data may become complicated.
</p>
<h3>
Usage
</h3>
<pre>
ms_plot_peak(
  data,
  peak_type = c("area", "line", "segment"),
  peak_facet_by = "ms_n",
  peak_mz_resolution = 0,
  peak_drop_ratio = 0.01,
  peak_repel_labels = TRUE,
  peak_line_color = "black",
  peak_fill_color = "grey50",
  peak_fill_alpha = 0.2,
  peak_text_size = 3,
  peak_text_offset = 0.02,
  include_method = TRUE,
  db_conn = con
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>data</code>
</td>
<td>
<p>
data.frame of spectral data in the form of the ‘ms_data’ table
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_type</code>
</td>
<td>
<p>
CHR scalar of the plot type to draw, must be one of “line”,
“segment”, or “area” (default: “line”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_facet_by</code>
</td>
<td>
<p>
CHR scalar name of a column by which to facet the
resulting plot (default: “ms_n”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_mz_resolution</code>
</td>
<td>
<p>
INT scalar mass to charge ratio tolerance to group
peaks, with at minimum columns for intensity (as “base_int”), ion m/z value
(as “base_ion”), and scan time (as “scantime”) - (default: 0 goes to unit
resolution)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_drop_ratio</code>
</td>
<td>
<p>
NUM scalar threshold of the maximum intensity below
which traces will be dropped (default: 1e-2 means any trace with a maximum
intensity less than 1% of the maximum intensity in the plot will be
dropped); if &gt; 1 the inversion will be used (1e5 -&gt; 1e-5)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_repel_labels</code>
</td>
<td>
<p>
LGL scalar on whether to use the [<a href="https://CRAN.R-project.org/package=ggrepel">ggrepel</a>] package
to space out m/z labels in the plot (default: TRUE). If [<a href="https://CRAN.R-project.org/package=ggrepel">ggrepel</a>] is not
installed, it will default to FALSE rather than requiring an installation
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_line_color</code>
</td>
<td>
<p>
CHR scalar name of the color to use for the “color”
aesthetic (only a single color is supported; default: “black”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_fill_color</code>
</td>
<td>
<p>
CHR scalar name of the color to use for the “fill”
aesthetic (only a single color is supported; default: “grey70”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_text_offset</code>
</td>
<td>
<p>
NUM scalar y-axis offset as a fraction of the maximum
intensity for trace annotation (default: 0.02 offsets labels in the
positive direction by 2% of the maximum intensity)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
database connection (default: con) which must be live to pull
sample and compound identification information
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
The basic default plot will group all mass-to-charge ratio values by unit
resolution (increase resolution with ‘peak_mz_resolution’) and plot them as
an area trace over the scanning period. Traces are annotated with the
grouping value. Values of ‘peak_mz_resolution’ greater than available data
(e.g. 10 when data resolution is to the 5th decimal point) will default to
maximum resolution.
</p>
<p>
Traces are filtered out completely if their maximum intensity is below the
ratio set by ‘peak_drop_ratio’; only complete traces are filtered out this
way, not individual data points within a retained trace. Set this as the
fraction of the base peak (the peak of maximum intensity) to use to filter
out low-intensity traces. The calculated intensity threshold will be printed
to the caption.
</p>
<h3>
Value
</h3>
<p>
ggplot object
</p>
<h3>
Note
</h3>
<p>
Increasing ‘peak_mz_resolution’ will likely result in multiple separate
traces.
</p>
<p>
Implicitly missing values are not interpolated, but lines are drawn
through to the next point.
</p>
<p>
‘peak_type’ can will accept abbreviations of its accepted values (e.g.
“l” for “line”)
</p>
<hr/>
<table id="fn_def_ms_plot_peak_overview" width="100%" summary="page for ms_plot_peak_overview">
<tr>
<td>
ms_plot_peak_overview
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Create a patchwork plot of peak spectral properties
</h2>
<h3>
Description
</h3>
<p>
Call this function to generate a combined plot from [<a href="appendix-function-reference.html#fn_def_ms_plot_peak">ms_plot_peak</a>],
[<a href="appendix-function-reference.html#fn_def_ms_plot_spectra">ms_plot_spectra</a>], and [<a href="appendix-function-reference.html#fn_def_ms_plot_spectral_intensity">ms_plot_spectral_intensity</a>] using the [<a href="https://CRAN.R-project.org/package=patchwork">patchwork</a>]
package, which must be installed. All arguments will be passed directly to
the underlying functions to provide flexibility in the final display. The
default settings match those of the called plotting functions, and the output
can be further manipulated with the patchwork package.
</p>
<h3>
Usage
</h3>
<pre>
ms_plot_peak_overview(
  plot_peak_id,
  peak_type = c("area", "line", "segment"),
  peak_facet_by = "ms_n",
  peak_mz_resolution = 0,
  peak_drop_ratio = 0.01,
  peak_repel_labels = TRUE,
  peak_line_color = "black",
  peak_fill_color = "grey50",
  peak_fill_alpha = 0.2,
  peak_text_size = 3,
  peak_text_offset = 0.02,
  spectra_mz_resolution = 3,
  spectra_drop_ratio = 0.01,
  spectra_repel_labels = TRUE,
  spectra_repel_line_color = "grey50",
  spectra_nudge_y_factor = 0.03,
  spectra_log_y = FALSE,
  spectra_text_size = 3,
  spectra_max_overlaps = 50,
  intensity_plot_resolution = c("spectra", "peak"),
  intensity_mz_resolution = 3,
  intensity_drop_ratio = 0,
  patchwork_design = c(area(1, 4, 7, 7), area(1, 1, 4, 2), area(6, 1, 7, 2)),
  as_individual_plots = FALSE,
  include_method = TRUE,
  db_conn = con,
  log_ns = "global"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>peak_type</code>
</td>
<td>
<p>
CHR scalar of the plot type to draw, must be one of “line”,
“segment”, or “area” (default: “line”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_facet_by</code>
</td>
<td>
<p>
CHR scalar name of a column by which to facet the
resulting plot (default: “ms_n”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_mz_resolution</code>
</td>
<td>
<p>
INT scalar mass to charge ratio tolerance to group
peaks, with at minimum columns for intensity (as “base_int”), ion m/z value
(as “base_ion”), and scan time (as “scantime”) - (default: 0 goes to unit
resolution)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_drop_ratio</code>
</td>
<td>
<p>
NUM scalar threshold of the maximum intensity below
which traces will be dropped (default: 1e-2 means any trace with a maximum
intensity less than 1% of the maximum intensity in the plot will be
dropped); if &gt; 1 the inversion will be used (1e5 -&gt; 1e-5)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_repel_labels</code>
</td>
<td>
<p>
LGL scalar on whether to use the [<a href="https://CRAN.R-project.org/package=ggrepel">ggrepel</a>] package
to space out m/z labels in the plot (default: TRUE). If [<a href="https://CRAN.R-project.org/package=ggrepel">ggrepel</a>] is not
installed, it will default to FALSE rather than requiring an installation
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_line_color</code>
</td>
<td>
<p>
CHR scalar name of the color to use for the “color”
aesthetic (only a single color is supported; default: “black”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_fill_color</code>
</td>
<td>
<p>
CHR scalar name of the color to use for the “fill”
aesthetic (only a single color is supported; default: “grey70”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_text_offset</code>
</td>
<td>
<p>
NUM scalar y-axis offset as a fraction of the maximum
intensity for trace annotation (default: 0.02 offsets labels in the
positive direction by 2% of the maximum intensity)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_mz_resolution</code>
</td>
<td>
<p>
INT scalar mass to charge ratio tolerance to
group peaks, with at minimum columns for intensity (as base_int), ion m/z
value (as base_ion), and scan time (as scantime) - (default: 3)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_drop_ratio</code>
</td>
<td>
<p>
NUM scalar threshold of the maximum intensity below
which traces will be dropped (default: 1e-2 means any trace with a maximum
intensity less than 1% of the maximum intensity in the plot will be
dropped); if &gt; 1 the inversion will be used (1e5 -&gt; 1e-5)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_repel_labels</code>
</td>
<td>
<p>
LGL scalar on whether to use the [<a href="https://CRAN.R-project.org/package=ggrepel">ggrepel</a>]
package to space out m/z labels in the plot (default: TRUE). If [<a href="https://CRAN.R-project.org/package=ggrepel">ggrepel</a>]
is not installed, it will default to FALSE rather than requiring an
installation
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_repel_line_color</code>
</td>
<td>
<p>
CHR scalar name of the color to use for the
“color” aesthetic of the lines connecting repelled labels to their data
points; passed to [ggrepel::geom_text_repel] as segment.color (only a
single color is supported; default: “grey50”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_nudge_y_factor</code>
</td>
<td>
<p>
NUM scalar y-axis offset as a fraction of the
maximum intensity for trace annotation (default: 0.03 offsets labels in the
positive direction by 3% of the maximum intensity)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_log_y</code>
</td>
<td>
<p>
LGL scalar of whether or not to apply a log10 scaling
factor to the y-axis (default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_text_size</code>
</td>
<td>
<p>
NUM scalar of the text size to use for annotation
labels (default: 3)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_max_overlaps</code>
</td>
<td>
<p>
INT scalar of the maximum number of text overlaps
to allow (default: 50)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>intensity_mz_resolution</code>
</td>
<td>
<p>
INT scalar mass to charge ratio tolerance to
group peaks, with at minimum columns for intensity (as “base_int” or
“intensity”), ion m/z value (as “base_ion” or “mz”), and scan time (as
“scantime”) - (default: 5)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>intensity_drop_ratio</code>
</td>
<td>
<p>
NUM scalar threshold of the maximum intensity
below which traces will be dropped (default: 0 returns all); if &gt; 1 the
inversion will be used (1e5 -&gt; 1e-5)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>patchwork_design</code>
</td>
<td>
<p>
the layout of the final plot see [patchwork::design]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>as_individual_plots</code>
</td>
<td>
<p>
LGL scalar of whether to return the plots
individually in a list (set TRUE) or as a patchwork plot (default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
database connection (default: con) which must be live to pull
sample and compound identification information
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
object of classes ‘gg’ and ‘ggplot’, as a patchwork unless
‘as_individual_plots’ is TRUE
</p>
<h3>
Note
</h3>
<p>
Requires a live connection to the database to pull all plots for a
given peak_id.
</p>
<p>
Defaults are as for called functions
</p>
<hr/>
<table id="fn_def_ms_plot_spectra" width="100%" summary="page for ms_plot_spectra">
<tr>
<td>
ms_plot_spectra
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Plot a fragment map from database mass spectral data
</h2>
<h3>
Description
</h3>
<p>
Especially for non-targeted analysis workflows, it is often necessary to
examine annotated fragment data for spectra across a given peak of interest.
Annotated fragments lend increasing confidence in the identification of the
compound giving rise to a mass spectral peak. If a fragment has been
annotated, that identification is displayed along with the mass to charge
value in blue. Annotations of the mass to charge ratio for unannotated
fragments are displayed in red.
</p>
<h3>
Usage
</h3>
<pre>
ms_plot_spectra(
  data,
  spectra_type = c("separated", "zipped"),
  spectra_mz_resolution = 3,
  spectra_drop_ratio = 0.01,
  spectra_repel_labels = TRUE,
  spectra_repel_line_color = "grey50",
  spectra_nudge_y_factor = 0.03,
  spectra_log_y = FALSE,
  spectra_is_file = FALSE,
  spectra_from_JSON = FALSE,
  spectra_animate = FALSE,
  spectra_text_size = 3,
  spectra_max_overlaps = 50,
  include_method = TRUE,
  db_conn = con
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>data</code>
</td>
<td>
<p>
data.frame of spectral data in the form of the ‘ms_data’ table
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_mz_resolution</code>
</td>
<td>
<p>
INT scalar mass to charge ratio tolerance to
group peaks, with at minimum columns for intensity (as base_int), ion m/z
value (as base_ion), and scan time (as scantime) - (default: 3)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_drop_ratio</code>
</td>
<td>
<p>
NUM scalar threshold of the maximum intensity below
which traces will be dropped (default: 1e-2 means any trace with a maximum
intensity less than 1% of the maximum intensity in the plot will be
dropped); if &gt; 1 the inversion will be used (1e5 -&gt; 1e-5)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_repel_labels</code>
</td>
<td>
<p>
LGL scalar on whether to use the [<a href="https://CRAN.R-project.org/package=ggrepel">ggrepel</a>]
package to space out m/z labels in the plot (default: TRUE). If [<a href="https://CRAN.R-project.org/package=ggrepel">ggrepel</a>]
is not installed, it will default to FALSE rather than requiring an
installation
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_repel_line_color</code>
</td>
<td>
<p>
CHR scalar name of the color to use for the
“color” aesthetic of the lines connecting repelled labels to their data
points; passed to [ggrepel::geom_text_repel] as segment.color (only a
single color is supported; default: “grey50”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_nudge_y_factor</code>
</td>
<td>
<p>
NUM scalar y-axis offset as a fraction of the
maximum intensity for trace annotation (default: 0.03 offsets labels in the
positive direction by 3% of the maximum intensity)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_log_y</code>
</td>
<td>
<p>
LGL scalar of whether or not to apply a log10 scaling
factor to the y-axis (default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_is_file</code>
</td>
<td>
<p>
LGL scalar of whether data are coming from a file
(default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_from_JSON</code>
</td>
<td>
<p>
LGL scalar of whether data are in JSON format; other
formats are not supported when ‘spectra_is_file = TRUE’ (default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_animate</code>
</td>
<td>
<p>
LGL scalar of whether to produce an animation across
the scantime for these data (default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_text_size</code>
</td>
<td>
<p>
NUM scalar of the text size to use for annotation
labels (default: 3)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_max_overlaps</code>
</td>
<td>
<p>
INT scalar of the maximum number of text overlaps
to allow (default: 50)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
database connection (default: con) which must be live to pull
sample and compound identification information
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
ggplot object
</p>
<h3>
Note
</h3>
<p>
If ‘spectra_animate’ is set to true, it requires the [<a href="https://CRAN.R-project.org/package=gganimate">gganimate</a>]
package to be installed (and may also require the [gifski] package) and
WILL take a large amount of time to complete, but results in an animation
that will iterate through the scan period and display mass spectral data as
they appear across the peak. Your mileage likely will vary.
</p>
<hr/>
<table id="fn_def_ms_plot_spectral_intensity" width="100%" summary="page for ms_plot_spectral_intensity">
<tr>
<td>
ms_plot_spectral_intensity
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Create a spectral intensity plot
</h2>
<h3>
Description
</h3>
<p>
Often it is useful to get an overview of mass-to-charge intensity across the
scanning time of a peak. Typically this is done with individual traces in the
peak fashion, but large peaks can often mask smaller ones, or wash out lower
intensity signals. Use this to plot m/z as dependent upon scan time with
intensity shown by color and size. It is intended as a complement to
[<a href="appendix-function-reference.html#fn_def_ms_plot_peak">ms_plot_peak</a>] and may be called at the same levels of granularity, generally
greater so than [<a href="appendix-function-reference.html#fn_def_ms_plot_peak">ms_plot_peak</a>] which is more of an overview.
</p>
<h3>
Usage
</h3>
<pre>
ms_plot_spectral_intensity(
  data,
  intensity_mz_resolution = 5,
  intensity_drop_ratio = 0,
  intensity_facet_by = NULL,
  intensity_plot_resolution = c("spectra", "peak"),
  include_method = TRUE,
  db_conn = con
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>data</code>
</td>
<td>
<p>
tibble or pointer with data to plot, either at the peak level, in
which case “base_ion” must be present, or at the spectral level, in which
case “intensity” must be present
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>intensity_mz_resolution</code>
</td>
<td>
<p>
INT scalar mass to charge ratio tolerance to
group peaks, with at minimum columns for intensity (as “base_int” or
“intensity”), ion m/z value (as “base_ion” or “mz”), and scan time (as
“scantime”) - (default: 5)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>intensity_drop_ratio</code>
</td>
<td>
<p>
NUM scalar threshold of the maximum intensity
below which traces will be dropped (default: 0 returns all); if &gt; 1 the
inversion will be used (1e5 -&gt; 1e-5)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>intensity_facet_by</code>
</td>
<td>
<p>
CHR scalar of a column name in ‘data’ by which to
facet the resulting plot (default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
database connection (default: con) which must be live to pull
sample and compound identification information
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
object of classes ‘gg’ and ‘ggplot’
</p>
<hr/>
<table id="fn_def_ms_plot_titles" width="100%" summary="page for ms_plot_titles">
<tr>
<td>
ms_plot_titles
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Consistent title for ms_plot_x functions
</h2>
<h3>
Description
</h3>
<p>
This helper function creates consistently formatted plot label elements in an
opinionated manner. This is unlikely to be useful outside the direct context
of [<a href="appendix-function-reference.html#fn_def_ms_plot_peak">ms_plot_peak</a>], [<a href="appendix-function-reference.html#fn_def_ms_plot_spectra">ms_plot_spectra</a>], and [<a href="appendix-function-reference.html#fn_def_ms_plot_spectral_intensity">ms_plot_spectral_intensity</a>].
</p>
<h3>
Usage
</h3>
<pre>
ms_plot_titles(
  plot_data,
  mz_resolution,
  drop_ratio,
  include_method,
  db_conn = con
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>plot_data</code>
</td>
<td>
<p>
data.frame object passed from the plotting function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>mz_resolution</code>
</td>
<td>
<p>
NUM scalar passed from the plotting function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>drop_ratio</code>
</td>
<td>
<p>
NUM scalar passed from the plotting function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>include_method</code>
</td>
<td>
<p>
LGL scalar indicating whether or not to get the method
narrative from the database
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
database connection (default: con) which must be live to pull
sample and compound identification information
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LIST of strings named for ggplot title elements “title”, “subtitle”,
and “caption”
</p>
<hr/>
<table id="fn_def_ms_spectra_separated" width="100%" summary="page for ms_spectra_separated">
<tr>
<td>
ms_spectra_separated
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Parse “Separated” MS Data
</h2>
<h3>
Description
</h3>
<p>
The “separated” format includes spectra packed into two separate columns, one
for mass and another for intensity. All values for a given scan time are
packed into these columns, separated by space, with an unlimited number of
discrete values, and must be a 1:1 ratio of values between the two columns.
</p>
<h3>
Usage
</h3>
<pre>
ms_spectra_separated(df, ms_cols = c("mz", "intensity"))
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>df</code>
</td>
<td>
<p>
data.frame or json object containing spectra compressed in the
“separated” format
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms_cols</code>
</td>
<td>
<p>
CHR vector of length 2 identifying the column names to use for
mass and intensity in the source data; must be of length 2, with the first
value identifying the mass-to-charge ratio column and the second
identifying the intensity column
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data.frame object of the unpacked spectra as a list column
</p>
<h3>
Note
</h3>
<p>
ms_cols is treated as regex expressions, but it is safest to provide
matching column names
</p>
<h3>
Examples
</h3>
<pre>
### JSON Example
tmp &lt;- jsonify::as.json('{
 "measured_mz": "712.9501 713.1851",
 "measured_intensity": "15094.41015625 34809.9765625"
}')
ms_spectra_separated(tmp)

### Example data.frame
tmp &lt;- data.frame(
  measured_mz = "712.9501 713.1851",
  measured_intensity = "15094.41015625 34809.9765625"
)
ms_spectra_separated(tmp)
</pre>
<hr/>
<table id="fn_def_ms_spectra_zipped" width="100%" summary="page for ms_spectra_zipped">
<tr>
<td>
ms_spectra_zipped
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Parse “Zipped” MS Data
</h2>
<h3>
Description
</h3>
<p>
The “zipped” format includes spectra packed into one column containing
alternating mass and intensity values for all observations. All values are
packed into these columns for a given scan time, separated by spaces, with an
unlimited number of discrete values, and must be in an alternating 1:1
pattern of values of the form “mass intensity mass intensity”.
</p>
<h3>
Usage
</h3>
<pre>
ms_spectra_zipped(df, spectra_col = "data")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>df</code>
</td>
<td>
<p>
data.frame object containing spectra compressed in the “zipped”
format
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_col</code>
</td>
<td>
<p>
CHR vector of length 2 identifying the column names to use
for mass and intensity in the source data; must be of length 2, with the
first value identifying the mass column and the second identifying the
intensity column
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data.frame object containing unpacked spectra as a list column
</p>
<h3>
Note
</h3>
<p>
spectra-col is treated as a regex expression, but it is safest to
provide a matching column name
</p>
<h3>
Examples
</h3>
<pre>
### JSON Example
tmp &lt;- jsonlite::as.json('{"msdata": "712.9501 15094.41015625 713.1851 34809.9765625"}')
ms_spectra_separated(tmp)

### Example data.frame
tmp &lt;- data.frame(
  msdata = "712.9501 15094.41015625 713.1851 34809.9765625"
)
ms_spectra_zipped(tmp)
</pre>
<hr/>
<table id="fn_def_mzMLconvert" width="100%" summary="page for mzMLconvert">
<tr>
<td>
mzMLconvert
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Converts a raw file into an mzML
</h2>
<h3>
Description
</h3>
<p>
Converts a raw file into an mzML
</p>
<h3>
Usage
</h3>
<pre>
mzMLconvert(rawfile, msconvert = NULL, config = NULL, outdir = getwd())
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>rawfile</code>
</td>
<td>
<p>
file path of the MS raw file to be converted
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>msconvert</code>
</td>
<td>
<p>
file path of the msconvert.exe file, if NULL retrieves information from config directory
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>config</code>
</td>
<td>
<p>
configuration settings file for msconvert conversion to mzML, if NULL retrives information from config directory
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>outdir</code>
</td>
<td>
<p>
directory path for the converted mzML file.
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
CHR scalar path to the created file
</p>
<hr/>
<table id="fn_def_mzMLtoR" width="100%" summary="page for mzMLtoR">
<tr>
<td>
mzMLtoR
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Opens file of type mzML into R environment
</h2>
<h3>
Description
</h3>
<p>
Opens file of type mzML into R environment
</p>
<h3>
Usage
</h3>
<pre>
mzMLtoR(
  mzmlfile = file.choose(),
  lockmass = NULL,
  lockmasswidth = NULL,
  correct = FALSE,
  approach = "hybrid"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>mzmlfile</code>
</td>
<td>
<p>
the file path of the mzML file which the data are to be read from.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>lockmass</code>
</td>
<td>
<p>
NUM scalar m/z value of the lockmass to remove (Waters instruments only) (default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>lockmasswidth</code>
</td>
<td>
<p>
NUM scalar instrumental uncertainty associated with ‘lockmass’ (default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>correct</code>
</td>
<td>
<p>
logical if the subsequent spectra should be corrected for the lockmass (Waters instruments only)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>approach</code>
</td>
<td>
<p>
character string defining the type of lockmass removal filter to use, default is ‘hybrid’
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
list containing mzML data with unzipped masses and intensity information
</p>
<hr/>
<table id="fn_def_nist_shinyalert" width="100%" summary="page for nist_shinyalert">
<tr>
<td>
nist_shinyalert
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Call [shinyalert::shinyalert] with specific styling
</h2>
<h3>
Description
</h3>
<p>
This pass through function serves only to call [shinyalert::shinyalert] with
parameters defined by this function, and can be used for additional styling
that may be necessary. It is used solely for consistency sake.
</p>
<h3>
Usage
</h3>
<pre>
nist_shinyalert("test", "info", shiny::h3("test"))
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>title</code>
</td>
<td>
<p>
The title of the modal.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>type</code>
</td>
<td>
<p>
The type of the modal. There are 4 built-in types which will show
a corresponding icon: <code>“warning”</code>, <code>“error”</code>, <code>“success”</code> and
<code>“info”</code>. You can also set <code>type=“input”</code> to get a prompt
in the modal where the user can enter a response. By default, the modal has
no type.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>text</code>
</td>
<td>
<p>
The modal’s text. Can either be simple text, or Shiny tags (including
Shiny inputs and outputs). If using Shiny tags, then you must also set <code>html=TRUE</code>.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>className</code>
</td>
<td>
<p>
A custom CSS class name for the modal’s container.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>html</code>
</td>
<td>
<p>
If <code>TRUE</code>, the content of the title and text will not be
escaped. By default, the content in the title and text are escaped, so any
HTML tags will not render as HTML.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>closeOnClickOutside</code>
</td>
<td>
<p>
If <code>TRUE</code>, the user can dismiss the modal by
clicking outside it.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>immediate</code>
</td>
<td>
<p>
If <code>TRUE</code>, close any previously opened alerts and display
the current one immediately.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>…</code>
</td>
<td>
<p>
Additional named parameters to be passed to shinyalert.
Unrecognized ones will be ignored.
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, shows a shinyalert modal
</p>
<h3>
See Also
</h3>
<p>
shinyalert::shinyalert
</p>
<hr/>
<table id="fn_def_obj_name_check" width="100%" summary="page for obj_name_check">
<tr>
<td>
obj_name_check
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Sanity check for environment object names
</h2>
<h3>
Description
</h3>
<p>
Provides a sanity check on whether or not a name reference exists and return
its name if so. If not, return the default name defined from <code>default_name</code>.
This largely is used to prevent naming conflicts as part of managing the
plumber service but can be used for any item in the current namespace.
</p>
<h3>
Usage
</h3>
<pre>
if (exists("log_it")) {
    obj_name_check("test", "test")
    test &lt;- letters
    obj_name_check(test)
  }
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>obj</code>
</td>
<td>
<p>
R object or CHR scalar in question to be resolved in the namespace
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>default_name</code>
</td>
<td>
<p>
CHR scalar name to use for <code>obj</code> if it does not exist
(default: NULL).
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
CHR scalar of the resolved object name
</p>
<hr/>
<table id="fn_def_open_env" width="100%" summary="page for open_env">
<tr>
<td>
open_env
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Convenience shortcut to open and edit session environment variables
</h2>
<h3>
Description
</h3>
<p>
Calls [<a href="appendix-function-reference.html#fn_def_open_proj_file">open_proj_file</a>] for either the R, global, or logging environment
settings containing the most common settings dictating project behavior.
</p>
<h3>
Usage
</h3>
<pre>
open_env(name = c("R", "global", "logging", "rdkit", "shiny", "plumber"))
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>name</code>
</td>
<td>
<p>
CHR scalar, one of “R”, “global”, or “logging”.
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, opens a file for editing
</p>
<hr/>
<table id="fn_def_open_proj_file" width="100%" summary="page for open_proj_file">
<tr>
<td>
open_proj_file
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Open and edit project files
</h2>
<h3>
Description
</h3>
<p>
Project files are organized in several topical directories depending on their
purpose as part of the package. For example, several project control
variables are set to establish the session global environment in the “config”
directory rather than the “R” directory.
</p>
<h3>
Usage
</h3>
<pre>
open_proj_file(name, dir = NULL, create_new = FALSE)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>name</code>
</td>
<td>
<p>
CHR scalar of the file name to open, accepts regex
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>dir</code>
</td>
<td>
<p>
CHR scalar of a directory name to search within
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>create_new</code>
</td>
<td>
<p>
LGL scalar of whether to create the file (similar
functionality to [<a href="https://CRAN.R-project.org/package=usethis">usethis</a>]; default FALSE)
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
If a direct file match to name is not found, it will be searched for using a
recursive [list.files] allowing for regex matches (e.g. “.R$”). Directories
are similarly sought out within the project. Reasonable feedback is provided.
</p>
<p>
This convenience function uses [usethis::edit_file] to open (or create if
‘create_new’ is TRUE) any given file in the project.
</p>
<h3>
Value
</h3>
<p>
None, opens a file for editing
</p>
<h3>
Note
</h3>
<p>
If the directory and file cannot be found, and ‘create_new’ is true,
the directory will be placed within the project directory.
</p>
<hr/>
<table id="fn_def_optimal_ums" width="100%" summary="page for optimal_ums">
<tr>
<td>
optimal_ums
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get the optimal uncertainty mass spectrum parameters for data
</h2>
<h3>
Description
</h3>
<p>
Get the optimal uncertainty mass spectrum parameters for data
</p>
<h3>
Usage
</h3>
<pre>
optimal_ums(
  peaktable,
  max_correl = 0.75,
  correl_bin = 0.05,
  max_ph = 10,
  ph_bin = 1,
  max_freq = 10,
  freq_bin = 1,
  min_n_peaks = 3,
  cormethod = "pearson"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>peaktable</code>
</td>
<td>
<p>
list generated from ‘create_peak_table_ms1’ or ‘create_peak_table_ms2’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>max_correl</code>
</td>
<td>
<p>
numeric maximum acceptable correlation
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>correl_bin</code>
</td>
<td>
<p>
numeric sequence bin width from max_correl..0
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>max_ph</code>
</td>
<td>
<p>
numeric maximum acceptable peak height (%)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ph_bin</code>
</td>
<td>
<p>
numeric sequence bin width from max_ph..0
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>max_freq</code>
</td>
<td>
<p>
numeric maximum acceptable observational frequency (%)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>freq_bin</code>
</td>
<td>
<p>
numeric sequence bin width from max_freq..0
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>min_n_peaks</code>
</td>
<td>
<p>
integer ideal minimum number of scans for mass spectrum
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>cormethod</code>
</td>
<td>
<p>
string indicating correlation function to use (see [cor()] for description)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data.frame object containing optimized search parameters
</p>
<hr/>
<table id="fn_def_overlap" width="100%" summary="page for overlap">
<tr>
<td>
overlap
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Calculate overlap ranges
</h2>
<h3>
Description
</h3>
<p>
Internal function: determines if two ranges (x1-e1 to x1+e1) and (x2-e2 to x2+e2) overlap (nonstatistical evaluation)
</p>
<h3>
Usage
</h3>
<pre>
overlap(x1, e1, x2, e2)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>x1, x2</code>
</td>
<td>
<p>
values containing mean values
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>e1, e2</code>
</td>
<td>
<p>
values containing respective error values
</p>
</td>
</tr>
</table>
<hr/>
<table id="fn_def_pair_ums" width="100%" summary="page for pair_ums">
<tr>
<td>
pair_ums
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Pairwise data.frame of two uncertainty mass spectra
</h2>
<h3>
Description
</h3>
<p>
The function stacks two uncertainty mass spectra together based on binned m/z values
</p>
<h3>
Usage
</h3>
<pre>
pair_ums(ums1, ums2, error = 5, minerror = 0.002)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>ums1</code>
</td>
<td>
<p>
uncertainty mass spectrum from ‘get_ums’ function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ums2</code>
</td>
<td>
<p>
uncertainty mass spectrum from ‘get_ums’ function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>minerror</code>
</td>
<td>
<p>
the minimum mass error (in Da) of the instrument data
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>masserror</code>
</td>
<td>
<p>
the mass accuracy (in ppm) of the instrument data
</p>
</td>
</tr>
</table>
<hr/>
<table id="fn_def_peak_gather_json" width="100%" summary="page for peak_gather_json">
<tr>
<td>
peak_gather_json
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Extract peak data and metadata
</h2>
<h3>
Description
</h3>
<p>
gathers metadata from methodjson and extracts the MS1 and MS2 data from the mzml
</p>
<h3>
Usage
</h3>
<pre>
peak_gather_json(
  methodjson,
  mzml,
  compoundtable,
  zoom = c(1, 5),
  minerror = 0.002
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>methodjson</code>
</td>
<td>
<p>
list of JSON generated from ‘parse_method_json’ function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>mzml</code>
</td>
<td>
<p>
list of msdata from ‘mzMLtoR’ function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>compoundtable</code>
</td>
<td>
<p>
data.frame containing compound identities [should be extractable from SQL later]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>zoom</code>
</td>
<td>
<p>
numeric vector specifying the range around the precursor ion to include, from m/z - zoom[1] to m/z + zoom[2]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>minerror</code>
</td>
<td>
<p>
numeric the minimum error (in Da) of the instrument
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
list of peak objects
</p>
<hr/>
<table id="fn_def_plot_compare_ms" width="100%" summary="page for plot_compare_ms">
<tr>
<td>
plot_compare_ms
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Plot MS Comparison
</h2>
<h3>
Description
</h3>
<p>
Plots a butterfly plot for the comparison of two uncertainty mass spectra
</p>
<h3>
Usage
</h3>
<pre>
plot_compare_ms(
  ums1,
  ums2,
  main = "Comparison Mass Spectrum",
  size = 1,
  c1 = "black",
  c2 = "red",
  ylim.exp = 1
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>ums1, ums2</code>
</td>
<td>
<p>
uncertainty mass spectrum from ‘get_ums’ function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>main</code>
</td>
<td>
<p>
Main Title of the Plot
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>size</code>
</td>
<td>
<p>
line width of the mass spectra lines
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>c1</code>
</td>
<td>
<p>
Color of the top (ums1) mass spectral lines
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>c2</code>
</td>
<td>
<p>
Color of the bottom (ums2) mass spectral lines
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ylim.exp</code>
</td>
<td>
<p>
Expansion unit for the y-axis
</p>
</td>
</tr>
</table>
<hr/>
<table id="fn_def_plot_ms" width="100%" summary="page for plot_ms">
<tr>
<td>
plot_ms
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Generate consensus mass spectrum
</h2>
<h3>
Description
</h3>
<p>
Extract relevant information from a mass spectrum and plot it as an uncertainty mass spectrum.
</p>
<h3>
Usage
</h3>
<pre>
plot_ms(
  ms,
  xlim = NULL,
  ylim = NULL,
  main = "Mass Spectrum",
  color = "black",
  size = 1,
  removal = 0
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>peaklist</code>
</td>
<td>
<p>
result of the ‘create_peak_list’ function
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
Extract relevant information from a mass spectrum and plot it as an uncertainty mass spectrum.
</p>
<h3>
Value
</h3>
<p>
ggplot object
</p>
<hr/>
<table id="fn_def_pool.sd" width="100%" summary="page for pool.sd">
<tr>
<td>
pool.sd
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Pool standard deviations
</h2>
<h3>
Description
</h3>
<p>
Internal function: calculates a pooled standard deviation
</p>
<h3>
Usage
</h3>
<pre>
pool.sd(sd, n)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>sd</code>
</td>
<td>
<p>
A vector containing numeric values of standard deviations
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>n</code>
</td>
<td>
<p>
A vector containing integers for the number of observations respective to the sd values
</p>
</td>
</tr>
</table>
<hr/>
<table id="fn_def_pool.ums" width="100%" summary="page for pool.ums">
<tr>
<td>
pool.ums
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Pool uncertainty mass spectra
</h2>
<h3>
Description
</h3>
<p>
Calculates a pooled uncertainty mass spectrum that is a result of data from multiple
uncertainty mass spectra.
</p>
<h3>
Usage
</h3>
<pre>
pool.ums(umslist, error = 5, minerror = 0.002)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>umslist</code>
</td>
<td>
<p>
A list where each item is a uncertainty mass spectrum from function ‘get_ums’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>minerror</code>
</td>
<td>
<p>
the minimum mass error (in Da) of the instrument data
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>masserror</code>
</td>
<td>
<p>
the mass accuracy (in ppm) of the instrument data
</p>
</td>
</tr>
</table>
<hr/>
<table id="fn_def_pragma_table_def" width="100%" summary="page for pragma_table_def">
<tr>
<td>
pragma_table_def
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get table definition from SQLite
</h2>
<h3>
Description
</h3>
<p>
Given a database connection (‘con’). Get more information about the
properties of (a) database table(s) directly from ‘PRAGMA table_info()’
rather than e.g. [DBI::dbListFields()]. Set ‘get_sql’ to ‘TRUE’ to include
the direct schema using sqlite_master; depending on formatting this may or
may not be directly usable though some effort has been made to remove
formatting characters (e.g. line feeds, tabs, etc) if stringr is available.
</p>
<h3>
Usage
</h3>
<pre>
pragma_table_def(db_table, db_conn = con, get_sql = FALSE, pretty = TRUE)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>db_table</code>
</td>
<td>
<p>
CHR vector name of the table(s) to inspect
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>get_sql</code>
</td>
<td>
<p>
BOOL scalar of whether or not to return the schema sql
(default FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>pretty</code>
</td>
<td>
<p>
BOOL scalar for whether to return “pretty” SQL that includes
human readability enhancements; if this is set to TRUE (the default), it is
recommended that the output is fed through ‘cat’ and, in the case of
multiple tables
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
Note that the package ‘stringr’ is required for formatting returns that
include either ‘get_sql’ or ‘pretty’ as TRUE.
</p>
<h3>
Value
</h3>
<p>
data.frame object representing the SQL PRAGMA expression
</p>
<hr/>
<table id="fn_def_pragma_table_info" width="100%" summary="page for pragma_table_info">
<tr>
<td>
pragma_table_info
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Explore properties of an SQLite table
</h2>
<h3>
Description
</h3>
<p>
Add functionality to ‘pragma_table_def’ by filtering on column properties
such as required and primary key fields. This provides some flexibility to
searching table properties without sacrificing the full details of table
schema. Parameter ‘get_sql’ is forced to FALSE; only information available
via PRAGMA is searched by this function.
</p>
<h3>
Usage
</h3>
<pre>
pragma_table_info("compounds")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>db_table</code>
</td>
<td>
<p>
CHR vector name of the table(s) to inspect
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>condition</code>
</td>
<td>
<p>
CHR vector matching specific checks, must be one of
c(“required”, “has_default”, “is_PK”) for constraints where a field must
not be null, has a default value defined, and is a primary key field,
respectively. (default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>name_like</code>
</td>
<td>
<p>
CHR vector of character patterns to match against column
names via grep. If length &gt; 1, will be collapsed to a basic OR regex (e.g.
c(“a”, “b”) becomes “a|b”). As regex, abbreviations and wildcards will
typically work, but care should be used in that case. (default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>data_type</code>
</td>
<td>
<p>
CHR vector of character patterns to match against column
data types via grep. If length &gt; 1 will be collapsed to a basic “OR” regex
(e.g. c(“int”, “real”) becomes “int|real”). As regex, abbreviations and
wildcards will typically work, but care should be used in that case.
(default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>include_comments</code>
</td>
<td>
<p>
LGL scalar of whether to include comments in the
return data frame (default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>names_only</code>
</td>
<td>
<p>
LGL scalar of whether to include names meeting defined
criteria as a vector return value (default: FALSE)
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
This is intended to support validation during database communications with an
SQLite connection, especially for application (e.g. ‘shiny’ development) by
allowing for programmatic inspection of datbase columns by name and property.
</p>
<h3>
Value
</h3>
<p>
data.frame object describing the database entity
</p>
<hr/>
<table id="fn_def_py_modules_available" width="100%" summary="page for py_modules_available">
<tr>
<td>
py_modules_available
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Are all conda modules available in the active environment
</h2>
<h3>
Description
</h3>
<p>
Checks that all defined modules are available in the currently active python
binding. Supports error logging
</p>
<h3>
Usage
</h3>
<pre>
py_modules_available("rdkit")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>required_modules</code>
</td>
<td>
<p>
CHR vector of required modules
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LGL scalar of whether or not all modules are available. Check console
for further details.
</p>
<hr/>
<table id="fn_def_rdkit_active" width="100%" summary="page for rdkit_active">
<tr>
<td>
rdkit_active
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Sanity check on RDKit binding
</h2>
<h3>
Description
</h3>
<p>
Given a name of an R object, performs a simple check on RDKit availability on
that object, creating it if it does not exist. A basic structure conversion
check is tried and a TRUE/FALSE result returned. Leave all arguments as their
defaults of NULL to ensure they will honor the settings in ‘rdkit/env_py.R’.
</p>
<h3>
Usage
</h3>
<pre>
rdkit_active(
  rdkit_ref = NULL,
  rdkit_name = NULL,
  log_ns = NULL,
  make_if_not = FALSE
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>rdkit_ref</code>
</td>
<td>
<p>
CHR scalar OR R object of an RDKit binding (default NULL
goes to “rdk” for convenience with other pipelines in this project)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>rdkit_name</code>
</td>
<td>
<p>
CHR scalar the name of a python environment able to run
rdkit (default NULL goes to “rdkit” for convenience with other pipelines in
this project)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
</td>
</tr>
<tr valign="top">
<td>
<code>make_if_not</code>
</td>
<td>
<p>
LGL scalar of whether or not to create a new python
environment using [<a href="appendix-function-reference.html#fn_def_activate_py_env">activate_py_env</a>] if the binding is not active
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LGL scalar of whether or not the test of RDKit was successful
</p>
<hr/>
<table id="fn_def_rdkit_mol_aliases" width="100%" summary="page for rdkit_mol_aliases">
<tr>
<td>
rdkit_mol_aliases
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Create aliases for a molecule from RDKit
</h2>
<h3>
Description
</h3>
<p>
Call this function to generate any number of machine-readable aliases from an
identifier set. Given the ‘identifiers’ and their ‘type’, RDKit will be
polled for conversion functions to create a mol object. That mol object is
then used to create machine-readable aliases in any number of supported
formats. See the <a href="http://rdkit.org/docs/index.html">RDKit Documentation</a> for
options. The ‘type’ argument is used to match against a “MolFromX” funtion,
while the ‘aliases’ argument is used to match against a “MolToX” function.
</p>
<h3>
Usage
</h3>
<pre>
rdkit_mol_aliases(
  identifiers,
  type = "smiles",
  mol_from_prefix = "MolFrom",
  get_aliases = c("inchi", "inchikey"),
  mol_to_prefix = "MolTo",
  rdkit_ref = "rdk",
  log_ns = "rdk",
  make_if_not = TRUE
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>identifiers</code>
</td>
<td>
<p>
CHR vector of machine-readable molecule identifiers in a
format matching ‘type’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>type</code>
</td>
<td>
<p>
CHR scalar of the type of encoding to use for ‘identifiers’
(default: smiles)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>mol_from_prefix</code>
</td>
<td>
<p>
CHR scalar of the prefix to identify an RDKit function
to create a mol object from’identifiers’ (default: “MolFrom”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>get_aliases</code>
</td>
<td>
<p>
CHR vector of aliases to produce (default: c(“inchi”,
“inchikey”))
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>mol_to_prefix</code>
</td>
<td>
<p>
CHR scalar of the prefix to identify an RDKit function
to create an alias from a mol object (default: “MolTo”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>rdkit_ref</code>
</td>
<td>
<p>
CHR scalar OR R object of an RDKit binding (default NULL
goes to “rdk” for convenience with other pipelines in this project)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
</td>
</tr>
<tr valign="top">
<td>
<code>make_if_not</code>
</td>
<td>
<p>
LGL scalar of whether or not to create a new python
environment using [<a href="appendix-function-reference.html#fn_def_activate_py_env">activate_py_env</a>] if the binding is not active
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
At the time of authorship, RDK v2021.09.4 was in use, which contained the
following options findable by this function: CMLBlock, CXSmarts, CXSmiles,
FASTA, HELM, Inchi, InchiAndAuxInfo, InchiKey, JSON, MolBlock, PDBBlock,
RandomSmilesVect, Sequence, Smarts, Smiles, TPLBlock, V3KMolBlock, XYZBlock.
</p>
<h3>
Value
</h3>
<p>
data.frame object containing the aliases and the original identifiers
</p>
<h3>
Note
</h3>
<p>
Both ‘type’ and ‘aliases’ are case insensitive.
</p>
<p>
If ‘aliases’ is set to NULL, all possible expressions (excluding those
with “File” in the name) are returned from RDKit, which will likely produce
NULL values and module ArgumentErrors.
</p>
<hr/>
<table id="fn_def_read_log" width="100%" summary="page for read_log">
<tr>
<td>
read_log
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Read a log from a log file
</h2>
<h3>
Description
</h3>
<p>
By default if ‘file’ does not exist (i.e. ‘file’ is not a fully defined path)
this looks for log text files in the directory defined by ‘LOG_DIRECTORY’ in
the session.
</p>
<h3>
Usage
</h3>
<pre>
read_log("log.txt")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>file</code>
</td>
<td>
<p>
CHR scalar file path to a log file (default NULL is translated to
“log.txt”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>last_n</code>
</td>
<td>
<p>
INT scalar of the last ‘n’ log entries to read.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>as_object</code>
</td>
<td>
<p>
LGL scalar of whether to return the log as an R object or
just to print the log to the console.
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
CHR vector of the requested log file entries if ‘as_object’ is TRUE,
or none with a console print if ‘as_object’ is FALSE
</p>
<hr/>
<table id="fn_def_rebuild_help_htmls" width="100%" summary="page for rebuild_help_htmls">
<tr>
<td>
rebuild_help_htmls
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Rebuild the help files as HTML with an index
</h2>
<h3>
Description
</h3>
<p>
Rebuild the help files as HTML with an index
</p>
<h3>
Usage
</h3>
<pre>
rebuild_help_htmls(rebuild_book = TRUE, book = "dimspec_user_guide")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>rebuild_book</code>
</td>
<td>
<p>
LGL scalar of whether or not to rebuild an associated bookdown document
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>book</code>
</td>
<td>
<p>
Path to folder containing the bookdown document to rebuild
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
URL to the requested book
</p>
<hr/>
<table id="fn_def_rectify_null_from_env" width="100%" summary="page for rectify_null_from_env">
<tr>
<td>
rectify_null_from_env
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Rectify NULL values provided to functions
</h2>
<h3>
Description
</h3>
<p>
To support redirection of sensible parameter reads from an environment,
either Global or System, functions in this package may include NULL as their
default value. This returns values in precedence of <code>parameter</code>,
<code>env_parameter</code> and <code>default</code>.
</p>
<h3>
Usage
</h3>
<pre>
rectify_null_from_env(test, test, "test")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>parameter</code>
</td>
<td>
<p>
the object being evaluated
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>env_parameter</code>
</td>
<td>
<p>
the name or object of a value to use from the
environment if <code>parameter</code> is NULL
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>default</code>
</td>
<td>
<p>
the fallback value to use if <code>parameter</code> is NULL and
<code>env_parameter</code> does not exist
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
the namespace to use with [<a href="appendix-function-reference.html#fn_def_log_it">log_it</a>] if available
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
The requested value, either as-is, rectified from the environment, or
the default
</p>
<h3>
Note
</h3>
<p>
<code>log_ns</code> is only applicable if logging is set up in this project (see
project settings in env_glob.txt, env_R.R, and env_logger.R for details).
</p>
<p>
Both [base::.GlobalEnv] and [base::Sys.getenv] are checked, and can be
provided as a character scalar or as an object reference
</p>
<hr/>
<table id="fn_def_ref_table_from_map" width="100%" summary="page for ref_table_from_map">
<tr>
<td>
ref_table_from_map
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Get the name of a linked normalization table
</h2>
<h3>
Description
</h3>
<p>
Extract the name of a normalization table from the database given a table and
column reference.
</p>
<h3>
Usage
</h3>
<pre>
ref_table_from_map("table1", "fk_column1", er_map(con), "references")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>table_name</code>
</td>
<td>
<p>
CHR scalar name of the database table
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>table_column</code>
</td>
<td>
<p>
CHR scalar name of the foreign key table column
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>this_map</code>
</td>
<td>
<p>
LIST object containing the schema representation from
‘er_map’ (default: an object named “db_map” created as part of the package
spin up)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fk_refs_in</code>
</td>
<td>
<p>
CHR scalar name of the item in ‘this_map’ containing the
SQL “REFERENCES” statements extracted from the schema
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
CHR scalar name of the table to which a FK column is linked or an
empty character string if no match is located (i.e. ‘table_column’ is not a
defined foreign key).
</p>
<h3>
Note
</h3>
<p>
This requires an object of the same shape and properties as those
resulting from [<a href="appendix-function-reference.html#fn_def_er_map">er_map</a>] as ‘this_map’.
</p>
<hr/>
<table id="fn_def_remove_db" width="100%" summary="page for remove_db">
<tr>
<td>
remove_db
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Remove an existing database
</h2>
<h3>
Description
</h3>
<p>
This is limited to only the current working directory and includes its
subdirectories. If you wish to retain a copy of the prior database, ensure
argument ‘archive = TRUE’ (note the default is FALSE) to create a copy of the
requested database prior to rebuild; this is created in the same directory as
the found database and appends
</p>
<h3>
Usage
</h3>
<pre>
remove_db("test.sqlite", archive = TRUE)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>db</code>
</td>
<td>
<p>
CHR scalar name of the database to build (default: session value
DB_NAME)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>archive</code>
</td>
<td>
<p>
LGL scalar of whether to create an archive of the current
database (if it exists) matching the name supplied in argument ‘db’
(default: FALSE)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, check console for details
</p>
<hr/>
<table id="fn_def_remove_icon_from" width="100%" summary="page for remove_icon_from">
<tr>
<td>
remove_icon_from
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Remove the last icon attached to an HTML element
</h2>
<h3>
Description
</h3>
<p>
Remove the last icon attached to an HTML element
</p>
<h3>
Usage
</h3>
<pre>
remove_icon_from(id)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>id</code>
</td>
<td>
<p>
CHR scalar of the HTML ID from which to remove the last icon
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
CHR scalar suitable to execute with ‘shinyjs::runJS’
</p>
<h3>
Examples
</h3>
<pre>
append_icon_to("example", "r-project", "fa-3x")
remove_icon_from("example")
</pre>
<hr/>
<table id="fn_def_remove_sample" width="100%" summary="page for remove_sample">
<tr>
<td>
remove_sample
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Delete a sample
</h2>
<h3>
Description
</h3>
<p>
Removes a sample from the database and associated records in ms_methods,
conversion_software_settings, and conversion_software_linkage. Associated
peak and mass spectrometric signals will also be removed.
</p>
<h3>
Usage
</h3>
<pre>
remove_sample(sample_ids, db_conn = con, log_ns = "db")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>sample_ids</code>
</td>
<td>
<p>
INT vector of IDs to remove from the samples table.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use (default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, executes actions on the database
</p>
<hr/>
<table id="fn_def_repair_xl_casrn_forced_to_date" width="100%" summary="page for repair_xl_casrn_forced_to_date">
<tr>
<td>
repair_xl_casrn_forced_to_date
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Repair CAS RNs forced to a date numeric by MSXL
</h2>
<h3>
Description
</h3>
<p>
If a file is opened in Microsoft Excel(R), Chemical Abstract Service (CAS)
Registry Numbers (RNs) can occasionally be read as a pseudodate (e.g.
“1903-02-8”). Without tight controls over column formatting, this can result
in CAS RNs that are not real entering a processing pipeline. This convenience
function attempts to undo that automatic formatting by forcing vector members
whose values when coerced to numeric are equal to those provided to a
properly formatted date with an origin depending on operating system platform
(as read by ‘.Platform$OS.type’); Windows operating systems use the Windows
MSXL origin date of “1899-12-30” while others use “1904-01-01”. Text entries
of “NA” are coerced to NA.
</p>
<h3>
Usage
</h3>
<pre>
repair_xl_casrn_forced_to_date(casrn_vec, output_format = "%Y-%m-%d")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>casrn_vec</code>
</td>
<td>
<p>
CHR or NUM vector of what should be valid CAS RNs
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>output_format</code>
</td>
<td>
<p>
CHR scalar of the output format, which
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
CHR vector of length equal to that of ‘casrn_vec’ where numeric
entries have been coerced to the assumed date
</p>
<h3>
Examples
</h3>
<pre>
repair_xl_casrn_forced_to_date(c("64324-08-3", "12332"))
</pre>
<hr/>
<table id="fn_def_repl_nan" width="100%" summary="page for repl_nan">
<tr>
<td>
repl_nan
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Replace NaN
</h2>
<h3>
Description
</h3>
<p>
Replace all NaN values with a specified value
</p>
<h3>
Usage
</h3>
<pre>
repl_nan(x, repl = NULL)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>x</code>
</td>
<td>
<p>
vector of values
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>repl</code>
</td>
<td>
<p>
value to replace NaN contained in ‘x’
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
vector with all NaN replaced with ‘repl’
</p>
<hr/>
<table id="fn_def_report_qc" width="100%" summary="page for report_qc">
<tr>
<td>
report_qc
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Export QC result JSONfile into PDF
</h2>
<h3>
Description
</h3>
<p>
Export QC result JSONfile into PDF
</p>
<h3>
Usage
</h3>
<pre>
report_qc(
  jsonfile = file.choose(),
  outputfile = gsub(".json", ".pdf", jsonfile, ignore.case = TRUE)
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>jsonfile</code>
</td>
<td>
<p>
jsonfile file path
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>outputfile</code>
</td>
<td>
<p>
output pdf file path
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
generates reporting PDF
</p>
<hr/>
<table id="fn_def_reset_logger_settings" width="100%" summary="page for reset_logger_settings">
<tr>
<td>
reset_logger_settings
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Update logger settings
</h2>
<h3>
Description
</h3>
<p>
This is a simple action wrapper to update any settings that may have been
changed with regard to logger. If, for instance, something is not logging the
way you expect it to, change the relevant setting and then run
<code>update_logger_settings()</code> to reflect the current environment.
</p>
<h3>
Usage
</h3>
<pre>
reset_logger_settings()
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>reload</code>
</td>
<td>
<p>
LGL scalar indicating (if TRUE) whether or not to refresh from
<code>env_R.R</code> or (if FALSE) to use the current environment settings (e.g. for
testing purposes) (default: FALSE)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None
</p>
<hr/>
<table id="fn_def_resolve_compound_aliases" width="100%" summary="page for resolve_compound_aliases">
<tr>
<td>
resolve_compound_aliases
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Resolve compound aliases provided as part of the import routine
</h2>
<h3>
Description
</h3>
<p>
Call this to add any aliases for a given ‘compound_id’ that may not be
present in the database. Only those identifiable as part of the accepted
types defined in ‘norm_alias_table’ will be mapped. If multiple items are
provided in the import NAME, ADDITIONAL, or other items matching names in
‘norm_alias_table’.name column, indicate the split character in
‘split_multiples_by’ and any separator between names and values (e.g.
CLASS:example) in ‘identify_property_by’.
</p>
<h3>
Usage
</h3>
<pre>
resolve_compound_aliases(
  obj,
  compound_id,
  compounds_in = "compounddata",
  compound_alias_table = "compound_aliases",
  norm_alias_table = "norm_analyte_alias_references",
  norm_alias_name_column = "name",
  headers_to_examine = c("ADDITIONAL", "NAME"),
  split_multiples_by = ";",
  identify_property_by = ":",
  out_file = "unknown_compound_aliases.csv",
  db_conn = con,
  log_ns = "db",
  ...
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>obj</code>
</td>
<td>
<p>
LIST object containing data formatted from the import generator
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>compound_id</code>
</td>
<td>
<p>
INT scalar of the compound_id to use for these aliases
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>compounds_in</code>
</td>
<td>
<p>
CHR scalar name in ‘obj’ holding compound data (default:
“compounddata”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>norm_alias_table</code>
</td>
<td>
<p>
CHR scalar name of the table normalizing analyte
alias references (default: “norm_analyte_alias_references”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>norm_alias_name_column</code>
</td>
<td>
<p>
CHR scalar name of the column in
‘norm_alias_table’ containing the human-readable expression of alias type
classes (default: “name”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>…</code>
</td>
<td>
<p>
Named list of any additional aliases to tack on that are not found
in the import object, with names matching those found in
‘norm_alias_table’.’norm_alias_name_column’
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, though if unclassifiable aliases (those with alias types not
present in the normalization table) are found, they will be written to a
file (‘out_file’) in the project directory
</p>
<h3>
Note
</h3>
<p>
Existing aliases, and aliases for which there is no ‘compound_id’ will
be ignored and not imported.
</p>
<p>
Compound IDs provided in ‘compound_id’ must be present in the compounds
table and must be provided explicitly on a 1:1 basis for each element
extracted from ‘obj’. If you provide an import object with 10 components
for compound data, you must provide tying ‘compound_id’ identifiers for
each. If all extracted components represent aliases for the same
‘compound_id’ then one may be provided.
</p>
<p>
Alias types (e.g. “InChI” are case insensitive)
</p>
<hr/>
<table id="fn_def_resolve_compound_fragments" width="100%" summary="page for resolve_compound_fragments">
<tr>
<td>
resolve_compound_fragments
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Link together peaks, fragments, and compounds
</h2>
<h3>
Description
</h3>
<p>
This function links together the peaks, annotated_fragments, and compounds
table. This serves as the main connection table conceptually tying together
peaks, the fragments annotated within those peaks, and the compound
identification associated with the peaks. The database supports flexible
assignment wherein compounds may be related to either peaks or annotated
fragments, or both, and vice versa. At least two IDs are required for
linkage; i.e. compounds may not have an acciated peak in the database, but
are known to produce fragments at a particular m/z value. Ideally, all three
are provided to provide traceback from compounds, a complete list of their
annotated fragments, and association with a peak object with data containing
unannotated fragments, which can be traced back to the sample from which it
was drawn and the associated metrological method information.
</p>
<h3>
Usage
</h3>
<pre>
resolve_compound_fragments(
  values = NULL,
  peak_id = NA,
  annotated_fragment_id = NA,
  compound_id = NA,
  linkage_table = "compound_fragments",
  peaks_table = "peaks",
  annotated_fragments_table = "annotated_fragments",
  compounds_table = "compounds",
  db_conn = con,
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>values</code>
</td>
<td>
<p>
LIST item containing items for ‘peak_id’,
‘annotated_fragment_id’, and ‘compound_id’ (default: NULL); used
preferentially if provided
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_id</code>
</td>
<td>
<p>
INT vector (ideally of length 1) of the peak ID(s) to link;
ignored if ‘values’ is provided (default: NA)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>annotated_fragment_id</code>
</td>
<td>
<p>
INT vector of fragment ID(s) to link; ignored if
‘values’ is provided (default: NA)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>compound_id</code>
</td>
<td>
<p>
INT vector of compound ID(s) to link; ignored if ‘values’
is provided (default: NA)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>linkage_table</code>
</td>
<td>
<p>
CHR scalar name of the database table containing
linkages between peaks, fragments, and compounds (default:
“compound_fragments”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peaks_table</code>
</td>
<td>
<p>
CHR scalar name of the database table containing peaks for
look up (default: “peaks”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>compounds_table</code>
</td>
<td>
<p>
CHR scalar name of the table holding compound
information
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use (default: “db”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fragments_table</code>
</td>
<td>
<p>
CHR scalar name of the table holding annotated
fragment information
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, value checks entries and executes database actions
</p>
<hr/>
<table id="fn_def_resolve_compounds" width="100%" summary="page for resolve_compounds">
<tr>
<td>
resolve_compounds
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Resolve the compounds node during bulk import
</h2>
<h3>
Description
</h3>
<p>
Call this function as part of an import routine to resolve the compounds node.
</p>
<h3>
Usage
</h3>
<pre>
resolve_compounds(
  obj,
  compounds_in = "compounddata",
  compounds_table = "compounds",
  compound_category = NULL,
  compound_category_table = "compound_categories",
  compound_alias_table = "compound_aliases",
  norm_alias_table = "norm_analyte_alias_references",
  norm_alias_name_column = "name",
  NIST_id_in = "id",
  require_all = FALSE,
  import_map = IMPORT_MAP,
  ensure_unique = TRUE,
  db_conn = con,
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>obj</code>
</td>
<td>
<p>
LIST object containing data formatted from the import generator
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>compounds_in</code>
</td>
<td>
<p>
CHR scalar name in ‘obj’ holding compound data (default:
“compounddata”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>compounds_table</code>
</td>
<td>
<p>
CHR scalar name the database table holding compound
data (default: “compounds”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>compound_category</code>
</td>
<td>
<p>
CHR or INT scalar of the compound category (either a
direct ID or a matching category label in ‘compound_category_table’)
(default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>compound_category_table</code>
</td>
<td>
<p>
CHR scalar name the database table holding
normalized compound categories (default: “compound_categories”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>norm_alias_table</code>
</td>
<td>
<p>
CHR scalar name of the table normalizing analyte
alias references (default: “norm_analyte_alias_references”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>norm_alias_name_column</code>
</td>
<td>
<p>
CHR scalar name of the column in
‘norm_alias_table’ containing the human-readable expression of alias type
classes (default: “name”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>require_all</code>
</td>
<td>
<p>
LGL scalar of whether to require all columns (except the
assumed primary key column of “id”) or only those defined as “NOT NULL”
(default: TRUE requires the presence of all columns in the table)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>import_map</code>
</td>
<td>
<p>
data.frame object of the import map (e.g. from a CSV)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ensure_unique</code>
</td>
<td>
<p>
LGL scalar of whether or not to first check that the
values provided form a new unique record (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use (default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
INT scalar if successful, result of the call to [<a href="appendix-function-reference.html#fn_def_add_or_get_id">add_or_get_id</a>]
otherwise
</p>
<h3>
Note
</h3>
<p>
This function is called as part of [full_import()]
</p>
<hr/>
<table id="fn_def_resolve_description_NTAMRT" width="100%" summary="page for resolve_description_NTAMRT">
<tr>
<td>
resolve_description_NTAMRT
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Resolve the method description tables during import
</h2>
<h3>
Description
</h3>
<p>
Two tables (and their associated normalization tables) exist in the database
to store additional information about mass spectrometric and chromatographic
methods. These tables are “ms_descriptions” and “chromatography_descriptions”
and cannot be easily mapped directly. This function serves to coerce values
supplied during import into that required by the database. Primarily, the
issue rests in the need to support multiple descriptions of analytical
instrumentation (e.g. multiple mass analyzer types, multiple vendors,
multiple separation columns, etc.). Tables targeted by this function are
“long” tables that may well have ‘n’ records for each mass spectrometric
method.
</p>
<h3>
Usage
</h3>
<pre>
resolve_description_NTAMRT(
  obj,
  method_id,
  type = c("massspec", "chromatography"),
  mass_spec_in = "massspectrometry",
  chrom_spec_in = "chromatography",
  db_conn = con,
  fuzzy = TRUE,
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>obj</code>
</td>
<td>
<p>
LIST object containing data formatted from the import generator
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>method_id</code>
</td>
<td>
<p>
INT scalar of the ms_method.id record to associate
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>type</code>
</td>
<td>
<p>
CHR scalar, one of “massspec” or “chromatography” depending on
the type of description to add; much of the logic is shared, only details
differ
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>mass_spec_in</code>
</td>
<td>
<p>
CHR scalar name of the element in ‘obj’ holding mass
spectrometry information (default: “massspectrometry”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>chrom_spec_in</code>
</td>
<td>
<p>
CHR scalar name of the element in ‘obj’ holding
chromatographic information (default: “chromatography”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use during execution
(default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, executes actions on the database
</p>
<h3>
Note
</h3>
<p>
This function is called as part of [full_import()]
</p>
<p>
This function is brittle; built specifically for the NIST NTA MRT
import format. If using a different import format, customize to your needs
using this function as a guide.
</p>
<hr/>
<table id="fn_def_resolve_fragments_NTAMRT" width="100%" summary="page for resolve_fragments_NTAMRT">
<tr>
<td>
resolve_fragments_NTAMRT
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Resolve the fragments node during database import
</h2>
<h3>
Description
</h3>
<p>
Call this function as part of an import routine to resolve the fragments node
including fragment inspections and aliases. If the python connection to RDKit
is available and no aliases are provided, aliases as defined in
‘rdkit_aliases’ will be generated and stored if ‘generate_missing_aliases’ is
set to TRUE. Components of the import file will be collated, have their
values normalized, and any new fragment identifiers will be added to the
database.
</p>
<h3>
Usage
</h3>
<pre>
resolve_fragments_NTAMRT(
  obj,
  sample_id = NULL,
  generation_type = NULL,
  fragments_in = "annotation",
  fragments_table = "annotated_fragments",
  fragments_norm_table = ref_table_from_map(fragments_table, "fragment_id"),
  fragments_sources_table = "fragment_sources",
  citation_info_in = "fragment_citation",
  inspection_info_in = "fragment_inspections",
  inspection_table = "fragment_inspections",
  generate_missing_aliases = FALSE,
  fragment_aliases_in = "fragment_aliases",
  fragment_aliases_table = "fragment_aliases",
  alias_type_norm_table = ref_table_from_map(fragment_aliases_table, "alias_type"),
  inchi_prefix = "InChI=1S/",
  rdkit_name = ifelse(exists("PYENV_NAME"), PYENV_NAME, "rdkit"),
  rdkit_ref = ifelse(exists("PYENV_REF"), PYENV_REF, "rdk"),
  rdkit_ns = "rdk",
  rdkit_make_if_not = TRUE,
  rdkit_aliases = c("Inchi", "InchiKey"),
  mol_to_prefix = "MolTo",
  mol_from_prefix = "MolFrom",
  type = "smiles",
  import_map = IMPORT_MAP,
  case_sensitive = FALSE,
  fuzzy = FALSE,
  strip_na = TRUE,
  db_conn = con,
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>obj</code>
</td>
<td>
<p>
LIST object containing data formatted from the import generator
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>sample_id</code>
</td>
<td>
<p>
INT scalar matching a sample ID to which to tie these
fragments (optional, default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>generation_type</code>
</td>
<td>
<p>
CHR scalar containing the generation type as defined
in the “norm_generation_type” table (default: NULL will obtain the
generation type attached to the ‘sample_id’ by database lookup)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fragments_in</code>
</td>
<td>
<p>
CHR scalar name of the ‘obj’ component holding annotated
fragment information (default: “annotation”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fragments_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding
annotated fragment information (default: “annotated_fragments”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fragments_norm_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding
normalized fragment identities (default: obtains this from the result of a
call to [<a href="appendix-function-reference.html#fn_def_er_map">er_map</a>] with the table name from ‘fragments_table’)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fragments_sources_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding
fragment source (e.g. generation) information (default: “fragment_sources”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>citation_info_in</code>
</td>
<td>
<p>
CHR scalar name of the ‘obj’ component holding
fragment citation information (default: “fragment_citation”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>inspection_info_in</code>
</td>
<td>
<p>
CHR scalar name of the ‘obj’ component holding
fragment inspection information (default: “fragment_inspections”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>inspection_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding
fragment inspection information (default: “fragment_inspections”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>generate_missing_aliases</code>
</td>
<td>
<p>
LGL scalar determining whether or not to
generate machine readable expressions (e.g. InChI) for fragment aliases
from RDKit (requires RDKit activation; default: FALSE); see formals list
for [<a href="appendix-function-reference.html#fn_def_add_rdkit_aliases">add_rdkit_aliases</a>]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fragment_aliases_in</code>
</td>
<td>
<p>
CHR scalar name of the ‘obj’ component holding
fragment aliases (default: “fragment_aliases”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fragment_aliases_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding
fragment aliases (default: “fragment_aliases”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>rdkit_ref</code>
</td>
<td>
<p>
CHR scalar OR R object of an RDKit binding (default NULL
goes to “rdk” for convenience with other pipelines in this project)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>mol_to_prefix</code>
</td>
<td>
<p>
CHR scalar of the prefix to identify an RDKit function
to create an alias from a mol object (default: “MolTo”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>mol_from_prefix</code>
</td>
<td>
<p>
CHR scalar of the prefix to identify an RDKit function
to create a mol object from’identifiers’ (default: “MolFrom”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>type</code>
</td>
<td>
<p>
CHR scalar of the type of encoding to use for ‘identifiers’
(default: smiles)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>import_map</code>
</td>
<td>
<p>
data.frame object of the import map (e.g. from a CSV)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>case_sensitive</code>
</td>
<td>
<p>
LGL scalar of whether to match on a case sensitive
basis (the default TRUE searches for values as-provided) or whether to
coerce value matches by upper, lower, sentence, and title case matches
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fuzzy</code>
</td>
<td>
<p>
LGL scalar of whether to do a “fuzzy” match in the sense that
values provided are wrapped in an SQL “LIKE ’
the ‘case_sensitive’ setting if TRUE (default: FALSE).
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use (default: “db”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fragment_alias_type_norm_table</code>
</td>
<td>
<p>
CHR scalar name of the database table
holding normalized fragment alias type identities (default: obtains this
from the result of a call to [<a href="appendix-function-reference.html#fn_def_er_map">er_map</a>] with the table name from
‘fragment_aliases_table’)
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
Fragments missing structure annotation are supported (e.g. those with a
formula but no SMILES notation provided).
</p>
<p>
For new fragments, the calculated molecular mass is generated by
[calculate.monoisotope] from exact masses of each constituent atom. If RDKit
is available and a SMILES notation is provided, the formal molecular net
charge is also calculated via rdkit.Chem.GetFormalCharge.
</p>
<p>
Database tables affected by resolving the fragments node include:
annotated_fragments, norm_fragments, fragment_inspections, fragment_aliases,
and fragment_sources.
</p>
<h3>
Value
</h3>
<p>
INT vector of resolved annotated fragment IDs; executes database
actions
</p>
<h3>
Note
</h3>
<p>
This function is called as part of [full_import()]
</p>
<p>
If components named in ‘citation_info_in’ and ‘inspection_info_in’ do
not exist, that information will not be appended to the resulting database
records.
</p>
<p>
Typical usage as part of the import workflow involves simply passing
the import object and associated sample id: resolve_fragments_NTAMRT(obj =
import_object, sample_id = 1), though wrapper functions like [<a href="appendix-function-reference.html#fn_def_full_import">full_import</a>]
also contain name-matched arguments to be passed in a [do.call] context.
</p>
<hr/>
<table id="fn_def_resolve_method" width="100%" summary="page for resolve_method">
<tr>
<td>
resolve_method
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Add an ms_method record via import
</h2>
<h3>
Description
</h3>
<p>
Part of the data import routine. Adds a record to the “ms_methods” table with
the values provided in the JSON import template. Makes extensive uses of
[<a href="appendix-function-reference.html#fn_def_resolve_normalization_value">resolve_normalization_value</a>] to parse foreign key relationships.
</p>
<h3>
Usage
</h3>
<pre>
resolve_method(
  obj,
  method_in = "massspectrometry",
  ms_methods_table = "ms_methods",
  db_conn = con,
  ensure_unique = TRUE,
  log_ns = "db",
  qc_method_in = "qcmethod",
  qc_search_text = "QC Method Used",
  qc_value_in = "value",
  require_all = TRUE,
  import_map = IMPORT_MAP,
  ...
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>obj</code>
</td>
<td>
<p>
LIST object containing data formatted from the import generator
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>method_in</code>
</td>
<td>
<p>
CHR scalar name of the ‘obj’ list containing method
information
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms_methods_table</code>
</td>
<td>
<p>
CHR scalar name of the database table containing
method information
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ensure_unique</code>
</td>
<td>
<p>
LGL scalar of whether or not to first check that the
values provided form a new unique record (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use (default: “db”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>qc_method_in</code>
</td>
<td>
<p>
CHR scalar name of the import object element containing
QC method information (default: “qcmethod”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>qc_search_text</code>
</td>
<td>
<p>
CHR scalar name of an element in the import object in
part ‘qc_method_in’ identifying whether or not a QC method was used
(default: “QC Method Used”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>qc_value_in</code>
</td>
<td>
<p>
CHR scalar name of an element in the import object
corresponding to ‘qc_method_in’ where the value of the metric named for
‘qc_search_text’ is located (default: “value”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>require_all</code>
</td>
<td>
<p>
LGL scalar of whether to require all columns (except the
assumed primary key column of “id”) or only those defined as “NOT NULL”
(default: TRUE requires the presence of all columns in the table)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>import_map</code>
</td>
<td>
<p>
data.frame object of the import map (e.g. from a CSV)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>…</code>
</td>
<td>
<p>
Other named elements to be appended to “ms_methods” as necessary
for workflow resolution, can be used to pass defaults or additional values.
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
INT scalar if successful, result of the call to [<a href="appendix-function-reference.html#fn_def_add_or_get_id">add_or_get_id</a>]
otherwise
</p>
<h3>
Note
</h3>
<p>
This function is called as part of [full_import()]
</p>
<hr/>
<table id="fn_def_resolve_mobile_phase_NTAMRT" width="100%" summary="page for resolve_mobile_phase_NTAMRT">
<tr>
<td>
resolve_mobile_phase_NTAMRT
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Resolve the mobile phase node
</h2>
<h3>
Description
</h3>
<p>
The database node containing chromatographic method information is able to
handle any number of descriptive aspects regarding chromatography. It houses
normalized and aliased data in a manner that maximizes flexibility, allowing
any number of carrier agents (e.g. gasses for GC, solvents for LC) to be
described in increasing detail. To accommodate that, the structure itself may
be unintuitive and may not map well as records may be heavily nested.
</p>
<h3>
Usage
</h3>
<pre>
resolve_mobile_phase_NTAMRT(
  obj,
  method_id,
  sample_id,
  peak_id,
  carrier_mix_names = NULL,
  id_mix_by = "^mp*[0-9]+",
  ms_methods_table = "ms_methods",
  sample_table = "samples",
  peak_table = "peaks",
  db_conn = con,
  mix_collection_table = "carrier_mix_collections",
  mobile_phase_props = list(in_item = "chromatography", db_table = "mobile_phases", props
    = c(flow = "flow", flow_units = "flowunits", duration = "duration", duration_units =
    "durationunits")),
  carrier_props = list(db_table = "carrier_mixes", norm_by = "norm_carriers", alias_in =
    "carrier_aliases", props = c(id_by = "solvent", fraction_by = "fraction")),
  additive_props = list(db_table = "carrier_additives", norm_by = "norm_additives",
    alias_in = "additive_aliases", props = c(id_by = "add$", amount_by = "_amount",
    units_by = "_units")),
  exclude_values = c("none", "", NA),
  fuzzy = TRUE,
  clean_up = TRUE,
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>obj</code>
</td>
<td>
<p>
LIST object containing data formatted from the import generator
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>method_id</code>
</td>
<td>
<p>
INT scalar of the method id (e.g. from the import workflow)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>sample_id</code>
</td>
<td>
<p>
INT scalar of the sample id (e.g. from the import workflow)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_id</code>
</td>
<td>
<p>
INT scalar of the peak id (e.g. from the import workflow)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>carrier_mix_names</code>
</td>
<td>
<p>
CHR vector (optional) of carrier mix collection
names to assign, the length of which should equal 1 or the length of
discrete carrier mixtures; the default, NULL, will automatically assign
names as a function of the method and sample id.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>id_mix_by</code>
</td>
<td>
<p>
CHR scalar regex to identify the elements of ‘obj’ to use
for the mobile phase node (default “^mp*[0-9]+“) grouping of carrier mix
collections, this is the main piece of connectivity pulling together the
descriptions and should only be changed to match different import naming
schemes
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms_methods_table</code>
</td>
<td>
<p>
CHR scalar name of the methods table (default:
“ms_methods”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>sample_table</code>
</td>
<td>
<p>
CHR scalar name of the samples table (default: “samples”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_table</code>
</td>
<td>
<p>
CHR scalar name of the peaks table (default: “peaks”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
existing connection object (e.g. of class “SQLiteConnection”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>mix_collection_table</code>
</td>
<td>
<p>
CHR scalar name of the mix collections table
(default: “carrier_mix_collections”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>mobile_phase_props</code>
</td>
<td>
<p>
LIST object describing how to import the mobile
phase table containing: in_item: CHR scalar name of the ‘obj’ name
containing chromatographic information (default: “chromatography”);
db_table: CHR scalar name of the mobile phases table (default:
“mobile_phases”); props: named CHR vector of name mappings with names equal
to database columns in ‘mobile_phase_props<span class="math inline">\(db_table&#39; and values matching regex to match names in &#39;obj[[mobile_phase_props\)</span>in_item]]’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>carrier_props</code>
</td>
<td>
<p>
LIST object describing how to import the mobile phase
table containing: db_table: CHR scalar name of the mobile phases table
(default: “mobile_phases”); norm_table: CHR scalar name of the table used
to normalize carriers (default: “norm_carriers”); alias_table: CHR scalar
name of the table containing carrier aliases to search (default:
“carrier_aliases”); props: named CHR vector of name mappings with names
equal to database columns in ‘carrier_props<span class="math inline">\(db_table&#39; and values matching regex to match names in &#39;obj[[mobile_phase_props\)</span>in_item]]’, and an extra
element named ‘id_by’ containing regex used to match names in the import
object indicate a carrier (e.g. “solvent”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>additive_props</code>
</td>
<td>
<p>
LIST object describing how to import the mobile phase
table containing: db_table: CHR scalar name of the mobile phases table
(default: “mobile_phases”); norm_table: CHR scalar name of the table used
to normalize carriers (default: “norm_additives”); alias_table: CHR scalar
name of the table containing carrier aliases to search (default:
“additive_aliases”); props: named CHR vector of name mappings with names
equal to database columns in ‘additive_props<span class="math inline">\(db_table&#39; and values matching regex to match names in &#39;obj[[mobile_phase_props\)</span>in_item]]’
‘obj[[mobile_phase_props<span class="math inline">\(in_item]][[mobile_phase_props\)</span>db_table]]’, and an
extra element named ‘id_by’ containing regex used to match names in the
import object indicate an additive (e.g. names terminating in “add”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>exclude_values</code>
</td>
<td>
<p>
CHR vector indicating which values to ignore in ‘obj’
(default: c(“none”, ““, NA))
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fuzzy</code>
</td>
<td>
<p>
LGL scalar of whether to do a “fuzzy” match in the sense that
values provided are wrapped in an SQL SQL LIKE clause bookended with wildcards;
overrides the ‘case_sensitive’ setting if TRUE (default: FALSE).
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>clean_up</code>
</td>
<td>
<p>
LGL scalar determining whether or not to clean up the
‘mix_collection_table’ by removing just-added records if there are errors
adding to ‘carrier_props$db_table’ (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use during execution
(default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
The mobile phase node contains one record in table “mobile_phases” for each
method id, sample id, and carrier mix collection id with its associated flow
rate, normalized flow units, duration, and normalized duration units. Each
carrier mix collection has a name and child tables containing: records for
each value normalized carrier component and its unit fraction (e.g. in
carrier_mixes: Helium 1 would indicate pure Helium as a carrier gas in GC
work; Water, 0.9; Methanol, 0.1 to indicate a solvent mixture of 10
in water), as well as value normalized carrier additives, their amount, and
the units for that amount (mostly for LC work; e.g. in carrier_additives:
ammonium acetate, 5, mMol to indicate an additive to a solvent of 5 mMol
ammonium acetate); these are linked through the carrier mix collection id.
</p>
<p>
Call this function to import the results of the NIST Non-Targeted Analysis
Method Reporting Tool (NTA MRT), or feed it as ‘obj’ a flat list containing
chromatography information.
</p>
<h3>
Value
</h3>
<p>
None, executes actions on the database
</p>
<h3>
Note
</h3>
<p>
This is a brittle function, and should only be used as part of the NTA
MRT import process, or as a template for how to import data.
</p>
<p>
Some arguments are complicated by design to keep conceptual information
together. These should be fed a structured list matching expectations. This
applies to ‘mobile_phase_props’, ‘carrier_props’, and ‘additive_props’. See
defaults in documentation for examples.
</p>
<p>
Database insertions are done in real time, so failures may result in
hanging or orphaned records. Turn on ‘clean_up’ to roll back by removing
entries from ‘mix_collection_table’ and relying on delete cascades built
into the database. Additional names are provided here to match the schema.
</p>
<p>
This function is called as part of [full_import()]
</p>
<hr/>
<table id="fn_def_resolve_ms_data" width="100%" summary="page for resolve_ms_data">
<tr>
<td>
resolve_ms_data
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Resolve and store mass spectral data during import
</h2>
<h3>
Description
</h3>
<p>
Use peak IDs generated by the import workflow to assign and store mass
spectral data (if coming from the NIST NTA Method Reporting Tool, these will
all be in the “separated” format). Optionally also calls [<a href="appendix-function-reference.html#fn_def_resolve_ms_spectra">resolve_ms_spectra</a>]
if unpack_spectra = TRUE. Mass spectral data are stored in either one
(“zipped”)
</p>
<h3>
Usage
</h3>
<pre>
resolve_ms_data(
  obj,
  peak_id = NULL,
  peaks_table = "peaks",
  ms_data_in = "msdata",
  ms_data_table = "ms_data",
  unpack_spectra = FALSE,
  ms_spectra_table = "ms_spectra",
  unpack_format = c("separated", "zipped"),
  as_object = FALSE,
  import_map = IMPORT_MAP,
  db_conn = con,
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>obj</code>
</td>
<td>
<p>
LIST object containing data formatted from the import generator
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_id</code>
</td>
<td>
<p>
INT scalar of the peak ID in question, which must be present
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peaks_table</code>
</td>
<td>
<p>
CHR scalar name of the peaks table in the database
(default: “peaks”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms_data_in</code>
</td>
<td>
<p>
CHR scalar of the named component of ‘obj’ holding mass
spectral data (default: “msdata”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms_data_table</code>
</td>
<td>
<p>
CHR scalar name of the table holding packed spectra in
the database (default: “ms_data”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>unpack_spectra</code>
</td>
<td>
<p>
LGL scalar indicating whether or not to unpack spectral
data to a long format (i.e. all masses and intensities will become a single
record) in the table defined by ‘ms_spectra_table’ (default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms_spectra_table</code>
</td>
<td>
<p>
CHR scalar name of the table holding long form
spectra in the database (default: “ms_spectra”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>unpack_format</code>
</td>
<td>
<p>
CHR scalar of the type of data packing for the spectra,
one of “separated” (default) or “zipped”
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>as_object</code>
</td>
<td>
<p>
LGL scalar indicating whether or not to return the result to
the session as an object (TRUE) or to add it to the database (default:
FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>import_map</code>
</td>
<td>
<p>
data.frame object of the import map (e.g. from a CSV)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use (default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
If ‘as_object’ == TRUE, a data.frame object containing either packed
(if ‘unpack_spectra’ == FALSE) or unpacked (if ‘unpack_spectra’ == TRUE)
spectra, otherwise adds spectra to the database
</p>
<h3>
Note
</h3>
<p>
This function is called as part of [full_import()] during the call to
[<a href="appendix-function-reference.html#fn_def_resolve_peaks">resolve_peaks</a>]
</p>
<hr/>
<table id="fn_def_resolve_ms_spectra" width="100%" summary="page for resolve_ms_spectra">
<tr>
<td>
resolve_ms_spectra
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Unpack mass spectral data in compressed format
</h2>
<h3>
Description
</h3>
<p>
For some spectra, searching in a long form is much more performant. Use this
function to unpack data already present in the ‘ms_data’ table into the
‘ms_spectra’ table. Data should be packed in one of two ways, either two
columns for mass-to-charge ratio and intensity (“separated” - see
[<a href="appendix-function-reference.html#fn_def_ms_spectra_separated">ms_spectra_separated</a>]) or in a single column with interleaved data (“zipped”
- see [<a href="appendix-function-reference.html#fn_def_ms_spectra_zipped">ms_spectra_zipped</a>]).
</p>
<h3>
Usage
</h3>
<pre>
resolve_ms_spectra(
  peak_id,
  spectra_data = NULL,
  peaks_table = "peaks",
  ms_data_table = "ms_data",
  ms_spectra_table = "ms_spectra",
  unpack_format = c("separated", "zipped"),
  as_object = FALSE,
  db_conn = con,
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>peak_id</code>
</td>
<td>
<p>
INT scalar of the peak ID in question, which must be present
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_data</code>
</td>
<td>
<p>
data.frame object containing spectral data
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peaks_table</code>
</td>
<td>
<p>
CHR scalar name of the peaks table in the database
(default: “peaks”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms_data_table</code>
</td>
<td>
<p>
CHR scalar name of the table holding packed spectra in
the database (default: “ms_data”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms_spectra_table</code>
</td>
<td>
<p>
CHR scalar name of the table holding long form
spectra in the database (default: “ms_spectra”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>unpack_format</code>
</td>
<td>
<p>
CHR scalar of the type of data packing for the spectra,
one of “separated” (default) or “zipped”
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>as_object</code>
</td>
<td>
<p>
LGL scalar of whether to return the unpacked spectra to the
session (default: TRUE) or to insert into the database (FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
database connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar name of the logging namespace to use
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
If ‘as_object’ == TRUE, a data.frame of unpacked spectra, otherwise
no return and a database insertion will be performed
</p>
<h3>
Note
</h3>
<p>
This function may be slow, especially with peaks containing a large
number of scans or a large amount of data
</p>
<h3>
References
</h3>
<p>
ms_spectra_separated
</p>
<p>
ms_spectra_zipped
</p>
<hr/>
<table id="fn_def_resolve_multiple_values" width="100%" summary="page for resolve_multiple_values">
<tr>
<td>
resolve_multiple_values
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Utility function to resolve multiple choices interactively
</h2>
<h3>
Description
</h3>
<p>
This function is generally not called directly, but rather as a workflow
component from within [<a href="appendix-function-reference.html#fn_def_resolve_normalization_value">resolve_normalization_value</a>] during interactive
sessions to get feedback from users during the normalization value resolution
process.
</p>
<h3>
Usage
</h3>
<pre>
resolve_multiple_values(values, search_value, as_regex = FALSE, db_table = "")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>values</code>
</td>
<td>
<p>
CHR vector of possible values
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>search_value</code>
</td>
<td>
<p>
CHR scalar of the value to search
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>as_regex</code>
</td>
<td>
<p>
LGL scalar of whether to treat ‘search_value’ as a regular
expression string (TRUE) or to use it directly (FALSE, default)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_table</code>
</td>
<td>
<p>
CHR scalar name of the database table to search, used for
printing log messages only (default: ““)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
CHR scalar result of the user’s choice
</p>
<hr/>
<table id="fn_def_resolve_normalization_value" width="100%" summary="page for resolve_normalization_value">
<tr>
<td>
resolve_normalization_value
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Resolve a normalization value against the database
</h2>
<h3>
Description
</h3>
<p>
Normalized SQL databases often need to resolve primary keys. This function
checks for a given value in a given table and either returns the matching
index value or, if a value is not found and ‘interactive()’ is TRUE, it will
add that value to the table and return the new index value. It will look for
the first matching value in all columns of the requested table to support
loose finding of identifiers and is meant to operate only on normalization
tables (i.e. look up tables).
</p>
<h3>
Usage
</h3>
<pre>
resolve_normalization_value(
  this_value,
  db_table,
  id_column = "id",
  case_sensitive = FALSE,
  fuzzy = FALSE,
  db_conn = con,
  log_ns = "db",
  ...
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>this_value</code>
</td>
<td>
<p>
CHR (or coercible to) scalar value to look up
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_table</code>
</td>
<td>
<p>
CHR scalar of the database table to search
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>case_sensitive</code>
</td>
<td>
<p>
LGL scalar of whether to match on a case sensitive
basis (the default TRUE searches for values as-provided) or whether to
coerce value matches by upper, lower, sentence, and title case matches
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fuzzy</code>
</td>
<td>
<p>
LGL scalar of whether to do a “fuzzy” match in the sense that
values provided are wrapped in an SQL “LIKE ’
the ‘case_sensitive’ setting if TRUE (default: FALSE).
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use during execution
(default: “db”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>…</code>
</td>
<td>
<p>
other values to add to the normalization table, where names must
match the table schema
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
The search itself is done using [<a href="appendix-function-reference.html#fn_def_check_for_value">check_for_value</a>].
</p>
<h3>
Value
</h3>
<p>
The database primary key (typically INT) of the normalized value
</p>
<h3>
Note
</h3>
<p>
This is mostly a DRY convenience function to avoid having to write the
loookup and add logic each time.
</p>
<p>
Interactive sessions are required to add new values
</p>
<hr/>
<table id="fn_def_resolve_peak_ums_params" width="100%" summary="page for resolve_peak_ums_params">
<tr>
<td>
resolve_peak_ums_params
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Resolve and import optimal uncertain mass spectrum parameters
</h2>
<h3>
Description
</h3>
<p>
This imports the defined object component containing parameters for the
optimized uncertainty mass spectrum used to compare with new data. This
function may be called at any time to add data for a given peak, but there is
no row unique restriction on the underlying table and is best used in a “one
pass” method during the import routine. These parameters are calculated as
part of NIST QA procedures and are added to the output of the NTA MRT after
those JSONs have been created.
</p>
<h3>
Usage
</h3>
<pre>
resolve_peak_ums_params(
  obj,
  peak_id,
  ums_params_in = "opt_ums_params",
  ums_params_table = "opt_ums_params",
  db_conn = con,
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>obj</code>
</td>
<td>
<p>
LIST object containing data formatted from the import generator
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_id</code>
</td>
<td>
<p>
INT scalar of the peak ID in question, which must be present
(e.g. from the import workflow)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ums_params_in</code>
</td>
<td>
<p>
CHR scalar name of the item in ‘obj’ containing
optimized uncertainty mass spectrum parameters
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ums_params_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding
optimized uncertainty mass spectrum parameters
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use during execution
(default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
Nothing if successful, a data frame object of the extracted
parameters otherwise.
</p>
<h3>
Note
</h3>
<p>
This function is called as part of [resolve_peaks()]
</p>
<hr/>
<table id="fn_def_resolve_peaks" width="100%" summary="page for resolve_peaks">
<tr>
<td>
resolve_peaks
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Resolve the peaks node during import
</h2>
<h3>
Description
</h3>
<p>
Call this function to resolve and insert information for the “peaks” node in
the database including software conversion settings (via
[<a href="appendix-function-reference.html#fn_def_resolve_software_settings_NTAMRT">resolve_software_settings_NTAMRT</a>]) and mass spectra data (via
[<a href="appendix-function-reference.html#fn_def_resolve_ms_data">resolve_ms_data</a>] and, optionally, [<a href="appendix-function-reference.html#fn_def_resolve_ms_spectra">resolve_ms_spectra</a>]). This function
relies on the import object being formatted appropriately.
</p>
<h3>
Usage
</h3>
<pre>
resolve_peaks(
  obj,
  sample_id,
  peaks_table = "peaks",
  software_timestamp = NULL,
  software_settings_in = "msconvertsettings",
  ms_data_in = "msdata",
  ms_data_table = "ms_data",
  unpack_spectra = FALSE,
  unpack_format = c("separated", "zipped"),
  ms_spectra_table = "ms_spectra",
  linkage_table = "conversion_software_peaks_linkage",
  settings_table = "conversion_software_settings",
  as_date_format = "%Y-%m-%d %H:%M:%S",
  format_checks = c("ymd_HMS", "ydm_HMS", "mdy_HMS", "dmy_HMS"),
  min_datetime = "2000-01-01 00:00:00",
  import_map = IMPORT_MAP,
  ums_params_in = "opt_ums_params",
  ums_params_table = "opt_ums_params",
  db_conn = con,
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>obj</code>
</td>
<td>
<p>
CHR vector describing settings or a named LIST with names matching
column names in table conversion_software_settings.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>sample_id</code>
</td>
<td>
<p>
INT scalar of the sample id (e.g. from the import workflow)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peaks_table</code>
</td>
<td>
<p>
CHR scalar of the database table name holding QC method check
information (default: “peaks”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms_data_in</code>
</td>
<td>
<p>
CHR scalar of the named component of ‘obj’ holding mass
spectral data (default: “msdata”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms_data_table</code>
</td>
<td>
<p>
CHR scalar name of the table holding packed spectra in
the database (default: “ms_data”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>unpack_spectra</code>
</td>
<td>
<p>
LGL scalar indicating whether or not to unpack spectral
data to a long format (i.e. all masses and intensities will become a single
record) in the table defined by ‘ms_spectra_table’ (default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>unpack_format</code>
</td>
<td>
<p>
CHR scalar of the type of data packing for the spectra,
one of “separated” (default) or “zipped”
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms_spectra_table</code>
</td>
<td>
<p>
CHR scalar name of the table holding long form
spectra in the database (default: “ms_spectra”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>import_map</code>
</td>
<td>
<p>
data.frame object of the import map (e.g. from a CSV)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ums_params_in</code>
</td>
<td>
<p>
CHR scalar name of the item in ‘obj’ containing
optimized uncertainty mass spectrum parameters
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ums_params_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding
optimized uncertainty mass spectrum parameters
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
Connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use (default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
INT scalar of the newly inserted or identified peak ID(s)
</p>
<h3>
Note
</h3>
<p>
This function is called as part of [full_import()]
</p>
<p>
This function relies on an import map
</p>
<hr/>
<table id="fn_def_resolve_qc_data_NTAMRT" width="100%" summary="page for resolve_qc_data_NTAMRT">
<tr>
<td>
resolve_qc_data_NTAMRT
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Resolve and import quality control data for import
</h2>
<h3>
Description
</h3>
<p>
This imports the defined object component containing QC data (i.e. a nested
list of multiple quality control checks) from the NIST Non-Targeted Analysis
Method Reporting Tool (NTA MRT).
</p>
<h3>
Usage
</h3>
<pre>
resolve_qc_data_NTAMRT(
  obj,
  peak_id,
  qc_data_in = "qc",
  qc_data_table = "qc_data",
  peaks_table = "peaks",
  ignore = FALSE,
  db_conn = con,
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>obj</code>
</td>
<td>
<p>
LIST object containing data formatted from the import generator
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_id</code>
</td>
<td>
<p>
INT vector of the peak ids (e.g. from the import workflow)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>qc_data_in</code>
</td>
<td>
<p>
CHR scalar name of the component in ‘obj’ containing QC
data (default: “qc”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>qc_data_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding QC data
(default: “qc_data”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peaks_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding peaks data
(default: “peaks”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use during execution
(default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, executes actions on the database
</p>
<h3>
Note
</h3>
<p>
This function is called as part of [full_import()]
</p>
<hr/>
<table id="fn_def_resolve_qc_methods_NTAMRT" width="100%" summary="page for resolve_qc_methods_NTAMRT">
<tr>
<td>
resolve_qc_methods_NTAMRT
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Resolve and import quality control method information
</h2>
<h3>
Description
</h3>
<p>
This imports the defined object component containing QC method information
(i.e. a data frame of multiple quality control checks) from the NIST
Non-Targeted Analysis Method Reporting Tool (NTA MRT).
</p>
<h3>
Usage
</h3>
<pre>
resolve_qc_methods_NTAMRT(
  obj,
  peak_id,
  qc_method_in = "qcmethod",
  qc_method_table = "qc_methods",
  qc_method_norm_table = "norm_qc_methods_name",
  qc_method_norm_reference = "norm_qc_methods_reference",
  qc_references_in = "source",
  peaks_table = "peaks",
  ignore = FALSE,
  db_conn = con,
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>obj</code>
</td>
<td>
<p>
LIST object containing data formatted from the import generator
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peak_id</code>
</td>
<td>
<p>
INT vector of the peak ids (e.g. from the import workflow)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>qc_method_in</code>
</td>
<td>
<p>
CHR scalar of the name in ‘obj’ that contains QC method
check information (default: “qcmethod”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>qc_method_table</code>
</td>
<td>
<p>
CHR scalar of the database table name holding QC
method check information (default: “qc_methods”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>qc_method_norm_table</code>
</td>
<td>
<p>
CHR scalar name of the database table normalizing
QC methods type (default: “norm_qc_methods_name”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>qc_method_norm_reference</code>
</td>
<td>
<p>
CHR scalar name of the database table
normalizing QC methods reference type (default:
“norm_qc_methods_reference”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>qc_references_in</code>
</td>
<td>
<p>
CHR scalar of the name in ‘obj[[qc_method_in]]’ that
contains the reference or citation for the QC protocol (default: “source”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>peaks_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding sample
information (default: “samples”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use during execution
(default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, executes actions on the database
</p>
<h3>
Note
</h3>
<p>
This function is called as part of [full_import()]
</p>
<hr/>
<table id="fn_def_resolve_sample" width="100%" summary="page for resolve_sample">
<tr>
<td>
resolve_sample
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Add a sample via import
</h2>
<h3>
Description
</h3>
<p>
Part of the data import routine. Adds a record to the “samples” table with
the values provided in the JSON import template. Uses [verify_sample_class]
and [verify_contributor] to parse foreign key relationships, [<a href="appendix-function-reference.html#fn_def_resolve_method">resolve_method</a>]
to add a record to ms_methods to get the proper id, and
[<a href="appendix-function-reference.html#fn_def_resolve_software_settings_NTAMRT">resolve_software_settings_NTAMRT</a>] to insert records into and get the proper
conversion software linkage id from tables “conversion_software_settings” and
“conversion_software_linkage” if appropriate.
</p>
<h3>
Usage
</h3>
<pre>
resolve_sample(
  obj,
  db_conn = con,
  method_id = NULL,
  sample_in = "sample",
  sample_table = "samples",
  generation_type = NULL,
  generation_type_default = "empirical",
  generation_type_norm_table = "norm_generation_type",
  import_map = IMPORT_MAP,
  ensure_unique = TRUE,
  require_all = TRUE,
  fuzzy = FALSE,
  case_sensitive = TRUE,
  log_ns = "db",
  ...
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>obj</code>
</td>
<td>
<p>
LIST object containing data formatted from the import generator
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>method_id</code>
</td>
<td>
<p>
INT scalar of the associated ms_methods record id
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>sample_in</code>
</td>
<td>
<p>
CHR scalar of the import object name storing sample data
(default: “sample”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>sample_table</code>
</td>
<td>
<p>
CHR scalar name of the database table holding sample
information (default: “samples”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>generation_type</code>
</td>
<td>
<p>
CHR scalar of the type of data generated for this
sample (e.g. “empirical” or “in silico”). The default (NULL) will assign
based on ‘generation_type_default’; any other value will override the
default value and be checked against values in ‘geneation_type_norm_table’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>generation_type_default</code>
</td>
<td>
<p>
CHR scalar naming the default data generation
type (default: “empirical”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>generation_type_norm_table</code>
</td>
<td>
<p>
CHR scalar name of the database table
normalizing sample generation type (default: “empirical”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>import_map</code>
</td>
<td>
<p>
data.frame object of the import map (e.g. from a CSV)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ensure_unique</code>
</td>
<td>
<p>
LGL scalar of whether or not to first check that the
values provided form a new unique record (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>require_all</code>
</td>
<td>
<p>
LGL scalar of whether to require all columns (except the
assumed primary key column of “id”) or only those defined as “NOT NULL”
(default: TRUE requires the presence of all columns in the table)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fuzzy</code>
</td>
<td>
<p>
LGL scalar of whether to do a “fuzzy” match in the sense that
values provided are wrapped in an SQL “LIKE ’
the ‘case_sensitive’ setting if TRUE (default: FALSE).
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>case_sensitive</code>
</td>
<td>
<p>
LGL scalar of whether to match on a case sensitive
basis (the default TRUE searches for values as-provided) or whether to
coerce value matches by upper, lower, sentence, and title case matches
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use (default: “db”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>…</code>
</td>
<td>
<p>
Other named elements to be appended to samples as necessary for
workflow resolution, can be used to pass defaults or additional values.
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
INT scalar if successful, result of the call to [<a href="appendix-function-reference.html#fn_def_add_or_get_id">add_or_get_id</a>]
otherwise
</p>
<h3>
Note
</h3>
<p>
This function is called as part of [full_import()]
</p>
<hr/>
<table id="fn_def_resolve_sample_aliases" width="100%" summary="page for resolve_sample_aliases">
<tr>
<td>
resolve_sample_aliases
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Resolve and import sample aliases
</h2>
<h3>
Description
</h3>
<p>
Call this function to attach sample aliases to a sample record in the
database. This can be done either through the import object with a name
reference or directly by assigning additional values.
</p>
<h3>
Usage
</h3>
<pre>
resolve_sample_aliases(
  sample_id,
  obj = NULL,
  aliases_in = NULL,
  values = NULL,
  db_table = "sample_aliases",
  db_conn = con,
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>sample_id</code>
</td>
<td>
<p>
INT scalar of the sample id (e.g. from the import workflow)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>obj</code>
</td>
<td>
<p>
(optional) LIST object containing data formatted from the import
generator (default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>aliases_in</code>
</td>
<td>
<p>
(optional) CHR scalar of the name in ‘obj’ containing the
sample aliases in list format (default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>values</code>
</td>
<td>
<p>
(optional) LIST containing the sample aliases with names as the
alias name and values containing the reference (e.g. URI, link to a
containing repository, or reference to the owner or project from which a
sample is drawn) to that alias
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_table</code>
</td>
<td>
<p>
CHR scalar name of the database table containing sample
aliases (default: “sample_aliases”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use during execution
(default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, executes actions on the database
</p>
<h3>
Note
</h3>
<p>
This function is called as part of [full_import()]
</p>
<p>
One of ‘values’ or both of ‘obj’ and ‘aliases_in’ must be provided to
add new sample aliases.
</p>
<hr/>
<table id="fn_def_resolve_software_settings_NTAMRT" width="100%" summary="page for resolve_software_settings_NTAMRT">
<tr>
<td>
resolve_software_settings_NTAMRT
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Import software settings
</h2>
<h3>
Description
</h3>
<p>
Part of the standard import pipeline, adding rows to the
‘conversion_software_settings’ table with a given sample id. Some argument
names are shared with other import functions, specifically ‘obj’ but are
formed differently to resolve the node complexity correctly.
</p>
<h3>
Usage
</h3>
<pre>
resolve_software_settings_NTAMRT(
  obj,
  software_timestamp = NULL,
  db_conn = con,
  software_settings_in = "msconvertsettings",
  settings_table = "conversion_software_settings",
  linkage_table = "conversion_software_peaks_linkage",
  as_date_format = "%Y-%m-%d %H:%M:%S",
  format_checks = c("ymd_HMS", "ydm_HMS", "mdy_HMS", "dmy_HMS"),
  min_datetime = "2000-01-01 00:00:00",
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>obj</code>
</td>
<td>
<p>
CHR vector describing settings or a named LIST with names matching
column names in table conversion_software_settings.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>software_timestamp</code>
</td>
<td>
<p>
CHR scalar of the sample timestamp (e.g.
sample$starttime) to use for linking software conversion settings with peak
data, with a call back to the originating sample. If NULL (the default),
the current system timestamp in UTC will be used from [lubridate::now()].
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>software_settings_in</code>
</td>
<td>
<p>
CHR scalar name of the component in ‘obj’
containing software settings (default: “msconvertsettings”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>settings_table</code>
</td>
<td>
<p>
CHR scalar name of the database table containing the
software settings used for an imported data file (default:
“conversion_software_settings”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>linkage_table</code>
</td>
<td>
<p>
CHR scalar name of the database table containing the
linkage between peaks and their software settings (default:
“conversion_software_peaks_linkage”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>as_date_format</code>
</td>
<td>
<p>
CHR scalar the format to use when storing timestamps
that matches database column expectations (default: “%Y-%m-%d %H:%M:%S”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>format_checks</code>
</td>
<td>
<p>
CHR vector of the [lubridate::parse_date_time()] format
checks to execute in order of priority; these must match a lubridate
function of the same name (default: c(“ymd_HMS”, “ydm_HMS”, “mdy_HMS”,
“dmy_HMS”))
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>min_datetime</code>
</td>
<td>
<p>
CHR scalar of the minimum reasonable timestamp used as a
sanity check (default: “2000-01-01 00:00:00”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use (default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
NULL on errors, INT scalar of the inserted software linkage id if
successful
</p>
<h3>
Note
</h3>
<p>
This function is called as part of [full_import()]
</p>
<hr/>
<table id="fn_def_resolve_table_name" width="100%" summary="page for resolve_table_name">
<tr>
<td>
resolve_table_name
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Check presence of a database table
</h2>
<h3>
Description
</h3>
<p>
This convenience function checks for the existence of one or more ‘db_table’
objects in a database.
</p>
<h3>
Usage
</h3>
<pre>
resolve_table_name(db_table = "compounds", db_conn = "test_con")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>db_table</code>
</td>
<td>
<p>
CHR vector of table names to check
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the namespace (if any) to use for logging
(default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
CHR vector of existing tables
</p>
<hr/>
<table id="fn_def_save_data_dictionary" width="100%" summary="page for save_data_dictionary">
<tr>
<td>
save_data_dictionary
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Save the current data dictionary to disk
</h2>
<h3>
Description
</h3>
<p>
Executes [data_dictionary()] and saves the output to a local file. If <code>output_format</code>
is one of “data.frame” or “list”, the resulting file will be saved as an RDS.
Parameter <code>output_file</code> will be used during the save process; relative paths
will be identified by the current working directory.
</p>
<h3>
Usage
</h3>
<pre>
save_data_dictionary(db_conn = con)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>output_format</code>
</td>
<td>
<p>
CHR scalar, one of (capitalization insensitive) “json”,
“csv”, “data.frame”, or “list” (default “json”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>output_file</code>
</td>
<td>
<p>
CHR scalar indicating where to save the resulting file; an
appropriate file name will be constructed if left NULL (default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>overwrite_existing</code>
</td>
<td>
<p>
LGL scalar indicating whether to overwrite an
existing file whose name matches that determined from ‘output_file’
(default: TRUE); file names will be appended with “(x)” sequentially if
this is FALSE and a file with matching name exists.
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, saves a file to the current working directory
</p>
<hr/>
<table id="fn_def_search_all" width="100%" summary="page for search_all">
<tr>
<td>
search_all
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Search all mass spectra within database against unknown mass spectrum
</h2>
<h3>
Description
</h3>
<p>
Search all mass spectra within database against unknown mass spectrum
</p>
<h3>
Usage
</h3>
<pre>
search_all(
  con,
  searchms,
  normfn = "sum",
  cormethod = "pearson",
  optimized_params = TRUE
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>con</code>
</td>
<td>
<p>
SQLite database connection
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>searchms</code>
</td>
<td>
<p>
object generated from ‘create_search_ms’ function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>normfn</code>
</td>
<td>
<p>
the normalization function typically “mean” or “sum” for normalizing the intensity values
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>cormethod</code>
</td>
<td>
<p>
the correlation method used for calculating the correlation, see ‘cor’ function for methods
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>optimized_params</code>
</td>
<td>
<p>
LGL scalar indicating whether or not to use the
optimal search parameters stored in the database table ‘opt_ums_params’
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LIST of search results
</p>
<hr/>
<table id="fn_def_search_precursor" width="100%" summary="page for search_precursor">
<tr>
<td>
search_precursor
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Search the database for all compounds with matching precursor ion m/z values
</h2>
<h3>
Description
</h3>
<p>
Search the database for all compounds with matching precursor ion m/z values
</p>
<h3>
Usage
</h3>
<pre>
search_precursor(
  con,
  searchms,
  normfn = "sum",
  cormethod = "pearson",
  optimized_params = TRUE
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>con</code>
</td>
<td>
<p>
SQLite database connection
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>searchms</code>
</td>
<td>
<p>
object generated from ‘create_search_ms’ function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>normfn</code>
</td>
<td>
<p>
the normalization function typically “mean” or “sum” for normalizing the intensity values
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>cormethod</code>
</td>
<td>
<p>
the correlation method used for calculating the correlation, see ‘cor’ function for methods
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>optimized_params</code>
</td>
<td>
<p>
LGL scalar indicating whether or not to use the
optimal search parameters stored in the database table ‘opt_ums_params’
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
table of match statistics for the compound of interest
</p>
<hr/>
<table id="fn_def_setup_rdkit" width="100%" summary="page for setup_rdkit">
<tr>
<td>
setup_rdkit
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Conveniently set up an RDKit python environment for use with R
</h2>
<h3>
Description
</h3>
<p>
Conveniently set up an RDKit python environment for use with R
</p>
<h3>
Usage
</h3>
<pre>
setup_rdkit(env_name = "nist_hrms_db", required_libraries = c("reticulate", "rdkit"), env_ref = "rdk")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>env_name</code>
</td>
<td>
<p>
CHR scalar of the name of a python environment
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>env_ref</code>
</td>
<td>
<p>
CHR scalar of the name of an R expression bound to a python
library OR an R object reference by name to an existing object that should be
bound to RDKit (e.g. from [reticulate::import])
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ns</code>
</td>
<td>
<p>
CHR scalar
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, though calls to utility functions will give their own returns
</p>
<hr/>
<table id="fn_def_sigtest" width="100%" summary="page for sigtest">
<tr>
<td>
sigtest
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Significance testing function
</h2>
<h3>
Description
</h3>
<p>
Internal function: enables significance testing between two values
</p>
<h3>
Usage
</h3>
<pre>
sigtest(x1, x2, s1, s2, n1, n2, sig = 0.95)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>x1, x2</code>
</td>
<td>
<p>
mean values to be compared
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>s1, s2</code>
</td>
<td>
<p>
standard deviation of their respective values
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>n1, n2</code>
</td>
<td>
<p>
number of observations of the respective values
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>sig</code>
</td>
<td>
<p>
significance level to test (0.95 = 95%)
</p>
</td>
</tr>
</table>
<hr/>
<table id="fn_def_smilestoformula" width="100%" summary="page for smilestoformula">
<tr>
<td>
smilestoformula
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Convert SMILES string to Formula and other information
</h2>
<h3>
Description
</h3>
<p>
The function converts SMILES strings into a data frame containing the molecular
formula (FORMULA), fixed mass of the formula (FIXED MASS), and the net charge (NETCHARGE).
</p>
<h3>
Usage
</h3>
<pre>
smilestoformula(SMILES)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>SMILES</code>
</td>
<td>
<p>
vector of SMILES strings
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data frame
</p>
<h3>
Examples
</h3>
<pre>
smilestoformula(c("CCCC", "C(F)(F)F"))

smilestoformula("CCCC")
</pre>
<hr/>
<table id="fn_def_sql_to_msp" width="100%" summary="page for sql_to_msp">
<tr>
<td>
sql_to_msp
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Export SQL Database to a MSP NIST MS Format
</h2>
<h3>
Description
</h3>
<p>
Export SQL Database to a MSP NIST MS Format
</p>
<h3>
Usage
</h3>
<pre>
sql_to_msp(
  con,
  optimized_params = TRUE,
  outputfile = paste0("DimSpecExport", Sys.Date(), ".msp"),
  cormethod = "pearson",
  normfn = "sum"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>con</code>
</td>
<td>
<p>
SQLite database connection
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>optimized_params</code>
</td>
<td>
<p>
Boolean TRUE indicates that the optimized parameters for uncertainty mass spectra will be used.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>outputfile</code>
</td>
<td>
<p>
Text string file name and/or location to save MSP file format
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>cormethod</code>
</td>
<td>
<p>
Text string type of correlation function to use (DEFAULT = ‘pearson’)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>normfn</code>
</td>
<td>
<p>
Text string type of normalization function to use (DEFAULT = ‘sum’)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, saves a *.msp file to the local file system.
</p>
<hr/>
<table id="fn_def_sqlite_auto_trigger" width="100%" summary="page for sqlite_auto_trigger">
<tr>
<td>
sqlite_auto_trigger
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Create a basic SQL trigger for handling foreign key relationships
</h2>
<h3>
Description
</h3>
<p>
This creates a simple trigger designed to streamline foreign key compliance
for SQLite databases. Resulting triggers will check during table insert or
update actions that have one or more foreign key relationships defined as
‘target_table.fk_col = norm_table.pk_col’. It is primarily for use in
controlled vocabulary lists where a single id is tied to a single value in
the parent table, but more complicated relationships can be handled.
</p>
<h3>
Usage
</h3>
<pre>
sqlite_auto_trigger(target_table = "test", fk_col = c("col1", "col2",
  "col3"), norm_table = c("norm_col1", "norm_col2", "norm_col3"), pk_col =
  "id", val_col = "value", action_occurs = "after", trigger_action =
  "insert", table_action = "update")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>target_table</code>
</td>
<td>
<p>
CHR scalar name of a table with a foreign key constraint.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fk_col</code>
</td>
<td>
<p>
CHR vector name(s) of the column(s) in ‘target_table’ with
foreign key relationship(s) defined.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>norm_table</code>
</td>
<td>
<p>
CHR vector name(s) of the table(s) containing the primary
key relationship(s).
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>pk_col</code>
</td>
<td>
<p>
CHR vector name(s) of the column(s) in ‘norm_table’ containing
the primary key(s) side of the relationship(s).
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>val_col</code>
</td>
<td>
<p>
CHR vector name(s) of the column(s) in ‘norm_table’ containing
values related to the primary key(s) of the relationship(s).
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>action_occurs</code>
</td>
<td>
<p>
CHR scalar on when to run the trigger, must be one of
‘c(“before”, “after”, “instead”)’ (“instead” should only be used if
‘target_table’ is a view - this restriction is not enforced).
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>trigger_action</code>
</td>
<td>
<p>
CHR scalar on what type of trigger this is (e.g. ‘when’
= “after” and ‘trigger_action’ = “insert” -&gt; “AFTER INSERT INTO”) and must
be one of ‘c(“insert”, “update”, “delete”)’.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>for_each</code>
</td>
<td>
<p>
CHR scalar for SQLite this must be only ‘row’ - translated
into a “FOR EACH ROW” clause. Set to any given noun for other SQL engines
supporting other trigger transaction types (e.g. “FOR EACH STATEMENT”
triggers)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>table_action</code>
</td>
<td>
<p>
CHR scalar on what type of action to run when the trigger
fires, must be one of ‘c(“insert”, “update”, “delete”)’.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>filter_col</code>
</td>
<td>
<p>
CHR scalar of a filter column to override the final WHERE
clause in the trigger. This should almost always be left as the default ““.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>filter_val</code>
</td>
<td>
<p>
CHR scalar of a filter value to override the final WHERE
clause in the trigger. This should almost always be left as the default ““.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>or_ignore</code>
</td>
<td>
<p>
LGL scalar on whether to ignore insertions to normalization
tables if an error occurs (default: TRUE, which can under certain
conditions raise exceptions during execution of the trigger if more than a
single value column exists in the parent table)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>addl_actions</code>
</td>
<td>
<p>
CHR vector of additional target actions to add to
‘table_action’ statements, appended to the end of the resulting “insert” or
“update” actions to ‘target_table’. If multiple tables are in use, use
positional matching in the vector (e.g. with three normalization tables,
and additional actions to only the second, use c(““,”additional actions”,
““))
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
These are intended as native database backup support for when connections do
not change the default SQLite setting of PRAGMA foreign_keys = off.
Theoretically any trigger could be created, but should only be used with care
outside the intended purpose.
</p>
<p>
Triggers created by this function will check all new INSERT and UPDATE
statements by checking provided values against their parent table keys. If an
index match is found no action will be taken on the parent table. If no match
is found, it is assumed this is a new normalized value and it will be added
to the normalization table and the resulting new key will be replaced in the
target table column.
</p>
<h3>
Value
</h3>
<p>
CHR scalar of class glue containing the SQL necessary to create a
trigger. This is raw text; it is not escaped and should be further
manipulated (e.g. via dbplyr::sql()) as your needs and database
communication pipelines dictate.
</p>
<h3>
Note
</h3>
<p>
While this will work on any number of combinations, all triggers should
be heavily inspected prior to use. The default case for this trigger is to
set it for a single FK/PK relationship with a single normalization value.
It will run on any number of normalized columns however trigger behavior
may be unexpected for more complex relationships.
</p>
<p>
If ‘or_ignore’ is set to TRUE, errors in adding to the parent table
will be ignored silently, possibly causing NULL values to be inserted into
the target table foreign key column. For this reason it is recommended that
the ‘or_ignore’ parameter only be set to true to expand parent table
entries, but it will only supply a single value for the new normalization
table. If additional columns in the parent table must be populated (e.g.
the parent table has two required columns “value” and “acronym”), it is
recommended to take care of those prior to any action that would activate
these triggers.
</p>
<p>
Parameters are not checked against a schema (e.g. tables and columns
exist, or that a relationships exists between tables). This function
processes only text provided to it.
</p>
<p>
Define individual relationships between ‘fk_col’, ‘norm_table’,
‘pk_col’, and ‘val_col’ as necessary. Lengths for these parameters should
match in a 1:1:1:1 manner to fully describe the relationships. If the
schema of all tables listed in ‘norm_table’ are close matches, e.g. all
have two columns “id” and “value” then ‘pk_col’ and ‘val_col’ will be
reused when only a single value is provided for them. That is, provided
three ‘norm_table’(s) and one ‘pk_col’ and one ‘val_col’, the arguments for
‘pk_col’ and ‘val_col’ will apply to each ‘norm_table’.
</p>
<p>
The usage example is built on a hypothetical SQLite schema containing
four tables, one of which (“test” - with columns “id”, “col1”, “col2”, and
“col3”) defines foreign key relationships to the other three (“norm_col1”,
“norm_col2”, and “norm_col3”).
</p>
<h3>
See Also
</h3>
<p>
build_triggers
</p>
<hr/>
<table id="fn_def_sqlite_auto_view" width="100%" summary="page for sqlite_auto_view">
<tr>
<td>
sqlite_auto_view
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Create a basic SQL view of a normalized table
</h2>
<h3>
Description
</h3>
<p>
Many database viewers will allow links for normalization tables to get the
human-readable value of a normalized column. Instead it is often preferable
to build in views automatically that “denormalize” such tables for display or
use in an application. This function seeks to script the process of creating
those views. It examines the table definition from [<a href="appendix-function-reference.html#fn_def_pragma_table_info">pragma_table_info</a>] and
will extract the primary/foreign key relationships to build a “denormalized”
view of the table using [<a href="appendix-function-reference.html#fn_def_get_fkpk_relationships">get_fkpk_relationships</a>] which requires a database
map created from [<a href="appendix-function-reference.html#fn_def_er_map">er_map</a>] and data dictionary created from [<a href="appendix-function-reference.html#fn_def_data_dictionary">data_dictionary</a>].
</p>
<h3>
Usage
</h3>
<pre>
sqlite_auto_view(table_pragma = pragma_table_info("contributors"),
  target_table = "contributors", relationships =
  get_fkpk_relationships(db_map = er_map(con), dictionary =
  data_dictionary(con)), drop_if_exists = FALSE)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>table_pragma</code>
</td>
<td>
<p>
data.frame object from [<a href="appendix-function-reference.html#fn_def_pragma_table_info">pragma_table_info</a>] for a given
table name in the database
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>target_table</code>
</td>
<td>
<p>
CHR scalar name of the database table to build for, which
should be present in the relationship definition
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>relationships</code>
</td>
<td>
<p>
data.frame object describing the foreign key
relationships for ‘target_table’, which should generally be the result of a
call to [<a href="appendix-function-reference.html#fn_def_get_fkpk_relationships">get_fkpk_relationships</a>]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>drop_if_exists</code>
</td>
<td>
<p>
LGL scalar indicating whether to include a “DROP VIEW”
prefix for the generated view statement; as this has an impact on schema,
no default is set
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
TODO for v2: abstract the relationships call by looking for objects in the
current session.
</p>
<h3>
Value
</h3>
<p>
CHR scalar of class glue containing the SQL necessary to create a
“denormalized” view. This is raw text; it is not escaped and should be
further manipulated (e.g. via dbplyr::sql()) as your needs and database
communication pipelines dictate.
</p>
<h3>
Note
</h3>
<p>
No schema checking is performed by this function, but rather relies on
definitions from other functions.
</p>
<p>
This example will run slowly if the database map [<a href="appendix-function-reference.html#fn_def_er_map">er_map</a>] and
dictionary [<a href="appendix-function-reference.html#fn_def_data_dictionary">data_dictionary</a>] haven’t yet been called. If they exist in your
session, use those as arguments to get_fkpk_relationships.
</p>
<h3>
See Also
</h3>
<p>
build_views
</p>
<p>
pragma_table_info
</p>
<p>
get_fkpk_relationships
</p>
<p>
er_map
</p>
<p>
data_dictionary
</p>
<hr/>
<table id="fn_def_sqlite_parse_build" width="100%" summary="page for sqlite_parse_build">
<tr>
<td>
sqlite_parse_build
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Parse SQL build statements
</h2>
<h3>
Description
</h3>
<p>
Reading SQL files directly into R can be problematic. This function is
primarily called in [<a href="appendix-function-reference.html#fn_def_create_fallback_build">create_fallback_build</a>]. To support multiline,
human-readable SQL statements, ‘sql_statements’ must be of length 1.
</p>
<h3>
Usage
</h3>
<pre>
example_file &lt;- "./config/sql_nodes/reference.sql"
if (file.exists(example_file)) {
  build_commands &lt;- readr::read_file(example_file)
  sqlite_parse_build(build_commands)
}
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>sql_statements</code>
</td>
<td>
<p>
CHR scalar of SQL build statements from an SQL file.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>magicsplit</code>
</td>
<td>
<p>
CHR scalar regex indicating some “magic” split point SQL
comment to simplify the identification of discrete commands; will be used
to split results (optional but highly recommended)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>header</code>
</td>
<td>
<p>
CHR scalar regex indicating the format of header comments SQL
comment to remove (optional)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>section</code>
</td>
<td>
<p>
CHR scalar regex indicating the format of section comments SQL
comment to remove (optional)
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
All arguments ‘magicsplit’, ‘header’, and ‘section’ provide flexibility in
the comment structure of the SQL file and accept regex for character matching
purposes.
</p>
<h3>
Value
</h3>
<p>
LIST of parsed complete build commands as CHR vectors containing each
line.
</p>
<hr/>
<table id="fn_def_sqlite_parse_import" width="100%" summary="page for sqlite_parse_import">
<tr>
<td>
sqlite_parse_import
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Parse SQL import statements
</h2>
<h3>
Description
</h3>
<p>
In the absence of the sqlite command line interface (CLI), the [<a href="appendix-function-reference.html#fn_def_build_db">build_db</a>]
process needs a full set of SQL statements to execute directly rather than
CLI dot commands. This utility function parses formatted SQL statements
containing CLI “.import” commands to create SQL INSERT statements. This
function is primarily called in [<a href="appendix-function-reference.html#fn_def_create_fallback_build">create_fallback_build</a>].
</p>
<h3>
Usage
</h3>
<pre>
if (file.exists("./config/data/elements.csv")) {
  sqlite_parse_import(".import --csv --skip 1 ./config/data/elements.csv elements")
}
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>build_statements</code>
</td>
<td>
<p>
CHR vector of SQL build statements from an SQL file.
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LIST of parsed .import statements as full “INSERT” statements.
</p>
<hr/>
<table id="fn_def_start_api" width="100%" summary="page for start_api">
<tr>
<td>
start_api
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Start the plumber interface from a clean environment
</h2>
<h3>
Description
</h3>
<p>
This convenience function launches the plumber instance if it was not set to
launch during the session setup. It is a thin wrapper with a more intuitive
name than [<a href="appendix-function-reference.html#fn_def_api_reload">api_reload</a>] and the default background setting turned off to test
the server in the current session.
</p>
<h3>
Usage
</h3>
<pre>
start_api()
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>plumber_file</code>
</td>
<td>
<p>
CHR scalar name of the plumber definition file, which
should be in <code>src_dir</code> (default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>plumber_host</code>
</td>
<td>
<p>
CHR scalar of the host server address (default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>plumber_port</code>
</td>
<td>
<p>
INT scalar of the listening port on the host server
(default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>background</code>
</td>
<td>
<p>
LGL scalar of whether to launch the API in a background
process (default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>src_dir</code>
</td>
<td>
<p>
CHR scalar file path to settings and functions enabling the
plumber API (default: here::here(“inst”, “plumber”))
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar name of the logging namespace to use for this
function (default: “api”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, launches the plumber instance
</p>
<h3>
Note
</h3>
<p>
This function is intended to pull from the environment variables
identifying the plumber file, host, and port.
</p>
<hr/>
<table id="fn_def_start_app" width="100%" summary="page for start_app">
<tr>
<td>
start_app
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
WIP Launch a shiny application
</h2>
<h3>
Description
</h3>
<p>
Call this function to launch an app either directly or in a background
process. The name must be present in the app directory or as a named
element of <code>SHINY_APPS</code> in the current environment.
</p>
<h3>
Usage
</h3>
<pre>
start_app("table_explorer")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>app_name</code>
</td>
<td>
<p>
CHR scalar name of the shiny app to run, this should be the
name of a directory containing a shiny app that is located within the
directory defined by <code>app_dir</code> or the name of an app as defined in your
environment SHINY_APPS variable
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>app_dir</code>
</td>
<td>
<p>
file path to a directory containing shiny apps (default:
here::here(“inst”, “apps”))
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>background</code>
</td>
<td>
<p>
LGL scalar of whether to launch the application in a
background process (default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>…</code>
</td>
<td>
<p>
Other named parameters to be passed to [shiny::runApp]
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, launches a browser with the requested shiny application
</p>
<h3>
Note
</h3>
<p>
Background launching of shiny apps is not yet supported.
</p>
<hr/>
<table id="fn_def_start_rdkit" width="100%" summary="page for start_rdkit">
<tr>
<td>
start_rdkit
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Start the RDKit integration
</h2>
<h3>
Description
</h3>
<p>
If the session was started without RDKit integration, e.g. INFORMATICS or
USE_RDKIT were FALSE in [config/env_R.R], start up RDKit in this session.
</p>
<h3>
Usage
</h3>
<pre>
start_rdkit(src_dir = here::here("inst", "rdkit"), log_ns = "rdkit")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>src_dir</code>
</td>
<td>
<p>
CHR scalar file path to settings and functions enabling rdkit
(default: here::here(“inst”, “rdkit”))
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar name of the logging namespace to use for this
function (default: “rdkit”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LGL scalar indicating whether starting RDKit integration was
successful
</p>
<h3>
Note
</h3>
<p>
RDKit and rcdk are incompatible. If the session was started with
INFORMATICS = TRUE and USE_RDKIT = FALSE, ChemmineR was likely loaded. If
this is the case, the session will need to be restarted due to java
conflicts between the two.
</p>
<hr/>
<table id="fn_def_summarize_check_fragments" width="100%" summary="page for summarize_check_fragments">
<tr>
<td>
summarize_check_fragments
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Summarize results of check_fragments function
</h2>
<h3>
Description
</h3>
<p>
Summarize results of check_fragments function
</p>
<h3>
Usage
</h3>
<pre>
summarize_check_fragments(fragments_checked)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>fragments_checked</code>
</td>
<td>
<p>
output of ‘check_fragments’ function
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
table summary of check_fragments function
</p>
<hr/>
<table id="fn_def_support_info" width="100%" summary="page for support_info">
<tr>
<td>
support_info
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
R session information for support needs
</h2>
<h3>
Description
</h3>
<p>
Several items of interest for this particular project including:
- DB_DATE, DB_VERSION, BUILD_FILE, LAST_DB_SCHEMA, LAST_MODIFIED, DEPENDS_ON,
and EXCLUSIONS as defined in the project’s ../config/env_R.R file.
</p>
<h3>
Usage
</h3>
<pre>
support_info()
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>app_info</code>
</td>
<td>
<p>
BOOL scalar on whether to return this application’s properties
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LIST of values
</p>
<hr/>
<table id="fn_def_suspectlist_at_NIST" width="100%" summary="page for suspectlist_at_NIST">
<tr>
<td>
suspectlist_at_NIST
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Open the NIST PDR entry for the current NIST PFAS suspect list
</h2>
<h3>
Description
</h3>
<p>
This simply points your browser to the NIST public data repository for the
current NIST suspect list, where you can find additional information. Click
the download button in the left column of any file to download it.
s
Requires the file “suspectlist_url.txt” to be present in the ‘config’
subdirectory of the current working directory.
</p>
<h3>
Usage
</h3>
<pre>
suspectlist_at_NIST(url_file = file.path("config", "suspectlist_url.txt"))
</pre>
<h3>
Value
</h3>
<p>
none
</p>
<h3>
Examples
</h3>
<pre>
suspectlist_at_NIST()
</pre>
<hr/>
<table id="fn_def_table_msdata" width="100%" summary="page for table_msdata">
<tr>
<td>
table_msdata
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Tabulate MS Data
</h2>
<h3>
Description
</h3>
<p>
Pulls specified MS Data from mzML and converts it into table format for further processing
Internal function for ‘peak_gather_json’ function
</p>
<h3>
Usage
</h3>
<pre>
table_msdata(mzml, scans, mz = NA, zoom = NA, masserror = NA, minerror = NA)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>mzml</code>
</td>
<td>
<p>
list of msdata from ‘mzMLtoR’ function
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>scans</code>
</td>
<td>
<p>
integer vector containing scan numbers to extract MS data
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>mz</code>
</td>
<td>
<p>
numeric targeted m/z
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>zoom</code>
</td>
<td>
<p>
numeric vector specifying the range around m/z, from m/z - zoom[1] to m/z + zoom[2]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>masserror</code>
</td>
<td>
<p>
numeric relative mass error (in ppm) of the instrument
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>minerror</code>
</td>
<td>
<p>
numeric minimum mass error (in Da) of the instrument
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data.frame containing MS data
</p>
<hr/>
<table id="fn_def_tack_on" width="100%" summary="page for tack_on">
<tr>
<td>
tack_on
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Append additional named elements to a list
</h2>
<h3>
Description
</h3>
<p>
This does nothing more than [base::append] ellipsis arguments to be added
directly to the end of an existing list object. This primarily supports
additional property assignment during the import process for future
development and refinement. Call this as part of any function with additional
arguments. This may result in failures or ignoring unrecognized named
parameters. If no additional arguments are passed <code>obj</code> is returned as
provided.
</p>
<h3>
Usage
</h3>
<pre>
tack_on(obj, ..., log_ns = "db")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>obj</code>
</td>
<td>
<p>
LIST of any length to be appended to
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>…</code>
</td>
<td>
<p>
Additional arguments passed to/from the ellipsis parameter of
calling functions. If named, names are preserved.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use (default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LIST object of length equal to <code>obj</code> plus additional named arguments
</p>
<h3>
Note
</h3>
<p>
If duplicate names exists in <code>obj</code> and those provided as ellipsis
arguments, those provided as part of the ellipsis will replace those in
<code>obj</code>.
</p>
<h3>
Examples
</h3>
<pre>
tack_on(list(a = 1:3), b = letters, c = rnorm(10))
tack_on(list(a = 1:3))
</pre>
<hr/>
<table id="fn_def_tidy_comments" width="100%" summary="page for tidy_comments">
<tr>
<td>
tidy_comments
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Tidy up table and field comments
</h2>
<h3>
Description
</h3>
<p>
Creates more human-readable outputs after extracting the raw SQL used to
build entities and parsing out the comments as identified with the /* … */
multi-line comment flag pair. Single line comments are not extracted. The
first comment is assumed to be the table comment. See examples in the
‘config/sql_nodes’ directory.
</p>
<h3>
Usage
</h3>
<pre>
tidy_comments(pragma_table_def("compounds", get_sql = TRUE))
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>obj</code>
</td>
<td>
<p>
result of calling [<a href="appendix-function-reference.html#fn_def_pragma_table_def">pragma_table_def</a>] with ‘get_sql’ = TRUE
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LIST of length equal to ‘obj’ containing extracted comments
</p>
<hr/>
<table id="fn_def_tidy_ms_spectra" width="100%" summary="page for tidy_ms_spectra">
<tr>
<td>
tidy_ms_spectra
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Tidy Spectra
</h2>
<h3>
Description
</h3>
<p>
A convenience function to take outputs from [<a href="appendix-function-reference.html#fn_def_ms_spectra_separated">ms_spectra_separated</a>] and
[<a href="appendix-function-reference.html#fn_def_ms_spectra_zipped">ms_spectra_zipped</a>] and return them as a tidy data frame by unpacking the
list column “spectra”.
</p>
<h3>
Usage
</h3>
<pre>
tidy_ms_spectra(df = packed_data)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>df</code>
</td>
<td>
<p>
data.frame object containing nested spectra in a column
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data.frame object containing tidy spectra
</p>
<hr/>
<table id="fn_def_tidy_spectra" width="100%" summary="page for tidy_spectra">
<tr>
<td>
tidy_spectra
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Decompress Spectra
</h2>
<h3>
Description
</h3>
<p>
This convenience wrapper will automatically decompress ms spectra in the
“separate” and “zipped” formats and return them as tidy data frames suitable
for further manipulation or visualization.
</p>
<h3>
Usage
</h3>
<pre>
tidy_spectra(
  target,
  is_file = FALSE,
  is_format = c("separated", "zipped"),
  spectra_set = "msdata",
  ms_col_sep = c("measured_mz", "measured_intensity"),
  ms_col_zip = "data",
  is_JSON = FALSE
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>target</code>
</td>
<td>
<p>
CHR scalar file path to use OR an R object containing
compressed spectral data in the “separate” or “zipped” format
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>is_file</code>
</td>
<td>
<p>
BOOL scalar of whether or not ‘target’ is a file. Set to FALSE
to use an existing R object, which should contain an object with a named
element matching parameter ‘spectra_set’ (default TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>is_format</code>
</td>
<td>
<p>
CHR scalar of the compression format, which must be one of
the supported compression forms (“separated” or “zipped”); ignored if the
compression format can be inferred from the text in ‘target’ (default
“separate”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>spectra_set</code>
</td>
<td>
<p>
CHR scalar of the object name holding a spectra data frame
to decompress (default “msdata”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms_col_sep</code>
</td>
<td>
<p>
CHR vector of the column names holding spectral masses and
intensities in the “separate” format (default c(“masses”, “intensities”))
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ms_col_zip</code>
</td>
<td>
<p>
CHR scalar of the name of the column holding spectral
masses and intensities in the “unzip” format (default “msdata”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>is_JSON</code>
</td>
<td>
<p>
BOOL scalar of whether or not ‘target’ is a JSON expression
needing conversion (default TRUE)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
data.frame object containing unpacked spectra
</p>
<h3>
Examples
</h3>
<pre>
tidy_spectra('{"msdata": "712.9501 15094.41015625 713.1851 34809.9765625"}', is_format = "zipped")
tidy_spectra('{"measured_mz":"712.9501 713.1851","measured_intensity":"15094.41015625 34809.9765625"}')
</pre>
<hr/>
<table id="fn_def_unzip" width="100%" summary="page for unzip">
<tr>
<td>
unzip
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Unzip binary data into vector
</h2>
<h3>
Description
</h3>
<p>
Unzip binary data into vector
</p>
<h3>
Usage
</h3>
<pre>
unzip(x, type = "gzip")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>x</code>
</td>
<td>
<p>
String of binary data to convert
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>type</code>
</td>
<td>
<p>
type of compression (see ‘base::memDecompress’). Default is ‘gzip’
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
vector containing data from converted binary data
</p>
<hr/>
<table id="fn_def_update_all" width="100%" summary="page for update_all">
<tr>
<td>
update_all
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Convenience function to rebuild all database related files
</h2>
<h3>
Description
</h3>
<p>
This is a development and deployment function that should be used with
caution. It is intended solely to assist with the development process of
rebuilding a database schema from source files and producing the supporting
data. It will create both the JSON expressin of the data dictionary and the
fallback SQL file.
</p>
<h3>
Usage
</h3>
<pre>
update_all()
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>rebuild</code>
</td>
<td>
<p>
LGL scalar indicating whether to first rebuild from
environment settings (default: FALSE for safety)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>api_running</code>
</td>
<td>
<p>
LGL scalar of whether or not the API service is currently
running (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>api_monitor</code>
</td>
<td>
<p>
process object pointing to the API service (default: NULL)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db</code>
</td>
<td>
<p>
CHR scalar of the database name (default: session value DB_NAME)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>build_from</code>
</td>
<td>
<p>
CHR scalar of a SQL build script to use (default:
environment value DB_BUILD_FILE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>populate</code>
</td>
<td>
<p>
LGL scalar of whether to populate with data from the file in
‘populate_with’ (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>populate_with</code>
</td>
<td>
<p>
CHR scalar for the populate script (e.g.
“populate_demo.sql”) to during after the build is complete; (default:
session value DB_DATA); ignored if ‘populate = FALSE’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>archive</code>
</td>
<td>
<p>
LGL scalar of whether to create an archive of the current
database (if it exists) matching the name supplied in argument ‘db’
(default: FALSE), passed to [‘remove_db()’]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>sqlite_cli</code>
</td>
<td>
<p>
CHR scalar to use to look for installed sqlite3 CLI tools
in the current system environment (default: session value SQLITE_CLI)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>connect</code>
</td>
<td>
<p>
LGL scalar of whether or not to connect to the rebuilt
database in the global environment as object ’con“ (default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use during execution
(default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
!! To preserve data, do not call this with both ‘rebuild’ = TRUE and
‘archive’ = FALSE !!
</p>
<h3>
Value
</h3>
<p>
Files for the new database, fallback build, and data dictionary will
be created in the project directory and objects will be created in the
global environment for the database map (LIST “db_map”) and current
dictionary (LIST “db_dict”)
</p>
<h3>
Note
</h3>
<p>
This does not recast the views and triggers files created through
[sqlite_autoview] and [sqlite_autotrigger] as the output of those may often
need additional customization. Existing auto-views and -triggers will be
created as defined. To exclude those, first modify the build file
referenced by [<a href="appendix-function-reference.html#fn_def_build_db">build_db</a>].
</p>
<p>
This requires references to be in place to the individual functions in
the current environment.
</p>
<hr/>
<table id="fn_def_update_data_sources" width="100%" summary="page for update_data_sources">
<tr>
<td>
update_data_sources
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Dump current database contents
</h2>
<h3>
Description
</h3>
<p>
Perform one or both of two main tasks for backing up the NTA database.
</p>
<h3>
Usage
</h3>
<pre>
update_data_sources(
  project,
  data_dir = file.path("config", "data"),
  create_backups = TRUE,
  dump_tables = TRUE,
  dump_sql = TRUE,
  db_conn = con,
  sqlite_cli = ifelse(exists("SQLITE_CLI"), SQLITE_CLI, NULL),
  db_name = ifelse(exists("DB_NAME"), DB_NAME, NULL)
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>project</code>
</td>
<td>
<p>
CHR scalar of the directory containing project specific data
(required, no default)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>data_dir</code>
</td>
<td>
<p>
CHR scalar of the directory containing project independent
data sources used for population (default: ‘file.path(“config”, “data”)’)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>create_backups</code>
</td>
<td>
<p>
LGL scalar indicating whether to create backups prior
to writing updated data files (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>dump_tables</code>
</td>
<td>
<p>
LGL scalar indicating whether to dump contents of database
tables as comma-separated-value files (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>dump_sql</code>
</td>
<td>
<p>
LGL scalar indicating whether to create an SQL dump file
containing both schema and data as a backup (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>SQLITE_CLI</code>
</td>
<td>
<p>
CHR scalar system reference to your installation of the
sqlite command line interface
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
The main task is to update CSV files in the config/data directory with the
current contents of the database. This is done on a table by table basis and
results in flat files whose structures no longer interrelate except
numerically. Primarily this would be used to migrate database contents to
other systems or for further manipulation. Please specify a ‘project’ that
project-specific information can be maintained.
</p>
<p>
Backups created with this function are placed in a “backups” subdirectory of
the directory defined by parameter ‘data_dir’. If ‘dump_sql = TRUE’ SQL dump
files will be written to “backups/sqlite” with file names equal to the
current database name prefixed by date.
</p>
<h3>
Value
</h3>
<p>
None, copies database information to the local file system
</p>
<hr/>
<table id="fn_def_update_env_from_file" width="100%" summary="page for update_env_from_file">
<tr>
<td>
update_env_from_file
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Update a conda environment from a requirements file
</h2>
<h3>
Description
</h3>
<p>
The ‘requirements_file’ can be any formatted file that contains a definition
for python libraries to add to an environment (e.g. requirements.txt,
environment.yml, etc) that is understood by conda. Relative file paths are
fine, but the file will not be discovered (e.g. by ‘list.files’) so
specificity is always better.
</p>
<h3>
Usage
</h3>
<pre>
update_env_from_file("nist_hrms_db")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>env_name</code>
</td>
<td>
<p>
CHR scalar of a python environment
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>requirements_file</code>
</td>
<td>
<p>
CHR scalar file path to a suitable requirements.txt
or environment.yml file
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>conda_alias</code>
</td>
<td>
<p>
CHR scalar of the command line interface alias for your
conda tools (default: NULL is translated first to the environment variable
CONDA_CLI and then to “conda”)
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
This is a helper function, largely to support versions of reticulate prior to
the introduction of the environment argument in version 1.24+.
</p>
<h3>
Value
</h3>
<p>
None, directly updates the referenced python environment
</p>
<h3>
Note
</h3>
<p>
This requires conda CLI tools to be installed.
</p>
<p>
A default installation alias of “conda” is assumed.
</p>
<p>
Set global variable ‘CONDA_CLI’ to your conda alias for better support.
</p>
<hr/>
<table id="fn_def_update_logger_settings" width="100%" summary="page for update_logger_settings">
<tr>
<td>
update_logger_settings
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Update logger settings
</h2>
<h3>
Description
</h3>
<p>
This applies the internal routing and formatting for logger functions to the
current value of the LOGGING object. If LOGGING is changed (i.e. a logging
namespace is added or changed) this function should be run to update routing
and formatting to be in line with the current settings.
</p>
<h3>
Usage
</h3>
<pre>
update_logger_settings(log_all_warnings = FALSE, log_all_errors =
  FALSE)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>log_all_warnings</code>
</td>
<td>
<p>
LGL scalar indicating whether or not to log all
warnings (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_all_errors</code>
</td>
<td>
<p>
LGL scalar indicating whether or not to log all errors
(default: TRUE)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None
</p>
<h3>
Note
</h3>
<p>
The calling stack for auto logging of warnings and errors does not work
with background processes. These settings call [logger::log_warnings()] and
[logger::log_errors()].
</p>
<p>
This function is used only for its side effects.
</p>
<hr/>
<table id="fn_def_user_guide" width="100%" summary="page for user_guide">
<tr>
<td>
user_guide
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Launch the User Guide for DIMSpec
</h2>
<h3>
Description
</h3>
<p>
Use this function to launch the bookdown version of the User Guide for the
NIST Database Infrastructure for Mass Spectrometry (DIMSpec) Toolkit
</p>
<h3>
Usage
</h3>
<pre>
user_guide()
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>path</code>
</td>
<td>
<p>
CHR scalar representing a valid file path to the local user guide
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>url_gh</code>
</td>
<td>
<p>
CHR scalar pointing to the web resource, in this case the URL
to the User Guide hosted on GitHub pages
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>view_on_github</code>
</td>
<td>
<p>
LGL scalar of whether to use the hosted version of the
User Guide on GitHub (default: TRUE is recommended) which will always
display the most up to date version
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None, opens a browser to the index page of the User Guide
</p>
<h3>
Note
</h3>
<p>
This works ONLY when DIMSpec is used as a project with the defined
directory structure
</p>
<hr/>
<table id="fn_def_valid_file_format" width="100%" summary="page for valid_file_format">
<tr>
<td>
valid_file_format
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Ensure files uploaded to a shiny app are of the required file type
</h2>
<h3>
Description
</h3>
<p>
This input validation check uses [tools::file_ext] to ensure that files
uploaded to [shiny::fileInput] are among the acceptable file formats. Users
may sometimes wish to load a file outside the “accepts” format list by
manually changing it during the upload process. If they are not, a
[<a href="appendix-function-reference.html#fn_def_nist_shinyalert">nist_shinyalert</a>] modal is displayed prompting the user to upload a file in
one of the requested formats.
</p>
<h3>
Usage
</h3>
<pre>
req(valid_file_format(input$file_upload, c(".csv", ".xls")))
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>filename</code>
</td>
<td>
<p>
CHR scalar name of the file uploaded to the shiny server
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>accepts</code>
</td>
<td>
<p>
CHR vector of acceptable file formats
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>show_alert</code>
</td>
<td>
<p>
LGL scalar indicating whether or not to show an alert, set
FALSE to return the status of the check
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
Whether or not all required values are present.
</p>
<hr/>
<table id="fn_def_validate_casrns" width="100%" summary="page for validate_casrns">
<tr>
<td>
validate_casrns
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Validate a CAS RN
</h2>
<h3>
Description
</h3>
<p>
Chemical Abstract Service (CAS) Registry Numbers (RNs) follow a standard
creation format. From
[<a href="https://www.cas.org/support/documentation/chemical-substances/faqs" class="uri">https://www.cas.org/support/documentation/chemical-substances/faqs</a>], a CAS
RN is a “numeric identifier that can contain up to 10 digits, divided by
hyphens into three parts. The right-most digit is a check digit used to
verify the validity and uniqueness of the entire number. For example, 58-08-2
is the CAS Registry Number for caffeine.”
</p>
<h3>
Usage
</h3>
<pre>
validate_casrns(casrn_vec, strip_bad_cas = TRUE)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>casrn_vec</code>
</td>
<td>
<p>
CHR vector of what CAS RNs to validate
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>strip_bad_cas</code>
</td>
<td>
<p>
LGL scalar of whether to strip out invalid CAS RNs
(default: TRUE)
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
Provided CAS RNs in ‘casrn_vec’ are validated for format and their checksum
digit. Those failing will be printed to the console by default, and users
have the option of stripping unverified entries from the return vector.
</p>
<p>
This only validates that a CAS RN is properly constructed; it does not
indicate that the registry number exists in the CAS Registry.
</p>
<p>
See [<a href="appendix-function-reference.html#fn_def_repair_xl_casrn_forced_to_date">repair_xl_casrn_forced_to_date</a>] as one possible pre-processing step.
</p>
<h3>
Value
</h3>
<p>
CHR vector of length equal to that of ‘casrn_vec’
</p>
<h3>
Examples
</h3>
<pre>
validate_casrns(c("64324-08-9", "64324-08-5", "12332"))
validate_casrns(c("64324-08-9", "64324-08-5", "12332"), strip_bad_cas = FALSE)
</pre>
<hr/>
<table id="fn_def_validate_column_names" width="100%" summary="page for validate_column_names">
<tr>
<td>
validate_column_names
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Ensure database column presence
</h2>
<h3>
Description
</h3>
<p>
When working with SQL databases, this convenience function validates any
number of column names by comparing against the list of column names in any
number of tables. Typically it is called transparently inline to cause
execution failure when column names are not present in referenced tables
during build of SQL queries.
</p>
<h3>
Usage
</h3>
<pre>
validate_column_names(con, "peaks", "id")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (e.g. of class “SQLiteConnection”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>table_names</code>
</td>
<td>
<p>
CHR vector of tables to search
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>column_names</code>
</td>
<td>
<p>
CHR vector of column names to validate
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
None
</p>
<hr/>
<table id="fn_def_validate_tables" width="100%" summary="page for validate_tables">
<tr>
<td>
validate_tables
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Ensure database table presence
</h2>
<h3>
Description
</h3>
<p>
When working with SQL databases, this convenience function validates any
number of table names by comparing against the list of those present.
Typically it is called transparently inline to cause execution failure when
tables are not present during build of SQL queries.
</p>
<h3>
Usage
</h3>
<pre>
validate_tables(con, "peaks")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (e.g. of class “SQLiteConnection”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>table_names</code>
</td>
<td>
<p>
CHR vector name of tables to ensure are present
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
Failure if the table doesn’t exist, none if it does.
</p>
<hr/>
<table id="fn_def_verify_args" width="100%" summary="page for verify_args">
<tr>
<td>
verify_args
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Verify arguments for a function
</h2>
<h3>
Description
</h3>
<p>
This helper function checks arguments against a list of expectations. This
was in part inspired by the excellent <a href="https://testthat.r-lib.org/"><a href="https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf">testthat</a></a>
package and shares concepts with the <a href="https://mllg.github.io/checkmate/">Checkmate</a>
package. However, this function performs many of the common checks without
additional package dependencies, and can be inserted into other functions
for a project easily with:
</p>
<pre>  arg_check &lt;- verify_args(args = as.list(environment()),
  conditions = list(param1 = c("mode", "logical"), param2 = c("length", 1))</pre>
<p>
and check the return with
</p>
<pre>  if (!arg_check$valid) cat(paste0(arg_check$messages, "\n"))</pre>
<p>
where argument <code>conditions</code> describes the tests. This comes at the price
of readability as the list items in <code>conditions</code> do not have to be
named, but can be to improve clarity. See more details below for argument
<code>conditions</code> to view which expectations are currently supported.
As this is a nested list condition check, it can also originate from any
source coercible to a list (e.g. JSON, XML, etc.) and this feature, along
with the return of human-meaningful evaluation strings, is particularly
useful for development of shiny applications. Values from other sources MUST
be coercible to a full list (e.g. if being parsed from JSON, use
<code>jsonlite::fromJSON(simplifyMatrix = FALSE)</code>)
</p>
<h3>
Usage
</h3>
<pre>
verify_args(args = list(character_length_2 = c("a", "b")),
            conditions = list(character_length_2 = list(c("mode", "character"),
                                                        c("length", 3))
)
verify_args(args = list(boolean = c(TRUE, FALSE, TRUE)),
            conditions = list(list(c("mode", "logical"),
                                   c("length", 1)))
)
verify_args(args = list(foo = c(letters[1:3]),
                        bar = 1:10),
            conditions = list(foo = list(c("mode", "numeric"),
                                         c("n&gt;", 5)),
                              bar = list(c("mode", "logical"),
                                         c("length", 5),
                                         c("&gt;", 10),
                                         c("between", list(100, 200)),
                                         c("choices", list("a", "b"))))
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>args</code>
</td>
<td>
<p>
LIST of named arguments and their values, typically passed
directly from a function definition in the form <code>args = list(foo =
1:2, bar = c(“a”, “b”, “c”))</code> or directly by passing <code>environment()</code>
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>conditions</code>
</td>
<td>
<p>
Nested LIST of conditions and values to check, with one
list item for each element in <code>args</code>.
</p>
<ul>
<li>
<p>
The first
element of each list should be a character scalar in the supported list.
</p>
</li>
<li>
<p>
The second element of each list should be the check values themselves
and may be of any type.
</p>
</li>
</ul>
<p>
Multiple expectation conditions can be set for
each element of <code>args</code> in the form
</p>
<ul>
<li>
<p>
<code>conditions =
list(foo = list(c(“mode”, “numeric”), c(“length”, 2)), bar = list(c(“mode”,
“character”), c(“n&lt;”, 5)))</code>
</p>
</li>
</ul>
<p>
Currently supported expectations are:
</p>
<ul>
<li>
<p>
<code>class</code>: checks strict class expectation by direct
comparison with <code>class</code> to support object classes not supported with
the <code>is.x</code> or <code>is_x</code> family of functions; much stricter than a
“mode” check in that the requested check must be present in the return from
a call to <code>class</code> e.g. “list” will fail if a “data.frame” object is
passed
</p>
</li>
<li>
<p>
<code>mode</code>: checks class expectation by applying the
<code>is.X</code> or the <code>is_X</code> family of functions either directly or
flexibly depending on the value provided to <code>conditions</code> (e.g.
<code>c(“mode”, “character”)</code> and <code>c(“mode”, “is.character”)</code> and <code>c(“mode”,
“is_character”)</code> all work equally well) and will default to the version you
provide explicitly (e.g. if you wish to prioritize “is_character” over
“is.character” simply provide “is_character” as the condition. Only those
modes able to be checked by this family of functions are supported. Run
function <code>mode_checks()</code> for a complete sorted list for your current
configuration.
</p>
</li>
<li>
<p>
<code>length</code>: length of values matches a pre-determined
exact length, typically a single value expectation (e.g. <code>c(“length”,#’
1)</code>)
</p>
</li>
<li>
<p>
<code>no_na</code>: no <code>NA</code> values are present
</p>
</li>
<li>
<p>
<code>n&gt;</code>: length of
values is greater than a given value - “n&lt;” length of values is lesser than
a given value
</p>
</li>
<li>
<p>
<code>n&gt;=</code>: length of values is greater than or equal to
a given value
</p>
</li>
<li>
<p>
<code>n&lt;=</code>: length of values is lesser than or equal to a
given value
</p>
</li>
<li>
<p>
<code>&gt;</code>: numeric or date value is greater than a given
value
</p>
</li>
<li>
<p>
<code>&lt;</code>: numeric or date value is greater than a given value
</p>
</li>
<li>
<p>
<code>&gt;=</code>: numeric or date value is greater than or equal to a given
value
</p>
</li>
<li>
<p>
<code>&lt;=</code>: numeric or date value is lesser than or equal to a
given value
</p>
</li>
<li>
<p>
<code>between</code>: numeric or date values are bound within an
INCLUSIVE range (e.g. <code>c(“range”, 1:5)</code>)
</p>
</li>
<li>
<p>
<code>choices</code>: provided values
are part of a selected list of expectations (e.g. <code>c(“choices”,
list(letters[1:3]))</code>)
</p>
</li>
<li>
<p>
<code>FUN</code>: apply a function to the value and
check that the result is valid or that the function can be executed without
error; this evaluates the check condition using [tryCatch()] via
[do.call()] and so can also accept a full named list of arg values. This
is a strict check in the sense that a warning will also result in a failed
result, passing the warning (or error if the function fails) message back
to the user, but does not halt checks
</p>
</li>
</ul>
</td>
</tr>
<tr valign="top">
<td>
<code>from_fn</code>
</td>
<td>
<p>
CHR scalar of the function from which this is called, used if
logger is enabled and ignored if not; by default it will pull the calling
function’s name from the call stack, but can be overwritten by a manual
entry here for better tracing. (default <code>NULL</code>)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>silent</code>
</td>
<td>
<p>
LGL scalar of whether to silence warnings for individual
failiures, leaving them only as part of the output. (default: <code>FALSE</code>)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
LIST of the resulting values and checks, primarily useful for its
<code><span class="math inline">\(valid&lt;/code&gt; (&lt;code&gt;TRUE&lt;/code&gt; if all checks pass or &lt;code&gt;FALSE&lt;/code&gt; if any fail) and &lt;code&gt;\)</span>message</code> values.
</p>
<h3>
Note
</h3>
<p>
If logger is enabled, also provides some additional meaningful feedback.
</p>
<p>
At least one condition check is required for every element passed to <code>args</code>.
</p>
<hr/>
<table id="fn_def_verify_import_columns" width="100%" summary="page for verify_import_columns">
<tr>
<td>
verify_import_columns
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Verify column names for import
</h2>
<h3>
Description
</h3>
<p>
This function validates that all required columns are present prior to
importing into a database column by examining provided values against the
database schema. This is more of a sanity check on other functions than
anything, but also strips extraneous columns to meet the needs of an INSERT
action. The input to ‘values’ should be either a LIST or named CHR vector of
values for insertion or a CHR vector of the column names.
</p>
<h3>
Usage
</h3>
<pre>
verify_import_columns(
  values,
  db_table,
  names_only = FALSE,
  require_all = TRUE,
  db_conn = con,
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>values</code>
</td>
<td>
<p>
LIST or CHR vector of values to add. If ‘names_only’ is TRUE,
values are directly interpreted as column names. Otherwise, all values
provided must be named.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_table</code>
</td>
<td>
<p>
CHR scalar of the table name
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>names_only</code>
</td>
<td>
<p>
LGL scalar of whether to treat entries of ‘values’ as the
column names rather than the column values (default: FALSE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>require_all</code>
</td>
<td>
<p>
LGL scalar of whether to require all columns (except the
assumed primary key column of “id”) or only those defined as “NOT NULL”
(default: TRUE requires the presence of all columns in the table)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>db_conn</code>
</td>
<td>
<p>
connection object (default: con)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use (default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
An object of the same type as ‘values’ with extraneous values (i.e.
those not matching a database column header) stripped away.
</p>
<h3>
Note
</h3>
<p>
If columns are defined as required in the schema and are not present,
this will fail with an informative message about which columns were
missing.
</p>
<p>
If columns are provided that do not match the schema, they will be
stripped away in the return value.
</p>
<hr/>
<table id="fn_def_verify_import_requirements" width="100%" summary="page for verify_import_requirements">
<tr>
<td>
verify_import_requirements
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Verify an import file’s properties
</h2>
<h3>
Description
</h3>
<p>
Checks an import file’s characteristics against expectations. This is mostly
a sanity check against changing conditions from project to project. Import
requirements should be defined at the environment level and enumerated as a
JSON object, which can be created by calling [<a href="appendix-function-reference.html#fn_def_make_requirements">make_requirements</a>] on an
example import for simplicity. An example is provided in the ‘examples’
directory as “NIST_import_requirements.json”. If multiple requirements are in
use (e.g. pulling from multiple locations), this can be run multiple times
with different values of ‘requirement_obj’ or ‘file_name’.
</p>
<h3>
Usage
</h3>
<pre>
verify_import_requirements(
  obj,
  ignore_extra = TRUE,
  requirements_obj = "import_requirements",
  file_name = "import_requirements",
  log_issues_as = "warn",
  log_ns = "db"
)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>obj</code>
</td>
<td>
<p>
LIST of the object to import matching structure expectations,
typically from a JSON file fed through [<a href="appendix-function-reference.html#fn_def_full_import">full_import</a>]
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ignore_extra</code>
</td>
<td>
<p>
LGL scalar of whether to ignore extraneous import
elements or stop the import process (default: TRUE)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>requirements_obj</code>
</td>
<td>
<p>
CHR scalar of the name of an R object holding import
requirements; this is a convenience shorthand to prevent multiple imports
from parameter ‘file_name’ (default: “import_requirements”)
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>file_name</code>
</td>
<td>
<p>
CHR scalar of the name of a file holding import
requirements; if this has already been added to the calling environment,
‘requirements_obj’ will be used preferentially as the name of that object
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_issues_as</code>
</td>
<td>
<p>
CHR scalar of the log level to use (default: “warn”),
which must be a valid log level as in [logger::FATAL]; will be ignored if
the [<a href="https://CRAN.R-project.org/package=logger">logger</a>] package isn’t available
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>log_ns</code>
</td>
<td>
<p>
CHR scalar of the logging namespace to use (default: “db”)
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
The return from this is a tibble with 9 columns. The first is the name of the
import object member, typically the file name. If a single, unnested import
object is provided this will be “import object”. The other columns include
the following verification checks:
</p>
<p>
<ol style="list-style-type: decimal">
<li>has_all_required: Are all required names present in the sample?
(TRUE/FALSE)</li>
</ol>
</p>
<p>
<ol start="2" style="list-style-type: decimal">
<li>missing_requirements: Character vectors naming any of the missing
requirements</li>
</ol>
</p>
<p>
<ol start="3" style="list-style-type: decimal">
<li>has_full_detail: Is all expected detail present? (TRUE/FALSE)</li>
</ol>
</p>
<p>
<ol start="4" style="list-style-type: decimal">
<li>missing_detail: Character vectors naming any missing value sets</li>
</ol>
</p>
<p>
<ol start="5" style="list-style-type: decimal">
<li>has_extra: Are there unexpected values provided? (TRUE/FALSE)</li>
</ol>
</p>
<p>
<ol start="6" style="list-style-type: decimal">
<li>extra_cols: Character vectors naming any has_extra columns; these will be
dropped from the import but are provided for information sake</li>
</ol>
</p>
<p>
<ol start="7" style="list-style-type: decimal">
<li>has_name_mismatches: Are there name differences between the import
requirement elements and the import object? (TRUE/FALSE)</li>
</ol>
</p>
<p>
<ol start="8" style="list-style-type: decimal">
<li>mismatched_names: Named lists enumerating which named elements (if any)
from the import object did not match name expectations in the requirements</li>
</ol>
</p>
<p>
All of this is defined by the ‘requirements_obj’ list. Do not provide that
list directly, instead pass this function the name of the requirements object
for interoperability. If a ‘requirements_obj’ cannot be identified via
[base::exists] then the ‘file_name’ will take precedence and be imported.
Initial use and set up may be easier in interactive sessions.
</p>
<h3>
Value
</h3>
<p>
A tibble object with 9 columns containing the results of the checks.
</p>
<h3>
Note
</h3>
<p>
If ‘file_name’ is provided, it need not be fully defined. The value
provided will be used to search the project directory.
</p>
<hr/>
<table id="fn_def_with_help" width="100%" summary="page for with_help">
<tr>
<td>
with_help
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Convenience application of <code>add_help</code> using pipes directly in <code>UI.R</code>
</h2>
<h3>
Description
</h3>
<p>
This may not work for certain widgets with heavily nested HTML. Note that
classes may be CSS dependent.
</p>
<h3>
Usage
</h3>
<pre>
actionButton("example", "With Help") 
  with_help("Now with a question mark icon hosting a tooltip")
actionButton("example", "With Help") 
  with_help("Large and green", size = "xl", class = "success")
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>widget</code>
</td>
<td>
<p>
shiny.tag widget
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>tooltip</code>
</td>
<td>
<p>
CHR scalar of the tooltip text
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>…</code>
</td>
<td>
<p>
Other named arguments to be passed to ‘add_help’
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
The <code>widget</code> provided with a hover tooltip icon appended to it.
</p>
<h3>
Note
</h3>
<p>
Most standard Shiny widgets are supported, but maybe not all.
</p>

</div>














            </section>

          </div>
        </div>
      </div>
<a href="msmatch-home.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": null,
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": [["DIMSPec_User_Guide.epub", "DIMSpec User Guide (epub)"], ["DIMSpec_User_Guide.pdf", "DIMSpec User Guide (pdf)"], ["quick_install.pdf", "Quick Guide - Installation"], ["file_convert.pdf", "Quick Guide - Conversion to mzML"], ["quick_plumber.pdf", "Quick Guide - API"], ["quick_apps.pdf", "Quick Guide - Web Apps"], ["quick_import.pdf", "Quick Guide - Importing Data"], ["quick_advanced.pdf", "Quick Guide - Advanced Use and Development"]],
"search": {
"engine": "fuse",
"options": null,
"isCaseSensitive": false,
"threshold": 0,
"distance": 0
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
